tnguyent@x3206c0s37b1n0:~/ai-science-training-series/02-AI-at-Scale> bash run_hw_session2.sh

Lmod is automatically replacing "nvidia/24.11" with "gcc-native/14.2".


Lmod is automatically replacing "PrgEnv-nvidia/8.6.0" with "PrgEnv-gnu/8.6.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-mpich/8.1.32

========================================================
Running Experiment: Layers=8, TP=1
Start Time: 2025-11-23 23:04:07
========================================================


[2025-11-23 23:04:19,330111][I][ezpz/launch:369:launch] ----[üçã ezpz.launch][started][2025-11-23-230419]----
[2025-11-23 23:04:20,542484][I][ezpz/launch:374:launch] Job ID: 6650384
[2025-11-23 23:04:20,543530][I][ezpz/launch:375:launch] nodelist: ['x3206c0s37b1n0', 'x3206c0s7b0n0']
[2025-11-23 23:04:20,543926][I][ezpz/launch:376:launch] hostfile: /var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov
[2025-11-23 23:04:20,544883][I][ezpz/pbs:179:get_pbs_launch_cmd] ‚úÖ Using [8/8] GPUs [2 hosts] x [4 GPU/host]
[2025-11-23 23:04:20,547023][I][ezpz/launch:345:build_executable] Building command to execute by piecing together:
[2025-11-23 23:04:20,547405][I][ezpz/launch:346:build_executable] (1.) launch_cmd: mpiexec --verbose --envall --np=8 --ppn=4 --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind=depth --depth=8
[2025-11-23 23:04:20,547947][I][ezpz/launch:347:build_executable] (2.) cmd_to_launch: python3 -m ezpz.examples.fsdp_tp --dataset random --n-layers 8 --tp 1
[2025-11-23 23:04:20,548525][I][ezpz/launch:389:launch] Took: 1.22 seconds to build command.
[2025-11-23 23:04:20,548869][I][ezpz/launch:390:launch] Executing:
mpiexec
  --verbose
  --envall
  --np=8
  --ppn=4
  --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov
  --cpu-bind=depth
  --depth=8
  python3
  -m
  ezpz.examples.fsdp_tp
  --dataset
  random
  --n-layers
  8
  --tp
  1
[2025-11-23 23:04:20,550594][I][ezpz/launch:397:launch] Execution started @ 2025-11-23-230420...
[2025-11-23 23:04:20,551026][I][ezpz/launch:398:launch] ----[üçã ezpz.launch][stop][2025-11-23-230420]----
[2025-11-23 23:04:20,551491][I][ezpz/launch:127:run_command] Running command:
 mpiexec --verbose --envall --np=8 --ppn=4 --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind=depth --depth=8 python3 -m ezpz.examples.fsdp_tp --dataset random --n-layers 8 --tp 1
Disabling local launch: multi-node application
Connected to tcp://x3206c0s37b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/applications/conda/2025-09-25/mconda3/bin/python3
Launching application 52fe1345-8637-4361-ab08-8868a001f0f5
Using PMI ports 58839,58840
[2025-11-23 23:04:33,784332][I][examples/fsdp_tp:334:<module>] args:
Namespace(dim=256, n_layers=8, n_heads=32, n_kv_heads=4, multiple_of=360, ffn_dim_multiplier=None, norm_eps=1e-05, vocab_size=32000, seq_length=2048, lr=0.003, epochs=50, batch_size=24, seed=None, tp=1, dataset='random', max_seq_len=32768, depth_init=True)
[2025-11-23 23:04:33,974578][I][ezpz/dist:1242:setup_torch_distributed] Using fw='ddp' with torch_{device,backend}= {cuda, nccl}
[2025-11-23 23:04:33,976497][I][ezpz/dist:1113:setup_torch_DDP] Caught MASTER_PORT=35815 from environment!
[2025-11-23 23:04:33,977091][I][ezpz/dist:1129:setup_torch_DDP] Using torch.distributed.init_process_group with
- master_addr='x3206c0s37b1n0.hsn.cm.polaris.alcf.anl.gov'
- master_port='35815'
- world_size=8
- rank=0
- local_rank=0
- timeout=datetime.timedelta(seconds=3600)
- backend='nccl'
[2025-11-23 23:04:33,977937][I][ezpz/dist:822:init_process_group] Calling torch.distributed.init_process_group_with: rank=0 world_size=8 backend=nccl
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank3]:[W1123 23:04:34.441118526 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank1]:[W1123 23:04:34.441850111 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank2]:[W1123 23:04:34.442422246 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:04:36,527519][I][ezpz/pbs:179:get_pbs_launch_cmd] ‚úÖ Using [8/8] GPUs [2 hosts] x [4 GPU/host]
[2025-11-23 23:04:36,530047][I][ezpz/dist:510:print_dist_setup] [device='cuda'][rank=0/7][local_rank=0/3][node=0/1]
[2025-11-23 23:04:36,530562][W][ezpz/dist:514:print_dist_setup] Using [8 / 8] available "cuda" devices !!
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank0]:[W1123 23:04:36.487046105 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank4]:[W1123 23:04:36.542136346 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank5]:[W1123 23:04:37.033506461 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank6]:[W1123 23:04:37.033523012 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank7]:[W1123 23:04:37.038577104 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:04:37,387346][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][1/7]
[2025-11-23 23:04:37,387342][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][3/7]
[2025-11-23 23:04:37,387656][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][5/7]
[2025-11-23 23:04:37,389019][I][ezpz/dist:1462:setup_torch] Using device='cuda' with backend='nccl' + 'nccl' for distributed training.
[2025-11-23 23:04:37,389716][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][0/7]
[2025-11-23 23:04:37,387649][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][6/7]
[2025-11-23 23:04:37,387657][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][7/7]
[2025-11-23 23:04:37,387336][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][2/7]
[2025-11-23 23:04:37,387648][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][4/7]
[2025-11-23 23:04:37,392401][I][examples/fsdp_tp:185:train] Device mesh created:
device_mesh=DeviceMesh('cuda', [[0], [1], [2], [3], [4], [5], [6], [7]], mesh_dim_names=('dp', 'tp'))
[2025-11-23 23:04:37,393395][I][examples/fsdp_tp:196:train] config:
ModelArgs(dim=256, n_layers=8, n_heads=32, n_kv_heads=4, vocab_size=32000, multiple_of=360, ffn_dim_multiplier=None, norm_eps=1e-05, batch_size=24, max_seq_len=32768, depth_init=True)
[2025-11-23 23:04:37,605217][I][examples/fsdp_tp:223:train] 
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Transformer                              --
‚îú‚îÄEmbedding: 1-1                         8,192,000
‚îú‚îÄModuleList: 1-2                        --
‚îÇ    ‚îî‚îÄTransformerBlock: 2-1             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-2             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-3             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-4             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-5             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-6             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-7             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-8             700,928
‚îú‚îÄRMSNorm: 1-3                           256
‚îú‚îÄLinear: 1-4                            8,192,000
=================================================================
Total params: 21,991,680
Trainable params: 21,991,680
Non-trainable params: 0
=================================================================
[2025-11-23 23:04:37,801676][I][examples/fsdp_tp:171:parallelize] Model after parallelization:
sharded_model=FullyShardedDataParallel(
  (_fsdp_wrapped_module): Transformer(
    (tok_embeddings): Embedding(32000, 256)
    (layers): ModuleList(
      (0-7): 8 x TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=256, out_features=256, bias=False)
          (wk): Linear(in_features=256, out_features=32, bias=False)
          (wv): Linear(in_features=256, out_features=32, bias=False)
          (wo): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=256, out_features=720, bias=False)
          (w2): Linear(in_features=720, out_features=256, bias=False)
          (w3): Linear(in_features=256, out_features=720, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
    )
    (norm): RMSNorm()
    (output): Linear(in_features=256, out_features=32000, bias=False)
  )
)

[2025-11-23 23:04:37,804398][I][examples/fsdp_tp:226:train] Creating optimizer=AdamW with lr=0.003
[2025-11-23 23:04:37,806842][I][examples/fsdp_tp:272:train] Starting 2D training...
[2025-11-23 23:04:38,540781][I][examples/fsdp_tp:308:train] epoch=0 iter=0 loss=10.854123 dt=0.732639 dtf=0.422089 dtb=0.310550
[2025-11-23 23:04:38,541590][I][examples/fsdp_tp:321:train] inp.shape=torch.Size([24, 2048])
[2025-11-23 23:04:39,749422][I][examples/fsdp_tp:308:train] epoch=0 iter=1 loss=10.845467 dt=1.135576 dtf=0.784515 dtb=0.351062
[2025-11-23 23:04:39,989082][I][examples/fsdp_tp:308:train] epoch=0 iter=2 loss=10.844533 dt=0.127304 dtf=0.050543 dtb=0.076761
[2025-11-23 23:04:40,229282][I][examples/fsdp_tp:308:train] epoch=0 iter=3 loss=10.835350 dt=0.126181 dtf=0.051131 dtb=0.075049
[2025-11-23 23:04:40,468759][I][examples/fsdp_tp:308:train] epoch=0 iter=4 loss=10.833801 dt=0.126258 dtf=0.050706 dtb=0.075552
[2025-11-23 23:04:40,673811][I][examples/fsdp_tp:308:train] epoch=0 iter=5 loss=10.821110 dt=0.183397 dtf=0.075031 dtb=0.108366
[2025-11-23 23:04:40,913740][I][examples/fsdp_tp:308:train] epoch=1 iter=0 loss=8.615651 dt=0.126303 dtf=0.051138 dtb=0.075165
[2025-11-23 23:04:41,153401][I][examples/fsdp_tp:308:train] epoch=1 iter=1 loss=9.281853 dt=0.125214 dtf=0.050574 dtb=0.074640
[2025-11-23 23:04:41,392606][I][examples/fsdp_tp:308:train] epoch=1 iter=2 loss=9.602365 dt=0.125834 dtf=0.050440 dtb=0.075394
[2025-11-23 23:04:41,632348][I][examples/fsdp_tp:308:train] epoch=1 iter=3 loss=9.779429 dt=0.125158 dtf=0.050679 dtb=0.074480
[2025-11-23 23:04:41,872045][I][examples/fsdp_tp:308:train] epoch=1 iter=4 loss=9.915690 dt=0.126241 dtf=0.050816 dtb=0.075425
[2025-11-23 23:04:42,021073][I][examples/fsdp_tp:308:train] epoch=1 iter=5 loss=8.676577 dt=0.126577 dtf=0.051116 dtb=0.075461
[2025-11-23 23:04:42,260728][I][examples/fsdp_tp:308:train] epoch=2 iter=0 loss=6.847059 dt=0.126280 dtf=0.050731 dtb=0.075550
[2025-11-23 23:04:42,500160][I][examples/fsdp_tp:308:train] epoch=2 iter=1 loss=7.662678 dt=0.125725 dtf=0.050649 dtb=0.075076
[2025-11-23 23:04:42,739430][I][examples/fsdp_tp:308:train] epoch=2 iter=2 loss=8.089717 dt=0.125747 dtf=0.050656 dtb=0.075091
[2025-11-23 23:04:42,979342][I][examples/fsdp_tp:308:train] epoch=2 iter=3 loss=8.390721 dt=0.125557 dtf=0.050695 dtb=0.074863
[2025-11-23 23:04:43,218844][I][examples/fsdp_tp:308:train] epoch=2 iter=4 loss=8.666764 dt=0.126171 dtf=0.050548 dtb=0.075623
[2025-11-23 23:04:43,368218][I][examples/fsdp_tp:308:train] epoch=2 iter=5 loss=5.619076 dt=0.126497 dtf=0.050931 dtb=0.075566
[2025-11-23 23:04:43,607760][I][examples/fsdp_tp:308:train] epoch=3 iter=0 loss=5.961712 dt=0.125241 dtf=0.050549 dtb=0.074691
[2025-11-23 23:04:43,847481][I][examples/fsdp_tp:308:train] epoch=3 iter=1 loss=6.831985 dt=0.125696 dtf=0.050867 dtb=0.074830
[2025-11-23 23:04:44,087019][I][examples/fsdp_tp:308:train] epoch=3 iter=2 loss=7.314924 dt=0.125754 dtf=0.050715 dtb=0.075039
[2025-11-23 23:04:44,326745][I][examples/fsdp_tp:308:train] epoch=3 iter=3 loss=7.635633 dt=0.126693 dtf=0.051098 dtb=0.075594
[2025-11-23 23:04:44,566182][I][examples/fsdp_tp:308:train] epoch=3 iter=4 loss=7.904795 dt=0.125754 dtf=0.050594 dtb=0.075160
[2025-11-23 23:04:44,715509][I][examples/fsdp_tp:308:train] epoch=3 iter=5 loss=3.624949 dt=0.126420 dtf=0.050746 dtb=0.075675
[2025-11-23 23:04:44,955619][I][examples/fsdp_tp:308:train] epoch=4 iter=0 loss=5.857514 dt=0.126286 dtf=0.050726 dtb=0.075560
[2025-11-23 23:04:45,194768][I][examples/fsdp_tp:308:train] epoch=4 iter=1 loss=6.741337 dt=0.125806 dtf=0.050475 dtb=0.075331
[2025-11-23 23:04:45,434566][I][examples/fsdp_tp:308:train] epoch=4 iter=2 loss=8.075135 dt=0.125806 dtf=0.050483 dtb=0.075322
[2025-11-23 23:04:45,674076][I][examples/fsdp_tp:308:train] epoch=4 iter=3 loss=8.775573 dt=0.125722 dtf=0.050504 dtb=0.075218
[2025-11-23 23:04:45,913724][I][examples/fsdp_tp:308:train] epoch=4 iter=4 loss=8.734982 dt=0.125975 dtf=0.050575 dtb=0.075399
[2025-11-23 23:04:46,062692][I][examples/fsdp_tp:308:train] epoch=4 iter=5 loss=4.724676 dt=0.125969 dtf=0.050564 dtb=0.075404
[2025-11-23 23:04:46,302125][I][examples/fsdp_tp:308:train] epoch=5 iter=0 loss=8.019737 dt=0.125708 dtf=0.050522 dtb=0.075186
[2025-11-23 23:04:46,541692][I][examples/fsdp_tp:308:train] epoch=5 iter=1 loss=8.660936 dt=0.125682 dtf=0.050593 dtb=0.075088
[2025-11-23 23:04:46,781391][I][examples/fsdp_tp:308:train] epoch=5 iter=2 loss=8.044227 dt=0.126468 dtf=0.050774 dtb=0.075695
[2025-11-23 23:04:47,021159][I][examples/fsdp_tp:308:train] epoch=5 iter=3 loss=9.758578 dt=0.125679 dtf=0.050594 dtb=0.075085
[2025-11-23 23:04:47,261184][I][examples/fsdp_tp:308:train] epoch=5 iter=4 loss=9.670624 dt=0.125911 dtf=0.050603 dtb=0.075308
[2025-11-23 23:04:47,410233][I][examples/fsdp_tp:308:train] epoch=5 iter=5 loss=8.285501 dt=0.125710 dtf=0.050581 dtb=0.075129
[2025-11-23 23:04:47,649733][I][examples/fsdp_tp:308:train] epoch=6 iter=0 loss=9.387978 dt=0.125730 dtf=0.050656 dtb=0.075074
[2025-11-23 23:04:47,889190][I][examples/fsdp_tp:308:train] epoch=6 iter=1 loss=9.996939 dt=0.125215 dtf=0.050318 dtb=0.074897
[2025-11-23 23:04:48,129043][I][examples/fsdp_tp:308:train] epoch=6 iter=2 loss=10.267781 dt=0.126209 dtf=0.050704 dtb=0.075505
[2025-11-23 23:04:48,369120][I][examples/fsdp_tp:308:train] epoch=6 iter=3 loss=11.044238 dt=0.125211 dtf=0.050722 dtb=0.074489
[2025-11-23 23:04:48,608456][I][examples/fsdp_tp:308:train] epoch=6 iter=4 loss=11.385802 dt=0.125707 dtf=0.050420 dtb=0.075287
[2025-11-23 23:04:48,757373][I][examples/fsdp_tp:308:train] epoch=6 iter=5 loss=10.394039 dt=0.125733 dtf=0.050463 dtb=0.075269
[2025-11-23 23:04:48,996953][I][examples/fsdp_tp:308:train] epoch=7 iter=0 loss=10.848736 dt=0.125803 dtf=0.050247 dtb=0.075556
[2025-11-23 23:04:49,236432][I][examples/fsdp_tp:308:train] epoch=7 iter=1 loss=10.997123 dt=0.125835 dtf=0.050512 dtb=0.075323
[2025-11-23 23:04:49,475812][I][examples/fsdp_tp:308:train] epoch=7 iter=2 loss=11.225536 dt=0.125925 dtf=0.050630 dtb=0.075294
[2025-11-23 23:04:49,715656][I][examples/fsdp_tp:308:train] epoch=7 iter=3 loss=11.369884 dt=0.126085 dtf=0.050666 dtb=0.075419
[2025-11-23 23:04:49,955245][I][examples/fsdp_tp:308:train] epoch=7 iter=4 loss=11.639510 dt=0.125689 dtf=0.050430 dtb=0.075260
[2025-11-23 23:04:50,104705][I][examples/fsdp_tp:308:train] epoch=7 iter=5 loss=10.667651 dt=0.125912 dtf=0.050566 dtb=0.075346
[2025-11-23 23:04:50,344098][I][examples/fsdp_tp:308:train] epoch=8 iter=0 loss=11.156494 dt=0.125321 dtf=0.050366 dtb=0.074955
[2025-11-23 23:04:50,583628][I][examples/fsdp_tp:308:train] epoch=8 iter=1 loss=11.220703 dt=0.125847 dtf=0.050955 dtb=0.074892
[2025-11-23 23:04:50,823068][I][examples/fsdp_tp:308:train] epoch=8 iter=2 loss=11.338223 dt=0.125231 dtf=0.050411 dtb=0.074820
[2025-11-23 23:04:51,062346][I][examples/fsdp_tp:308:train] epoch=8 iter=3 loss=11.639129 dt=0.126264 dtf=0.050635 dtb=0.075630
[2025-11-23 23:04:51,301813][I][examples/fsdp_tp:308:train] epoch=8 iter=4 loss=11.540756 dt=0.125843 dtf=0.050629 dtb=0.075214
[2025-11-23 23:04:51,450578][I][examples/fsdp_tp:308:train] epoch=8 iter=5 loss=10.987671 dt=0.125771 dtf=0.050730 dtb=0.075041
[2025-11-23 23:04:51,690425][I][examples/fsdp_tp:308:train] epoch=9 iter=0 loss=11.474111 dt=0.125878 dtf=0.050554 dtb=0.075323
[2025-11-23 23:04:51,930254][I][examples/fsdp_tp:308:train] epoch=9 iter=1 loss=11.778577 dt=0.125898 dtf=0.050644 dtb=0.075253
[2025-11-23 23:04:52,170049][I][examples/fsdp_tp:308:train] epoch=9 iter=2 loss=12.156555 dt=0.125688 dtf=0.050575 dtb=0.075113
[2025-11-23 23:04:52,409653][I][examples/fsdp_tp:308:train] epoch=9 iter=3 loss=12.050159 dt=0.126255 dtf=0.050675 dtb=0.075579
[2025-11-23 23:04:52,649338][I][examples/fsdp_tp:308:train] epoch=9 iter=4 loss=12.191865 dt=0.126315 dtf=0.050727 dtb=0.075588
[2025-11-23 23:04:52,798389][I][examples/fsdp_tp:308:train] epoch=9 iter=5 loss=11.708963 dt=0.126072 dtf=0.050724 dtb=0.075348
[2025-11-23 23:04:53,038043][I][examples/fsdp_tp:308:train] epoch=10 iter=0 loss=12.648824 dt=0.125752 dtf=0.050537 dtb=0.075215
[2025-11-23 23:04:53,277621][I][examples/fsdp_tp:308:train] epoch=10 iter=1 loss=12.790606 dt=0.126709 dtf=0.051232 dtb=0.075477
[2025-11-23 23:04:53,517147][I][examples/fsdp_tp:308:train] epoch=10 iter=2 loss=13.252995 dt=0.125628 dtf=0.050600 dtb=0.075028
[2025-11-23 23:04:53,757066][I][examples/fsdp_tp:308:train] epoch=10 iter=3 loss=13.395813 dt=0.126970 dtf=0.050768 dtb=0.076202
[2025-11-23 23:04:53,996441][I][examples/fsdp_tp:308:train] epoch=10 iter=4 loss=13.472701 dt=0.126017 dtf=0.050989 dtb=0.075028
[2025-11-23 23:04:54,143813][I][examples/fsdp_tp:308:train] epoch=10 iter=5 loss=13.282071 dt=0.126510 dtf=0.050610 dtb=0.075900
[2025-11-23 23:04:54,381457][I][examples/fsdp_tp:308:train] epoch=11 iter=0 loss=13.983212 dt=0.125796 dtf=0.050468 dtb=0.075328
[2025-11-23 23:04:54,621838][I][examples/fsdp_tp:308:train] epoch=11 iter=1 loss=14.060382 dt=0.126794 dtf=0.050689 dtb=0.076105
[2025-11-23 23:04:54,862094][I][examples/fsdp_tp:308:train] epoch=11 iter=2 loss=14.282741 dt=0.127392 dtf=0.050990 dtb=0.076402
[2025-11-23 23:04:55,102031][I][examples/fsdp_tp:308:train] epoch=11 iter=3 loss=14.508252 dt=0.127321 dtf=0.051337 dtb=0.075984
[2025-11-23 23:04:55,341820][I][examples/fsdp_tp:308:train] epoch=11 iter=4 loss=14.278487 dt=0.126100 dtf=0.050698 dtb=0.075402
[2025-11-23 23:04:55,491408][I][examples/fsdp_tp:308:train] epoch=11 iter=5 loss=13.847195 dt=0.127164 dtf=0.051433 dtb=0.075731
[2025-11-23 23:04:55,730713][I][examples/fsdp_tp:308:train] epoch=12 iter=0 loss=14.711774 dt=0.126046 dtf=0.050875 dtb=0.075171
[2025-11-23 23:04:56,102876][I][examples/fsdp_tp:308:train] epoch=12 iter=1 loss=14.573737 dt=0.126323 dtf=0.051156 dtb=0.075166
[2025-11-23 23:04:56,343043][I][examples/fsdp_tp:308:train] epoch=12 iter=2 loss=14.653500 dt=0.125506 dtf=0.049997 dtb=0.075509
[2025-11-23 23:04:56,582608][I][examples/fsdp_tp:308:train] epoch=12 iter=3 loss=14.843442 dt=0.125768 dtf=0.050913 dtb=0.074855
[2025-11-23 23:04:56,822553][I][examples/fsdp_tp:308:train] epoch=12 iter=4 loss=14.354047 dt=0.126443 dtf=0.050745 dtb=0.075698
[2025-11-23 23:04:56,971710][I][examples/fsdp_tp:308:train] epoch=12 iter=5 loss=13.779200 dt=0.126301 dtf=0.050884 dtb=0.075417
[2025-11-23 23:04:57,211611][I][examples/fsdp_tp:308:train] epoch=13 iter=0 loss=14.557897 dt=0.125551 dtf=0.050669 dtb=0.074883
[2025-11-23 23:04:57,451217][I][examples/fsdp_tp:308:train] epoch=13 iter=1 loss=14.420066 dt=0.125605 dtf=0.050639 dtb=0.074966
[2025-11-23 23:04:57,691145][I][examples/fsdp_tp:308:train] epoch=13 iter=2 loss=14.605209 dt=0.125792 dtf=0.050538 dtb=0.075254
[2025-11-23 23:04:57,930596][I][examples/fsdp_tp:308:train] epoch=13 iter=3 loss=14.853255 dt=0.125899 dtf=0.050714 dtb=0.075185
[2025-11-23 23:04:58,170118][I][examples/fsdp_tp:308:train] epoch=13 iter=4 loss=14.476089 dt=0.126102 dtf=0.050718 dtb=0.075384
[2025-11-23 23:04:58,319252][I][examples/fsdp_tp:308:train] epoch=13 iter=5 loss=14.107607 dt=0.126226 dtf=0.051141 dtb=0.075084
[2025-11-23 23:04:58,559050][I][examples/fsdp_tp:308:train] epoch=14 iter=0 loss=14.531123 dt=0.125775 dtf=0.050650 dtb=0.075125
[2025-11-23 23:04:58,799036][I][examples/fsdp_tp:308:train] epoch=14 iter=1 loss=14.510612 dt=0.125572 dtf=0.050680 dtb=0.074892
[2025-11-23 23:04:59,038784][I][examples/fsdp_tp:308:train] epoch=14 iter=2 loss=14.561831 dt=0.126084 dtf=0.050505 dtb=0.075579
[2025-11-23 23:04:59,278536][I][examples/fsdp_tp:308:train] epoch=14 iter=3 loss=14.721431 dt=0.126312 dtf=0.050767 dtb=0.075546
[2025-11-23 23:04:59,518316][I][examples/fsdp_tp:308:train] epoch=14 iter=4 loss=14.562434 dt=0.126175 dtf=0.050800 dtb=0.075375
[2025-11-23 23:04:59,667195][I][examples/fsdp_tp:308:train] epoch=14 iter=5 loss=14.359526 dt=0.126060 dtf=0.050857 dtb=0.075203
[2025-11-23 23:04:59,906935][I][examples/fsdp_tp:308:train] epoch=15 iter=0 loss=14.539471 dt=0.126077 dtf=0.050624 dtb=0.075452
[2025-11-23 23:05:00,146832][I][examples/fsdp_tp:308:train] epoch=15 iter=1 loss=14.787434 dt=0.126055 dtf=0.050515 dtb=0.075540
[2025-11-23 23:05:00,386539][I][examples/fsdp_tp:308:train] epoch=15 iter=2 loss=14.551082 dt=0.126079 dtf=0.050479 dtb=0.075600
[2025-11-23 23:05:00,626057][I][examples/fsdp_tp:308:train] epoch=15 iter=3 loss=14.642006 dt=0.126013 dtf=0.050521 dtb=0.075491
[2025-11-23 23:05:00,866038][I][examples/fsdp_tp:308:train] epoch=15 iter=4 loss=14.733083 dt=0.126020 dtf=0.050583 dtb=0.075437
[2025-11-23 23:05:01,159029][I][examples/fsdp_tp:308:train] epoch=15 iter=5 loss=14.566296 dt=0.273890 dtf=0.197151 dtb=0.076738
[2025-11-23 23:05:01,399262][I][examples/fsdp_tp:308:train] epoch=16 iter=0 loss=14.660538 dt=0.125687 dtf=0.050132 dtb=0.075555
[2025-11-23 23:05:01,639344][I][examples/fsdp_tp:308:train] epoch=16 iter=1 loss=15.111739 dt=0.126056 dtf=0.050797 dtb=0.075258
[2025-11-23 23:05:01,879232][I][examples/fsdp_tp:308:train] epoch=16 iter=2 loss=14.681973 dt=0.127039 dtf=0.051299 dtb=0.075739
[2025-11-23 23:05:02,119106][I][examples/fsdp_tp:308:train] epoch=16 iter=3 loss=14.730285 dt=0.126330 dtf=0.051099 dtb=0.075231
[2025-11-23 23:05:02,358850][I][examples/fsdp_tp:308:train] epoch=16 iter=4 loss=14.997078 dt=0.126906 dtf=0.051081 dtb=0.075825
[2025-11-23 23:05:02,507849][I][examples/fsdp_tp:308:train] epoch=16 iter=5 loss=14.751558 dt=0.126486 dtf=0.050924 dtb=0.075562
[2025-11-23 23:05:02,747595][I][examples/fsdp_tp:308:train] epoch=17 iter=0 loss=14.865439 dt=0.125937 dtf=0.051017 dtb=0.074920
[2025-11-23 23:05:02,987321][I][examples/fsdp_tp:308:train] epoch=17 iter=1 loss=15.311492 dt=0.126062 dtf=0.050913 dtb=0.075148
[2025-11-23 23:05:03,227131][I][examples/fsdp_tp:308:train] epoch=17 iter=2 loss=14.973460 dt=0.126506 dtf=0.051221 dtb=0.075285
[2025-11-23 23:05:03,466456][I][examples/fsdp_tp:308:train] epoch=17 iter=3 loss=15.009029 dt=0.126154 dtf=0.050827 dtb=0.075327
[2025-11-23 23:05:03,706188][I][examples/fsdp_tp:308:train] epoch=17 iter=4 loss=15.373019 dt=0.126537 dtf=0.050994 dtb=0.075544
[2025-11-23 23:05:03,855838][I][examples/fsdp_tp:308:train] epoch=17 iter=5 loss=15.020013 dt=0.126267 dtf=0.050750 dtb=0.075517
[2025-11-23 23:05:04,235213][I][examples/fsdp_tp:308:train] epoch=18 iter=0 loss=15.185716 dt=0.126111 dtf=0.050681 dtb=0.075430
[2025-11-23 23:05:04,474916][I][examples/fsdp_tp:308:train] epoch=18 iter=1 loss=15.428208 dt=0.126507 dtf=0.050674 dtb=0.075833
[2025-11-23 23:05:04,714730][I][examples/fsdp_tp:308:train] epoch=18 iter=2 loss=15.283814 dt=0.126156 dtf=0.050526 dtb=0.075630
[2025-11-23 23:05:04,954485][I][examples/fsdp_tp:308:train] epoch=18 iter=3 loss=15.283410 dt=0.125847 dtf=0.050677 dtb=0.075171
[2025-11-23 23:05:05,194573][I][examples/fsdp_tp:308:train] epoch=18 iter=4 loss=15.564124 dt=0.126318 dtf=0.050699 dtb=0.075620
[2025-11-23 23:05:05,343621][I][examples/fsdp_tp:308:train] epoch=18 iter=5 loss=15.063519 dt=0.126578 dtf=0.050970 dtb=0.075608
[2025-11-23 23:05:05,583897][I][examples/fsdp_tp:308:train] epoch=19 iter=0 loss=15.147641 dt=0.125720 dtf=0.050692 dtb=0.075028
[2025-11-23 23:05:05,823570][I][examples/fsdp_tp:308:train] epoch=19 iter=1 loss=15.190665 dt=0.126591 dtf=0.051108 dtb=0.075483
[2025-11-23 23:05:06,063214][I][examples/fsdp_tp:308:train] epoch=19 iter=2 loss=15.151441 dt=0.126484 dtf=0.050879 dtb=0.075605
[2025-11-23 23:05:06,303203][I][examples/fsdp_tp:308:train] epoch=19 iter=3 loss=15.202232 dt=0.126325 dtf=0.051090 dtb=0.075234
[2025-11-23 23:05:06,542943][I][examples/fsdp_tp:308:train] epoch=19 iter=4 loss=15.384778 dt=0.126591 dtf=0.050896 dtb=0.075696
[2025-11-23 23:05:06,692306][I][examples/fsdp_tp:308:train] epoch=19 iter=5 loss=14.854177 dt=0.126321 dtf=0.050801 dtb=0.075519
[2025-11-23 23:05:06,932030][I][examples/fsdp_tp:308:train] epoch=20 iter=0 loss=15.036433 dt=0.127338 dtf=0.051352 dtb=0.075985
[2025-11-23 23:05:07,172054][I][examples/fsdp_tp:308:train] epoch=20 iter=1 loss=15.091929 dt=0.126059 dtf=0.050902 dtb=0.075156
[2025-11-23 23:05:07,411800][I][examples/fsdp_tp:308:train] epoch=20 iter=2 loss=15.022095 dt=0.126676 dtf=0.050805 dtb=0.075872
[2025-11-23 23:05:07,652277][I][examples/fsdp_tp:308:train] epoch=20 iter=3 loss=14.960350 dt=0.126204 dtf=0.051244 dtb=0.074960
[2025-11-23 23:05:07,892428][I][examples/fsdp_tp:308:train] epoch=20 iter=4 loss=14.902541 dt=0.126798 dtf=0.050964 dtb=0.075834
[2025-11-23 23:05:08,041460][I][examples/fsdp_tp:308:train] epoch=20 iter=5 loss=14.301610 dt=0.126607 dtf=0.050965 dtb=0.075642
[2025-11-23 23:05:08,281402][I][examples/fsdp_tp:308:train] epoch=21 iter=0 loss=14.478213 dt=0.125814 dtf=0.050837 dtb=0.074977
[2025-11-23 23:05:08,521610][I][examples/fsdp_tp:308:train] epoch=21 iter=1 loss=14.373883 dt=0.126019 dtf=0.050906 dtb=0.075113
[2025-11-23 23:05:08,761488][I][examples/fsdp_tp:308:train] epoch=21 iter=2 loss=14.526233 dt=0.126282 dtf=0.050752 dtb=0.075530
[2025-11-23 23:05:09,000908][I][examples/fsdp_tp:308:train] epoch=21 iter=3 loss=14.444100 dt=0.126153 dtf=0.050999 dtb=0.075154
[2025-11-23 23:05:09,241078][I][examples/fsdp_tp:308:train] epoch=21 iter=4 loss=14.543925 dt=0.126369 dtf=0.050995 dtb=0.075374
[2025-11-23 23:05:09,389547][I][examples/fsdp_tp:308:train] epoch=21 iter=5 loss=14.013285 dt=0.127346 dtf=0.051559 dtb=0.075787
[2025-11-23 23:05:09,629125][I][examples/fsdp_tp:308:train] epoch=22 iter=0 loss=14.764554 dt=0.126868 dtf=0.051219 dtb=0.075649
[2025-11-23 23:05:09,868895][I][examples/fsdp_tp:308:train] epoch=22 iter=1 loss=14.574906 dt=0.126576 dtf=0.050984 dtb=0.075592
[2025-11-23 23:05:10,108741][I][examples/fsdp_tp:308:train] epoch=22 iter=2 loss=14.697280 dt=0.127005 dtf=0.051104 dtb=0.075901
[2025-11-23 23:05:10,348851][I][examples/fsdp_tp:308:train] epoch=22 iter=3 loss=14.311546 dt=0.126574 dtf=0.051012 dtb=0.075562
[2025-11-23 23:05:10,588674][I][examples/fsdp_tp:308:train] epoch=22 iter=4 loss=14.256368 dt=0.126391 dtf=0.050641 dtb=0.075750
[2025-11-23 23:05:10,738008][I][examples/fsdp_tp:308:train] epoch=22 iter=5 loss=13.449631 dt=0.126790 dtf=0.050783 dtb=0.076007
[2025-11-23 23:05:10,977719][I][examples/fsdp_tp:308:train] epoch=23 iter=0 loss=14.433632 dt=0.126227 dtf=0.050934 dtb=0.075292
[2025-11-23 23:05:11,217799][I][examples/fsdp_tp:308:train] epoch=23 iter=1 loss=14.458782 dt=0.126014 dtf=0.050765 dtb=0.075249
[2025-11-23 23:05:11,458081][I][examples/fsdp_tp:308:train] epoch=23 iter=2 loss=14.646836 dt=0.126414 dtf=0.051032 dtb=0.075382
[2025-11-23 23:05:11,697900][I][examples/fsdp_tp:308:train] epoch=23 iter=3 loss=14.678346 dt=0.126050 dtf=0.050904 dtb=0.075147
[2025-11-23 23:05:11,937530][I][examples/fsdp_tp:308:train] epoch=23 iter=4 loss=15.053639 dt=0.126728 dtf=0.050923 dtb=0.075805
[2025-11-23 23:05:12,086976][I][examples/fsdp_tp:308:train] epoch=23 iter=5 loss=14.380292 dt=0.126652 dtf=0.050931 dtb=0.075721
[2025-11-23 23:05:12,326105][I][examples/fsdp_tp:308:train] epoch=24 iter=0 loss=15.706033 dt=0.125670 dtf=0.050706 dtb=0.074965
[2025-11-23 23:05:12,565907][I][examples/fsdp_tp:308:train] epoch=24 iter=1 loss=15.962002 dt=0.126426 dtf=0.050985 dtb=0.075440
[2025-11-23 23:05:12,805744][I][examples/fsdp_tp:308:train] epoch=24 iter=2 loss=15.766917 dt=0.126221 dtf=0.050819 dtb=0.075402
[2025-11-23 23:05:13,045589][I][examples/fsdp_tp:308:train] epoch=24 iter=3 loss=15.763210 dt=0.126598 dtf=0.051137 dtb=0.075460
[2025-11-23 23:05:13,285923][I][examples/fsdp_tp:308:train] epoch=24 iter=4 loss=15.871860 dt=0.126148 dtf=0.050761 dtb=0.075387
[2025-11-23 23:05:13,434790][I][examples/fsdp_tp:308:train] epoch=24 iter=5 loss=14.927031 dt=0.126720 dtf=0.050701 dtb=0.076019
[2025-11-23 23:05:13,674497][I][examples/fsdp_tp:308:train] epoch=25 iter=0 loss=15.953465 dt=0.126293 dtf=0.050577 dtb=0.075716
[2025-11-23 23:05:13,913875][I][examples/fsdp_tp:308:train] epoch=25 iter=1 loss=16.016096 dt=0.126783 dtf=0.050958 dtb=0.075825
[2025-11-23 23:05:14,153907][I][examples/fsdp_tp:308:train] epoch=25 iter=2 loss=15.487727 dt=0.126233 dtf=0.050858 dtb=0.075375
[2025-11-23 23:05:14,393807][I][examples/fsdp_tp:308:train] epoch=25 iter=3 loss=15.378647 dt=0.126693 dtf=0.051108 dtb=0.075585
[2025-11-23 23:05:14,633299][I][examples/fsdp_tp:308:train] epoch=25 iter=4 loss=15.224462 dt=0.126426 dtf=0.050718 dtb=0.075708
[2025-11-23 23:05:14,782513][I][examples/fsdp_tp:308:train] epoch=25 iter=5 loss=14.284967 dt=0.126515 dtf=0.050948 dtb=0.075567
[2025-11-23 23:05:15,022202][I][examples/fsdp_tp:308:train] epoch=26 iter=0 loss=15.291893 dt=0.126157 dtf=0.051045 dtb=0.075112
[2025-11-23 23:05:15,262208][I][examples/fsdp_tp:308:train] epoch=26 iter=1 loss=15.340535 dt=0.126548 dtf=0.050972 dtb=0.075576
[2025-11-23 23:05:15,501892][I][examples/fsdp_tp:308:train] epoch=26 iter=2 loss=15.243408 dt=0.126263 dtf=0.050622 dtb=0.075641
[2025-11-23 23:05:15,741736][I][examples/fsdp_tp:308:train] epoch=26 iter=3 loss=15.587730 dt=0.126888 dtf=0.051137 dtb=0.075751
[2025-11-23 23:05:15,981447][I][examples/fsdp_tp:308:train] epoch=26 iter=4 loss=15.844054 dt=0.126313 dtf=0.050759 dtb=0.075554
[2025-11-23 23:05:16,130661][I][examples/fsdp_tp:308:train] epoch=26 iter=5 loss=15.589709 dt=0.126521 dtf=0.050672 dtb=0.075849
[2025-11-23 23:05:16,370448][I][examples/fsdp_tp:308:train] epoch=27 iter=0 loss=17.097456 dt=0.126130 dtf=0.050582 dtb=0.075548
[2025-11-23 23:05:16,610281][I][examples/fsdp_tp:308:train] epoch=27 iter=1 loss=17.406502 dt=0.126763 dtf=0.050781 dtb=0.075981
[2025-11-23 23:05:16,850165][I][examples/fsdp_tp:308:train] epoch=27 iter=2 loss=17.860863 dt=0.127109 dtf=0.051131 dtb=0.075978
[2025-11-23 23:05:17,090273][I][examples/fsdp_tp:308:train] epoch=27 iter=3 loss=18.237413 dt=0.126437 dtf=0.050791 dtb=0.075646
[2025-11-23 23:05:17,330358][I][examples/fsdp_tp:308:train] epoch=27 iter=4 loss=18.239067 dt=0.126039 dtf=0.050673 dtb=0.075366
[2025-11-23 23:05:17,480041][I][examples/fsdp_tp:308:train] epoch=27 iter=5 loss=17.604601 dt=0.126570 dtf=0.050834 dtb=0.075736
[2025-11-23 23:05:17,719147][I][examples/fsdp_tp:308:train] epoch=28 iter=0 loss=18.735876 dt=0.126028 dtf=0.050542 dtb=0.075486
[2025-11-23 23:05:17,958995][I][examples/fsdp_tp:308:train] epoch=28 iter=1 loss=18.527369 dt=0.126039 dtf=0.050717 dtb=0.075321
[2025-11-23 23:05:18,198873][I][examples/fsdp_tp:308:train] epoch=28 iter=2 loss=18.499664 dt=0.126759 dtf=0.051035 dtb=0.075724
[2025-11-23 23:05:18,438771][I][examples/fsdp_tp:308:train] epoch=28 iter=3 loss=18.398674 dt=0.126794 dtf=0.050932 dtb=0.075861
[2025-11-23 23:05:18,678794][I][examples/fsdp_tp:308:train] epoch=28 iter=4 loss=17.917948 dt=0.126737 dtf=0.050748 dtb=0.075989
[2025-11-23 23:05:18,827862][I][examples/fsdp_tp:308:train] epoch=28 iter=5 loss=16.937494 dt=0.126869 dtf=0.050857 dtb=0.076012
[2025-11-23 23:05:19,067576][I][examples/fsdp_tp:308:train] epoch=29 iter=0 loss=17.581295 dt=0.126269 dtf=0.051252 dtb=0.075017
[2025-11-23 23:05:19,306991][I][examples/fsdp_tp:308:train] epoch=29 iter=1 loss=17.277782 dt=0.126206 dtf=0.050682 dtb=0.075524
[2025-11-23 23:05:19,546359][I][examples/fsdp_tp:308:train] epoch=29 iter=2 loss=17.020481 dt=0.126235 dtf=0.050798 dtb=0.075437
[2025-11-23 23:05:19,786288][I][examples/fsdp_tp:308:train] epoch=29 iter=3 loss=17.122726 dt=0.126546 dtf=0.050961 dtb=0.075585
[2025-11-23 23:05:20,026580][I][examples/fsdp_tp:308:train] epoch=29 iter=4 loss=16.934660 dt=0.126361 dtf=0.050897 dtb=0.075464
[2025-11-23 23:05:20,175760][I][examples/fsdp_tp:308:train] epoch=29 iter=5 loss=16.522621 dt=0.126299 dtf=0.050788 dtb=0.075511
[2025-11-23 23:05:20,415528][I][examples/fsdp_tp:308:train] epoch=30 iter=0 loss=17.432455 dt=0.125774 dtf=0.050797 dtb=0.074977
[2025-11-23 23:05:20,654608][I][examples/fsdp_tp:308:train] epoch=30 iter=1 loss=17.802088 dt=0.125950 dtf=0.051015 dtb=0.074935
[2025-11-23 23:05:20,893328][I][examples/fsdp_tp:308:train] epoch=30 iter=2 loss=17.820269 dt=0.126039 dtf=0.050674 dtb=0.075366
[2025-11-23 23:05:21,133304][I][examples/fsdp_tp:308:train] epoch=30 iter=3 loss=18.379358 dt=0.126730 dtf=0.051145 dtb=0.075585
[2025-11-23 23:05:21,373256][I][examples/fsdp_tp:308:train] epoch=30 iter=4 loss=18.375902 dt=0.125936 dtf=0.050768 dtb=0.075168
[2025-11-23 23:05:21,522915][I][examples/fsdp_tp:308:train] epoch=30 iter=5 loss=18.168268 dt=0.126354 dtf=0.050618 dtb=0.075736
[2025-11-23 23:05:21,762630][I][examples/fsdp_tp:308:train] epoch=31 iter=0 loss=18.751032 dt=0.126487 dtf=0.050715 dtb=0.075772
[2025-11-23 23:05:22,002253][I][examples/fsdp_tp:308:train] epoch=31 iter=1 loss=19.125578 dt=0.127007 dtf=0.051006 dtb=0.076002
[2025-11-23 23:05:22,242239][I][examples/fsdp_tp:308:train] epoch=31 iter=2 loss=18.881720 dt=0.126478 dtf=0.051157 dtb=0.075321
[2025-11-23 23:05:22,482598][I][examples/fsdp_tp:308:train] epoch=31 iter=3 loss=19.314034 dt=0.126551 dtf=0.050933 dtb=0.075618
[2025-11-23 23:05:22,722128][I][examples/fsdp_tp:308:train] epoch=31 iter=4 loss=18.972557 dt=0.127311 dtf=0.050764 dtb=0.076547
[2025-11-23 23:05:22,871612][I][examples/fsdp_tp:308:train] epoch=31 iter=5 loss=18.546314 dt=0.126837 dtf=0.050761 dtb=0.076076
[2025-11-23 23:05:23,111224][I][examples/fsdp_tp:308:train] epoch=32 iter=0 loss=18.528345 dt=0.126368 dtf=0.050641 dtb=0.075728
[2025-11-23 23:05:23,351220][I][examples/fsdp_tp:308:train] epoch=32 iter=1 loss=18.604065 dt=0.126333 dtf=0.051107 dtb=0.075226
[2025-11-23 23:05:23,590809][I][examples/fsdp_tp:308:train] epoch=32 iter=2 loss=18.045008 dt=0.127102 dtf=0.051236 dtb=0.075867
[2025-11-23 23:05:23,830406][I][examples/fsdp_tp:308:train] epoch=32 iter=3 loss=18.255960 dt=0.126573 dtf=0.050845 dtb=0.075727
[2025-11-23 23:05:24,069843][I][examples/fsdp_tp:308:train] epoch=32 iter=4 loss=17.733500 dt=0.127109 dtf=0.051103 dtb=0.076006
[2025-11-23 23:05:24,219078][I][examples/fsdp_tp:308:train] epoch=32 iter=5 loss=17.311741 dt=0.126771 dtf=0.050843 dtb=0.075928
[2025-11-23 23:05:24,459094][I][examples/fsdp_tp:308:train] epoch=33 iter=0 loss=17.108763 dt=0.126558 dtf=0.050855 dtb=0.075703
[2025-11-23 23:05:24,699263][I][examples/fsdp_tp:308:train] epoch=33 iter=1 loss=17.203613 dt=0.127008 dtf=0.051193 dtb=0.075815
[2025-11-23 23:05:24,939491][I][examples/fsdp_tp:308:train] epoch=33 iter=2 loss=16.740274 dt=0.126641 dtf=0.051109 dtb=0.075532
[2025-11-23 23:05:25,179558][I][examples/fsdp_tp:308:train] epoch=33 iter=3 loss=17.009298 dt=0.126065 dtf=0.050928 dtb=0.075137
[2025-11-23 23:05:25,419582][I][examples/fsdp_tp:308:train] epoch=33 iter=4 loss=16.735415 dt=0.123578 dtf=0.049979 dtb=0.073599
[2025-11-23 23:05:25,569023][I][examples/fsdp_tp:308:train] epoch=33 iter=5 loss=16.302301 dt=0.123084 dtf=0.049361 dtb=0.073723
[2025-11-23 23:05:25,809039][I][examples/fsdp_tp:308:train] epoch=34 iter=0 loss=16.391516 dt=0.122341 dtf=0.049123 dtb=0.073218
[2025-11-23 23:05:26,048860][I][examples/fsdp_tp:308:train] epoch=34 iter=1 loss=16.522882 dt=0.122332 dtf=0.049075 dtb=0.073257
[2025-11-23 23:05:26,288390][I][examples/fsdp_tp:308:train] epoch=34 iter=2 loss=16.114418 dt=0.122289 dtf=0.049170 dtb=0.073118
[2025-11-23 23:05:26,527967][I][examples/fsdp_tp:308:train] epoch=34 iter=3 loss=16.294462 dt=0.122157 dtf=0.049131 dtb=0.073026
[2025-11-23 23:05:26,767931][I][examples/fsdp_tp:308:train] epoch=34 iter=4 loss=16.123640 dt=0.122719 dtf=0.049176 dtb=0.073543
[2025-11-23 23:05:26,916873][I][examples/fsdp_tp:308:train] epoch=34 iter=5 loss=15.385477 dt=0.122501 dtf=0.048916 dtb=0.073585
[2025-11-23 23:05:27,157161][I][examples/fsdp_tp:308:train] epoch=35 iter=0 loss=15.774254 dt=0.122469 dtf=0.049093 dtb=0.073376
[2025-11-23 23:05:27,396974][I][examples/fsdp_tp:308:train] epoch=35 iter=1 loss=15.833240 dt=0.122312 dtf=0.049248 dtb=0.073064
[2025-11-23 23:05:27,636864][I][examples/fsdp_tp:308:train] epoch=35 iter=2 loss=15.505695 dt=0.122693 dtf=0.049248 dtb=0.073445
[2025-11-23 23:05:27,877439][I][examples/fsdp_tp:308:train] epoch=35 iter=3 loss=15.576996 dt=0.122086 dtf=0.049193 dtb=0.072893
[2025-11-23 23:05:28,116996][I][examples/fsdp_tp:308:train] epoch=35 iter=4 loss=15.475731 dt=0.122512 dtf=0.049178 dtb=0.073334
[2025-11-23 23:05:28,266340][I][examples/fsdp_tp:308:train] epoch=35 iter=5 loss=14.541103 dt=0.122399 dtf=0.049047 dtb=0.073352
[2025-11-23 23:05:28,505927][I][examples/fsdp_tp:308:train] epoch=36 iter=0 loss=15.239766 dt=0.122078 dtf=0.049048 dtb=0.073030
[2025-11-23 23:05:28,746003][I][examples/fsdp_tp:308:train] epoch=36 iter=1 loss=15.233777 dt=0.122131 dtf=0.048946 dtb=0.073185
[2025-11-23 23:05:28,986233][I][examples/fsdp_tp:308:train] epoch=36 iter=2 loss=15.061149 dt=0.122445 dtf=0.049116 dtb=0.073329
[2025-11-23 23:05:29,226185][I][examples/fsdp_tp:308:train] epoch=36 iter=3 loss=15.026409 dt=0.122147 dtf=0.049077 dtb=0.073070
[2025-11-23 23:05:29,466247][I][examples/fsdp_tp:308:train] epoch=36 iter=4 loss=14.942997 dt=0.122430 dtf=0.049028 dtb=0.073402
[2025-11-23 23:05:29,615210][I][examples/fsdp_tp:308:train] epoch=36 iter=5 loss=14.091723 dt=0.122687 dtf=0.049163 dtb=0.073524
[2025-11-23 23:05:29,855221][I][examples/fsdp_tp:308:train] epoch=37 iter=0 loss=14.768620 dt=0.123345 dtf=0.049172 dtb=0.074172
[2025-11-23 23:05:30,095352][I][examples/fsdp_tp:308:train] epoch=37 iter=1 loss=14.615504 dt=0.122866 dtf=0.049035 dtb=0.073831
[2025-11-23 23:05:30,335200][I][examples/fsdp_tp:308:train] epoch=37 iter=2 loss=14.576480 dt=0.122677 dtf=0.049148 dtb=0.073529
[2025-11-23 23:05:30,575111][I][examples/fsdp_tp:308:train] epoch=37 iter=3 loss=14.464237 dt=0.122450 dtf=0.049131 dtb=0.073320
[2025-11-23 23:05:30,815258][I][examples/fsdp_tp:308:train] epoch=37 iter=4 loss=14.400208 dt=0.122834 dtf=0.049119 dtb=0.073715
[2025-11-23 23:05:30,964791][I][examples/fsdp_tp:308:train] epoch=37 iter=5 loss=13.941039 dt=0.122833 dtf=0.048966 dtb=0.073867
[2025-11-23 23:05:31,204844][I][examples/fsdp_tp:308:train] epoch=38 iter=0 loss=14.385422 dt=0.122019 dtf=0.048859 dtb=0.073160
[2025-11-23 23:05:31,444631][I][examples/fsdp_tp:308:train] epoch=38 iter=1 loss=14.197716 dt=0.122352 dtf=0.048922 dtb=0.073430
[2025-11-23 23:05:31,685023][I][examples/fsdp_tp:308:train] epoch=38 iter=2 loss=14.314637 dt=0.122468 dtf=0.049067 dtb=0.073402
[2025-11-23 23:05:31,924742][I][examples/fsdp_tp:308:train] epoch=38 iter=3 loss=14.214232 dt=0.122089 dtf=0.049100 dtb=0.072989
[2025-11-23 23:05:32,164514][I][examples/fsdp_tp:308:train] epoch=38 iter=4 loss=14.194028 dt=0.122774 dtf=0.049144 dtb=0.073630
[2025-11-23 23:05:32,313719][I][examples/fsdp_tp:308:train] epoch=38 iter=5 loss=14.214237 dt=0.122659 dtf=0.049078 dtb=0.073582
[2025-11-23 23:05:32,553775][I][examples/fsdp_tp:308:train] epoch=39 iter=0 loss=14.307973 dt=0.122620 dtf=0.049117 dtb=0.073503
[2025-11-23 23:05:32,793837][I][examples/fsdp_tp:308:train] epoch=39 iter=1 loss=14.103276 dt=0.122330 dtf=0.049129 dtb=0.073200
[2025-11-23 23:05:33,033915][I][examples/fsdp_tp:308:train] epoch=39 iter=2 loss=14.344586 dt=0.122640 dtf=0.049144 dtb=0.073497
[2025-11-23 23:05:33,273401][I][examples/fsdp_tp:308:train] epoch=39 iter=3 loss=14.277104 dt=0.122265 dtf=0.049138 dtb=0.073127
[2025-11-23 23:05:33,513196][I][examples/fsdp_tp:308:train] epoch=39 iter=4 loss=14.277501 dt=0.122676 dtf=0.049105 dtb=0.073570
[2025-11-23 23:05:33,661865][I][examples/fsdp_tp:308:train] epoch=39 iter=5 loss=14.736850 dt=0.122676 dtf=0.049037 dtb=0.073639
[2025-11-23 23:05:33,901540][I][examples/fsdp_tp:308:train] epoch=40 iter=0 loss=14.428084 dt=0.122266 dtf=0.049006 dtb=0.073261
[2025-11-23 23:05:34,141348][I][examples/fsdp_tp:308:train] epoch=40 iter=1 loss=14.239602 dt=0.122309 dtf=0.049031 dtb=0.073278
[2025-11-23 23:05:34,381434][I][examples/fsdp_tp:308:train] epoch=40 iter=2 loss=14.639995 dt=0.122322 dtf=0.048984 dtb=0.073337
[2025-11-23 23:05:34,621167][I][examples/fsdp_tp:308:train] epoch=40 iter=3 loss=14.628743 dt=0.122247 dtf=0.049058 dtb=0.073189
[2025-11-23 23:05:34,860626][I][examples/fsdp_tp:308:train] epoch=40 iter=4 loss=14.644039 dt=0.122622 dtf=0.049017 dtb=0.073605
[2025-11-23 23:05:35,009524][I][examples/fsdp_tp:308:train] epoch=40 iter=5 loss=15.316574 dt=0.122545 dtf=0.048890 dtb=0.073655
[2025-11-23 23:05:35,249931][I][examples/fsdp_tp:308:train] epoch=41 iter=0 loss=14.701756 dt=0.122217 dtf=0.048902 dtb=0.073315
[2025-11-23 23:05:35,489693][I][examples/fsdp_tp:308:train] epoch=41 iter=1 loss=14.517170 dt=0.122030 dtf=0.048907 dtb=0.073123
[2025-11-23 23:05:35,729491][I][examples/fsdp_tp:308:train] epoch=41 iter=2 loss=14.994105 dt=0.122515 dtf=0.049004 dtb=0.073511
[2025-11-23 23:05:35,969616][I][examples/fsdp_tp:308:train] epoch=41 iter=3 loss=14.925176 dt=0.122283 dtf=0.049020 dtb=0.073263
[2025-11-23 23:05:36,209114][I][examples/fsdp_tp:308:train] epoch=41 iter=4 loss=14.875297 dt=0.122678 dtf=0.049029 dtb=0.073649
[2025-11-23 23:05:36,358703][I][examples/fsdp_tp:308:train] epoch=41 iter=5 loss=15.484209 dt=0.122478 dtf=0.048955 dtb=0.073523
[2025-11-23 23:05:36,598543][I][examples/fsdp_tp:308:train] epoch=42 iter=0 loss=14.739423 dt=0.122492 dtf=0.048992 dtb=0.073500
[2025-11-23 23:05:36,838487][I][examples/fsdp_tp:308:train] epoch=42 iter=1 loss=14.496773 dt=0.122399 dtf=0.049099 dtb=0.073300
[2025-11-23 23:05:37,078638][I][examples/fsdp_tp:308:train] epoch=42 iter=2 loss=14.845181 dt=0.122745 dtf=0.049307 dtb=0.073438
[2025-11-23 23:05:37,318558][I][examples/fsdp_tp:308:train] epoch=42 iter=3 loss=14.667422 dt=0.122625 dtf=0.049295 dtb=0.073330
[2025-11-23 23:05:37,558780][I][examples/fsdp_tp:308:train] epoch=42 iter=4 loss=14.537341 dt=0.122551 dtf=0.049211 dtb=0.073340
[2025-11-23 23:05:37,708258][I][examples/fsdp_tp:308:train] epoch=42 iter=5 loss=15.032949 dt=0.122986 dtf=0.049122 dtb=0.073864
[2025-11-23 23:05:37,948604][I][examples/fsdp_tp:308:train] epoch=43 iter=0 loss=14.310425 dt=0.122622 dtf=0.049212 dtb=0.073410
[2025-11-23 23:05:38,188416][I][examples/fsdp_tp:308:train] epoch=43 iter=1 loss=14.069837 dt=0.122263 dtf=0.049021 dtb=0.073241
[2025-11-23 23:05:38,428066][I][examples/fsdp_tp:308:train] epoch=43 iter=2 loss=14.286153 dt=0.122643 dtf=0.049181 dtb=0.073462
[2025-11-23 23:05:38,668304][I][examples/fsdp_tp:308:train] epoch=43 iter=3 loss=14.083020 dt=0.122558 dtf=0.049292 dtb=0.073266
[2025-11-23 23:05:38,908141][I][examples/fsdp_tp:308:train] epoch=43 iter=4 loss=13.969319 dt=0.123122 dtf=0.049424 dtb=0.073698
[2025-11-23 23:05:39,057778][I][examples/fsdp_tp:308:train] epoch=43 iter=5 loss=14.370041 dt=0.122739 dtf=0.049167 dtb=0.073572
[2025-11-23 23:05:39,297614][I][examples/fsdp_tp:308:train] epoch=44 iter=0 loss=13.827186 dt=0.122452 dtf=0.049060 dtb=0.073392
[2025-11-23 23:05:39,537398][I][examples/fsdp_tp:308:train] epoch=44 iter=1 loss=13.675114 dt=0.122388 dtf=0.048959 dtb=0.073429
[2025-11-23 23:05:39,777581][I][examples/fsdp_tp:308:train] epoch=44 iter=2 loss=13.824708 dt=0.122311 dtf=0.048937 dtb=0.073374
[2025-11-23 23:05:40,017420][I][examples/fsdp_tp:308:train] epoch=44 iter=3 loss=13.660801 dt=0.122172 dtf=0.049067 dtb=0.073105
[2025-11-23 23:05:40,257601][I][examples/fsdp_tp:308:train] epoch=44 iter=4 loss=13.603635 dt=0.122376 dtf=0.049100 dtb=0.073276
[2025-11-23 23:05:40,406628][I][examples/fsdp_tp:308:train] epoch=44 iter=5 loss=13.829834 dt=0.122704 dtf=0.048961 dtb=0.073743
[2025-11-23 23:05:40,646620][I][examples/fsdp_tp:308:train] epoch=45 iter=0 loss=13.528256 dt=0.122394 dtf=0.048922 dtb=0.073472
[2025-11-23 23:05:40,887018][I][examples/fsdp_tp:308:train] epoch=45 iter=1 loss=13.463310 dt=0.122438 dtf=0.048952 dtb=0.073486
[2025-11-23 23:05:41,126353][I][examples/fsdp_tp:308:train] epoch=45 iter=2 loss=13.514918 dt=0.122433 dtf=0.049058 dtb=0.073374
[2025-11-23 23:05:41,366286][I][examples/fsdp_tp:308:train] epoch=45 iter=3 loss=13.373691 dt=0.122398 dtf=0.048990 dtb=0.073408
[2025-11-23 23:05:41,605776][I][examples/fsdp_tp:308:train] epoch=45 iter=4 loss=13.339371 dt=0.122518 dtf=0.048957 dtb=0.073561
[2025-11-23 23:05:41,755217][I][examples/fsdp_tp:308:train] epoch=45 iter=5 loss=13.314708 dt=0.122704 dtf=0.048947 dtb=0.073757
[2025-11-23 23:05:41,995070][I][examples/fsdp_tp:308:train] epoch=46 iter=0 loss=13.258095 dt=0.122378 dtf=0.048978 dtb=0.073400
[2025-11-23 23:05:42,235041][I][examples/fsdp_tp:308:train] epoch=46 iter=1 loss=13.269702 dt=0.121978 dtf=0.048809 dtb=0.073169
[2025-11-23 23:05:42,474488][I][examples/fsdp_tp:308:train] epoch=46 iter=2 loss=13.182803 dt=0.122510 dtf=0.048963 dtb=0.073548
[2025-11-23 23:05:42,714714][I][examples/fsdp_tp:308:train] epoch=46 iter=3 loss=13.083911 dt=0.122509 dtf=0.049191 dtb=0.073318
[2025-11-23 23:05:42,954630][I][examples/fsdp_tp:308:train] epoch=46 iter=4 loss=13.085930 dt=0.122659 dtf=0.049156 dtb=0.073503
[2025-11-23 23:05:43,103914][I][examples/fsdp_tp:308:train] epoch=46 iter=5 loss=12.874291 dt=0.122840 dtf=0.049273 dtb=0.073568
[2025-11-23 23:05:43,343641][I][examples/fsdp_tp:308:train] epoch=47 iter=0 loss=13.107726 dt=0.122695 dtf=0.049092 dtb=0.073603
[2025-11-23 23:05:43,583913][I][examples/fsdp_tp:308:train] epoch=47 iter=1 loss=13.277080 dt=0.122418 dtf=0.048938 dtb=0.073480
[2025-11-23 23:05:43,823597][I][examples/fsdp_tp:308:train] epoch=47 iter=2 loss=13.154934 dt=0.122790 dtf=0.049210 dtb=0.073580
[2025-11-23 23:05:44,063287][I][examples/fsdp_tp:308:train] epoch=47 iter=3 loss=13.261304 dt=0.122686 dtf=0.049205 dtb=0.073481
[2025-11-23 23:05:44,303344][I][examples/fsdp_tp:308:train] epoch=47 iter=4 loss=13.481776 dt=0.122560 dtf=0.049125 dtb=0.073434
[2025-11-23 23:05:44,452510][I][examples/fsdp_tp:308:train] epoch=47 iter=5 loss=13.371351 dt=0.122557 dtf=0.048981 dtb=0.073576
[2025-11-23 23:05:44,692346][I][examples/fsdp_tp:308:train] epoch=48 iter=0 loss=13.965228 dt=0.122353 dtf=0.049146 dtb=0.073207
[2025-11-23 23:05:44,932231][I][examples/fsdp_tp:308:train] epoch=48 iter=1 loss=14.404729 dt=0.122420 dtf=0.049230 dtb=0.073189
[2025-11-23 23:05:45,171523][I][examples/fsdp_tp:308:train] epoch=48 iter=2 loss=14.328328 dt=0.122762 dtf=0.049377 dtb=0.073385
[2025-11-23 23:05:45,411805][I][examples/fsdp_tp:308:train] epoch=48 iter=3 loss=14.660830 dt=0.122614 dtf=0.049372 dtb=0.073241
[2025-11-23 23:05:45,651274][I][examples/fsdp_tp:308:train] epoch=48 iter=4 loss=15.035357 dt=0.122580 dtf=0.049054 dtb=0.073526
[2025-11-23 23:05:45,800901][I][examples/fsdp_tp:308:train] epoch=48 iter=5 loss=14.927198 dt=0.122624 dtf=0.049040 dtb=0.073584
[2025-11-23 23:05:46,040441][I][examples/fsdp_tp:308:train] epoch=49 iter=0 loss=15.694957 dt=0.122625 dtf=0.049093 dtb=0.073533
[2025-11-23 23:05:46,280308][I][examples/fsdp_tp:308:train] epoch=49 iter=1 loss=16.199514 dt=0.122406 dtf=0.049117 dtb=0.073289
[2025-11-23 23:05:46,520216][I][examples/fsdp_tp:308:train] epoch=49 iter=2 loss=15.997758 dt=0.122980 dtf=0.049216 dtb=0.073764
[2025-11-23 23:05:46,760175][I][examples/fsdp_tp:308:train] epoch=49 iter=3 loss=16.366274 dt=0.122817 dtf=0.049256 dtb=0.073561
[2025-11-23 23:05:46,999812][I][examples/fsdp_tp:308:train] epoch=49 iter=4 loss=16.707830 dt=0.122680 dtf=0.049221 dtb=0.073459
[2025-11-23 23:05:47,148639][I][examples/fsdp_tp:308:train] epoch=49 iter=5 loss=16.423996 dt=0.122742 dtf=0.049299 dtb=0.073443
[2025-11-23 23:05:47,149302][I][examples/fsdp_tp:322:train] Finished 2D training
[rank4]:[W1123 23:05:47.474173276 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank2]:[W1123 23:05:47.452562968 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank6]:[W1123 23:05:47.491833715 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:[W1123 23:05:47.469149960 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank7]:[W1123 23:05:47.507909462 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank5]:[W1123 23:05:47.508922733 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank1]:[W1123 23:05:48.963389834 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-11-23 23:05:49,147206][I][ezpz/history:810:plot_all] Saving train_epoch plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:05:49,326932][I][ezpz/history:810:plot_all] Saving train_iter plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:05:49,505024][I][ezpz/history:810:plot_all] Saving train_loss plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:05:49,666701][I][ezpz/history:810:plot_all] Saving train_dt plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:05:49,842079][I][ezpz/history:810:plot_all] Saving train_dtf plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:05:50,017088][I][ezpz/history:810:plot_all] Saving train_dtb plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:05:50,180163][I][ezpz/history:714:tplot_all] Saving tplots to /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot
                 train_epoch [2025-11-23-230550]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
49.0‚î§                                                  ‚ñÑ‚ñÑ‚ñü‚ñÄ‚îÇ
    ‚îÇ                                              ‚ñó‚ñÑ‚ñÑ‚ñÄ‚ñò   ‚îÇ
41.7‚î§                                           ‚ñÑ‚ñÑ‚ñû‚ñÄ       ‚îÇ
    ‚îÇ                                       ‚ñó‚ñÑ‚ñÑ‚ñÄ‚ñò          ‚îÇ
    ‚îÇ                                    ‚ñÑ‚ñÑ‚ñõ‚ñò              ‚îÇ
34.3‚î§                                ‚ñÑ‚ñÑ‚ñü‚ñÄ                  ‚îÇ
    ‚îÇ                            ‚ñó‚ñÑ‚ñÑ‚ñõ‚ñò                     ‚îÇ
27.0‚î§                         ‚ñÑ‚ñû‚ñÄ‚ñÄ                         ‚îÇ
    ‚îÇ                     ‚ñó‚ñü‚ñÄ‚ñÄ‚ñò                            ‚îÇ
19.7‚î§                  ‚ñÑ‚ñõ‚ñÄ‚ñÄ                                ‚îÇ
    ‚îÇ              ‚ñó‚ñü‚ñÄ‚ñÄ                                    ‚îÇ
    ‚îÇ          ‚ñó‚ñÑ‚ñÄ‚ñÄ‚ñò                                       ‚îÇ
12.3‚î§       ‚ñÑ‚ñû‚ñÄ‚ñÄ                                           ‚îÇ
    ‚îÇ   ‚ñó‚ñÑ‚ñÄ‚ñÄ‚ñò                                              ‚îÇ
 5.0‚î§‚ñÑ‚ñõ‚ñÄ‚ñÄ                                                  ‚îÇ
    ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
     3 16 31  50   75 90    122 142  169   198    240 256
train_epoch                   iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_epoch.txt
                 train_iter [2025-11-23-230550]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
5.00‚î§ ‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚îÇ
    ‚îÇ ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚îÇ
4.17‚î§ ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚îÇ
    ‚îÇ‚ñó‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñû‚îÇ
    ‚îÇ‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñå‚îÇ
3.33‚î§‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñå‚îÇ
    ‚îÇ‚ñê‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñå‚îÇ
2.50‚î§‚ñê‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñå‚îÇ
    ‚îÇ‚ñê‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñå‚îÇ
1.67‚î§‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
0.83‚î§‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê ‚îÇ
0.00‚î§‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê ‚îÇ
    ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
     3 16 31  50   75 90    122 142  169   198    240 256
train_iter                    iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_iter.txt
                 train_loss [2025-11-23-230550]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
19.3‚î§                           ‚ñó   ‚ñà‚ññ                     ‚îÇ
    ‚îÇ                           ‚ñõ‚ñå ‚ñû‚ñå‚ñú‚ññ                    ‚îÇ
17.4‚î§                          ‚ñê‚ñò‚ñà‚ññ‚ñå  ‚ñô                    ‚îÇ
    ‚îÇ                          ‚ñû ‚ñù‚ñú   ‚ñù‚ñå‚ññ                 ‚ñó‚îÇ
    ‚îÇ                      ‚ñó‚ñÑ‚ñå ‚ñå       ‚ñù‚ñú‚ññ               ‚ñê‚ñå‚îÇ
15.5‚î§         ‚ññ‚ññ  ‚ñó‚ñü‚ñà‚ñú‚ñü‚ñÑ   ‚ñê‚ñê‚ñê‚ñõ‚ñò        ‚ñù‚ñú‚ñô‚ññ   ‚ñó‚ñô‚ñô‚ññ      ‚ñü ‚îÇ
    ‚îÇ       ‚ñó‚ñõ‚ñà‚ñú‚ñú‚ñÄ‚ñÄ‚ñò   ‚ñù‚ñà‚ñõ‚ñü‚ñú ‚ñù‚ñå           ‚ñò‚ñõ‚ñô‚ñÑ‚ñü‚ñõ‚ñò‚ñÄ‚ñö‚ñÑ    ‚ñó‚ñò ‚îÇ
13.7‚î§      ‚ñó‚ñå‚ñò‚ñù          ‚ñò‚ñú                 ‚ñò      ‚ñÄ‚ñà‚ñÑ  ‚ñû  ‚îÇ
    ‚îÇ      ‚ñû                                          ‚ñÄ‚ñõ   ‚îÇ
11.8‚î§     ‚ñà‚ñå                                               ‚îÇ
    ‚îÇ  ‚ñô‚ñô‚ñà‚ñò‚ñò                                               ‚îÇ
    ‚îÇ ‚ñê‚ñõ‚ñù                                                  ‚îÇ
 9.9‚î§‚ñó‚ñû                                                    ‚îÇ
    ‚îÇ‚ñü‚ñå                                                    ‚îÇ
 8.0‚î§‚ñà‚ñò                                                    ‚îÇ
    ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
     3 16 31  50   75 90    122 142  169   198    240 256
train_loss                    iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_loss.txt
                  train_dt [2025-11-23-230550]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.274‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.249‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.223‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.198‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.173‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.147‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.122‚î§‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñú‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
      3 16 31 50   75 90    122 142  169   198    240 256
train_dt                      iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_dt.txt
                  train_dt [2025-11-23-230550]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
269.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
224.2‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
179.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
134.5‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 89.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 44.8‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
  0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
    0.115        0.157        0.198        0.239      0.281
freq                        train_dt
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_dt-hist.txt
                  train_dtf [2025-11-23-230550]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.197‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.172‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.148‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.123‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.098‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.074‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.049‚î§‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñô‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
      3 16 31 50   75 90    122 142  169   198    240 256
train_dtf                     iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_dtf.txt
                  train_dtf [2025-11-23-230550]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
269.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
224.2‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
179.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
134.5‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 89.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 44.8‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
  0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
    0.042        0.083        0.123        0.163      0.204
freq                        train_dtf
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_dtf-hist.txt
                   train_dtb [2025-11-23-230550]
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.07674‚î§            ‚ñå                 ‚ññ                    ‚îÇ
       ‚îÇ       ‚ññ    ‚ñå                 ‚ñå                    ‚îÇ
0.07610‚î§      ‚ñå‚ñå    ‚ñå         ‚ñó    ‚ññ  ‚ñå                    ‚îÇ
       ‚îÇ      ‚ñà‚ñà    ‚ñå‚ññ ‚ññ‚ñó‚ñô ‚ñü‚ñå‚ññ‚ñà ‚ñÑ‚ñå‚ñê‚ñå ‚ñê‚ñå‚ñà                   ‚îÇ
       ‚îÇ‚ñü‚ñó‚ñó ‚ñå‚ñÑ‚ñà‚ñà‚ñê ‚ñó‚ñó‚ñô‚ñô‚ñê‚ñà‚ñü‚ñà‚ñô‚ñà‚ñå‚ñå‚ñà‚ñü‚ñà‚ñà‚ñû‚ñô‚ñÑ‚ñà‚ñú‚ñÄ‚ññ                  ‚îÇ
0.07546‚î§‚ñà‚ñü‚ñà‚ñå‚ñô‚ñà‚ñà‚ñà‚ñà‚ñô‚ñà‚ñõ‚ñú‚ñà‚ñõ‚ñà‚ñà‚ñà‚ñà‚ñò‚ñú‚ñà‚ñò‚ñú ‚ñù‚ñå‚ñõ‚ñà‚ñà‚ñê ‚ñå                  ‚îÇ
       ‚îÇ‚ñÄ‚ñà ‚ñö‚ñà‚ñò‚ñà ‚ñú‚ñõ‚ñà‚ñò ‚ñê ‚ñÄ‚ñå‚ñú‚ñõ  ‚ñú ‚ñù   ‚ñå‚ñà‚ñò  ‚ñå                  ‚îÇ
0.07482‚î§ ‚ñê ‚ñù‚ñò   ‚ñù‚ñò‚ñù  ‚ñù              ‚ñù   ‚ñå                  ‚îÇ
       ‚îÇ ‚ñê                              ‚ñå                  ‚îÇ
0.07418‚î§                                ‚ñå   ‚ññ              ‚îÇ
       ‚îÇ                                ‚ñå   ‚ñå              ‚îÇ
       ‚îÇ                                ‚ñô   ‚ñå‚ñå‚ññ‚ññ‚ñó‚ñó‚ñê‚ñó ‚ññ‚ñå  ‚ñó‚ñå‚îÇ
0.07353‚î§                                ‚ñê‚ñû‚ññ‚ñó‚ñú‚ñà‚ñú‚ñå‚ñà‚ñà‚ñü‚ñü‚ñü‚ñô‚ñà‚ñú‚ñå‚ñà‚ñö‚îÇ
       ‚îÇ                                ‚ñê‚ñå‚ñà‚ñü‚ñù‚ñà‚ñê‚ñõ‚ñà‚ñò‚ñÄ‚ñÄ‚ñê ‚ñú ‚ñú‚ñÄ ‚îÇ
0.07289‚î§                                 ‚ñò‚ñú‚ñÄ ‚ñù             ‚îÇ
       ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
        3 16 31 50   75 90   122 142  169   198   240 256
train_dtb                      iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_dtb.txt
                 train_dtb [2025-11-23-230550]
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
72‚î§                                  ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚îÇ
  ‚îÇ                                  ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚îÇ
60‚î§      ‚ñà‚ñà‚ñà‚ñà‚ñà                       ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚îÇ
  ‚îÇ      ‚ñà‚ñà‚ñà‚ñà‚ñà                       ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚îÇ
  ‚îÇ      ‚ñà‚ñà‚ñà‚ñà‚ñà                       ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚îÇ
48‚î§      ‚ñà‚ñà‚ñà‚ñà‚ñà                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚îÇ
  ‚îÇ      ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚îÇ
36‚î§      ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚îÇ
  ‚îÇ      ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚îÇ
24‚î§‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚îÇ
  ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚îÇ
  ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà                 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      ‚îÇ
12‚î§‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      ‚îÇ
  ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
 0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
  ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
 0.0727       0.0738        0.0748       0.0759      0.0769
freq                       train_dtb
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/plots/tplot/train_dtb-hist.txt
[2025-11-23 23:05:50,326863][I][utils/__init__:416:dataset_to_h5pyfile] Saving dataset to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230548/ezpz-fsdp-tp/train_dataset.h5
[2025-11-23 23:05:50,335964][I][examples/fsdp_tp:329:train] dataset=<xarray.Dataset> Size: 15kB
Dimensions:      (draw: 270)
Coordinates:
  * draw         (draw) int64 2kB 0 1 2 3 4 5 6 ... 263 264 265 266 267 268 269
Data variables:
    train_epoch  (draw) int64 2kB 5 5 5 5 5 5 6 6 6 ... 48 48 49 49 49 49 49 49
    train_iter   (draw) int64 2kB 0 1 2 3 4 5 0 1 2 3 4 ... 2 3 4 5 0 1 2 3 4 5
    train_loss   (draw) float64 2kB 8.02 8.661 8.044 9.759 ... 16.37 16.71 16.42
    train_dt     (draw) float64 2kB 0.1257 0.1257 0.1265 ... 0.1227 0.1227
    train_dtf    (draw) float64 2kB 0.05052 0.05059 0.05077 ... 0.04922 0.0493
    train_dtb    (draw) float64 2kB 0.07519 0.07509 0.07569 ... 0.07346 0.07344
[rank0]:[W1123 23:05:50.755471263 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Application 52fe1345 resources: utime=637s stime=169s maxrss=2451352KB inblock=544 oublock=3552 minflt=2437504 majflt=1164 nvcsw=338412 nivcsw=2830
[2025-11-23 23:05:54,835899][I][ezpz/launch:402:launch] Execution finished with 0.
[2025-11-23 23:05:54,836425][I][ezpz/launch:403:launch] Executing finished in 94.28 seconds.
[2025-11-23 23:05:54,836821][I][ezpz/launch:404:launch] Took 94.29 seconds to run. Exiting.
Finished TP=1 at 2025-11-23 23:05:56
--------------------------------------------------------
========================================================
Running Experiment: Layers=8, TP=2
Start Time: 2025-11-23 23:06:01
========================================================


[2025-11-23 23:06:13,178133][I][ezpz/launch:369:launch] ----[üçã ezpz.launch][started][2025-11-23-230613]----
[2025-11-23 23:06:14,404713][I][ezpz/launch:374:launch] Job ID: 6650384
[2025-11-23 23:06:14,405737][I][ezpz/launch:375:launch] nodelist: ['x3206c0s37b1n0', 'x3206c0s7b0n0']
[2025-11-23 23:06:14,406140][I][ezpz/launch:376:launch] hostfile: /var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov
[2025-11-23 23:06:14,407094][I][ezpz/pbs:179:get_pbs_launch_cmd] ‚úÖ Using [8/8] GPUs [2 hosts] x [4 GPU/host]
[2025-11-23 23:06:14,409201][I][ezpz/launch:345:build_executable] Building command to execute by piecing together:
[2025-11-23 23:06:14,409591][I][ezpz/launch:346:build_executable] (1.) launch_cmd: mpiexec --verbose --envall --np=8 --ppn=4 --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind=depth --depth=8
[2025-11-23 23:06:14,410135][I][ezpz/launch:347:build_executable] (2.) cmd_to_launch: python3 -m ezpz.examples.fsdp_tp --dataset random --n-layers 8 --tp 2
[2025-11-23 23:06:14,410718][I][ezpz/launch:389:launch] Took: 1.23 seconds to build command.
[2025-11-23 23:06:14,411065][I][ezpz/launch:390:launch] Executing:
mpiexec
  --verbose
  --envall
  --np=8
  --ppn=4
  --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov
  --cpu-bind=depth
  --depth=8
  python3
  -m
  ezpz.examples.fsdp_tp
  --dataset
  random
  --n-layers
  8
  --tp
  2
[2025-11-23 23:06:14,412870][I][ezpz/launch:397:launch] Execution started @ 2025-11-23-230614...
[2025-11-23 23:06:14,413309][I][ezpz/launch:398:launch] ----[üçã ezpz.launch][stop][2025-11-23-230614]----
[2025-11-23 23:06:14,413791][I][ezpz/launch:127:run_command] Running command:
 mpiexec --verbose --envall --np=8 --ppn=4 --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind=depth --depth=8 python3 -m ezpz.examples.fsdp_tp --dataset random --n-layers 8 --tp 2
Disabling local launch: multi-node application
Connected to tcp://x3206c0s37b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/applications/conda/2025-09-25/mconda3/bin/python3
Launching application 8f12cb28-f81a-4e67-a96f-3fd72be8e12f
Using PMI ports 46468,46469
[2025-11-23 23:06:27,661978][I][examples/fsdp_tp:334:<module>] args:
Namespace(dim=256, n_layers=8, n_heads=32, n_kv_heads=4, multiple_of=360, ffn_dim_multiplier=None, norm_eps=1e-05, vocab_size=32000, seq_length=2048, lr=0.003, epochs=50, batch_size=24, seed=None, tp=2, dataset='random', max_seq_len=32768, depth_init=True)
[2025-11-23 23:06:27,853472][I][ezpz/dist:1242:setup_torch_distributed] Using fw='ddp' with torch_{device,backend}= {cuda, nccl}
[2025-11-23 23:06:27,855590][I][ezpz/dist:1113:setup_torch_DDP] Caught MASTER_PORT=59853 from environment!
[2025-11-23 23:06:27,856169][I][ezpz/dist:1129:setup_torch_DDP] Using torch.distributed.init_process_group with
- master_addr='x3206c0s37b1n0.hsn.cm.polaris.alcf.anl.gov'
- master_port='59853'
- world_size=8
- rank=0
- local_rank=0
- timeout=datetime.timedelta(seconds=3600)
- backend='nccl'
[2025-11-23 23:06:27,856997][I][ezpz/dist:822:init_process_group] Calling torch.distributed.init_process_group_with: rank=0 world_size=8 backend=nccl
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank3]:[W1123 23:06:28.317429609 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank2]:[W1123 23:06:28.318572868 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank1]:[W1123 23:06:28.319382490 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:06:29,973847][I][tp/__init__:141:initialize_tensor_parallel] TP: 2, PP: 1, CP: 1, DP: 4
[2025-11-23 23:06:29,978536][I][ezpz/pbs:179:get_pbs_launch_cmd] ‚úÖ Using [8/8] GPUs [2 hosts] x [4 GPU/host]
[2025-11-23 23:06:29,981041][I][ezpz/dist:510:print_dist_setup] [device='cuda'][rank=0/7][local_rank=0/3][node=0/1]
[2025-11-23 23:06:29,981547][W][ezpz/dist:514:print_dist_setup] Using [8 / 8] available "cuda" devices !!
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank0]:[W1123 23:06:29.937949145 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank4]:[W1123 23:06:29.983509894 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank5]:[W1123 23:06:30.480873735 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank7]:[W1123 23:06:30.484906721 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank6]:[W1123 23:06:30.488907356 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank1]:[W1123 23:06:30.802430420 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 3 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank2]:[W1123 23:06:30.802420091 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 4 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank3]:[W1123 23:06:30.802434698 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 4 Rank 1]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:06:30,847739][I][ezpz/dist:1462:setup_torch] Using device='cuda' with backend='nccl' + 'nccl' for distributed training.
[rank0]:[W1123 23:06:30.803155212 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 3 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank4]:[W1123 23:06:30.835833659 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 5 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank5]:[W1123 23:06:30.835844409 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 5 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank6]:[W1123 23:06:30.835834089 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 6 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank7]:[W1123 23:06:30.835842395 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 6 Rank 1]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank4]:[W1123 23:06:30.913612184 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 1 Rank 2]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank5]:[W1123 23:06:30.913628535 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 2 Rank 2]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank2]:[W1123 23:06:30.889431386 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 1 Rank 1]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank3]:[W1123 23:06:30.889431105 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 2 Rank 1]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank0]:[W1123 23:06:30.927732892 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 1 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank1]:[W1123 23:06:30.927716151 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 2 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank6]:[W1123 23:06:30.966564688 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 1 Rank 3]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank7]:[W1123 23:06:30.966567023 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 2 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:06:31,072864][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][3/7] [tp:1/1][dp:1/3]
[2025-11-23 23:06:31,072884][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][7/7] [tp:1/1][dp:3/3]
[2025-11-23 23:06:31,072892][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][5/7] [tp:1/1][dp:2/3]
[2025-11-23 23:06:31,072865][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][1/7] [tp:1/1][dp:0/3]
[2025-11-23 23:06:31,156113][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][0/7] [tp:0/1][dp:0/3]
[2025-11-23 23:06:31,156126][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][2/7] [tp:0/1][dp:1/3]
[2025-11-23 23:06:31,156146][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][6/7] [tp:0/1][dp:3/3]
[2025-11-23 23:06:31,156141][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][4/7] [tp:0/1][dp:2/3]
[2025-11-23 23:06:31,159784][I][examples/fsdp_tp:185:train] Device mesh created:
device_mesh=DeviceMesh('cuda', [[0, 1], [2, 3], [4, 5], [6, 7]], mesh_dim_names=('dp', 'tp'))
[2025-11-23 23:06:31,160625][I][examples/fsdp_tp:196:train] config:
ModelArgs(dim=256, n_layers=8, n_heads=32, n_kv_heads=4, vocab_size=32000, multiple_of=360, ffn_dim_multiplier=None, norm_eps=1e-05, batch_size=24, max_seq_len=32768, depth_init=True)
[2025-11-23 23:06:31,374833][I][examples/fsdp_tp:223:train] 
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Transformer                              --
‚îú‚îÄEmbedding: 1-1                         8,192,000
‚îú‚îÄModuleList: 1-2                        --
‚îÇ    ‚îî‚îÄTransformerBlock: 2-1             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-2             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-3             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-4             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-5             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-6             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-7             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-8             700,928
‚îú‚îÄRMSNorm: 1-3                           256
‚îú‚îÄLinear: 1-4                            8,192,000
=================================================================
Total params: 21,991,680
Trainable params: 21,991,680
Non-trainable params: 0
=================================================================
[2025-11-23 23:06:31,574574][I][examples/fsdp_tp:171:parallelize] Model after parallelization:
sharded_model=FullyShardedDataParallel(
  (_fsdp_wrapped_module): Transformer(
    (tok_embeddings): Embedding(32000, 256)
    (layers): ModuleList(
      (0-7): 8 x TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=256, out_features=256, bias=False)
          (wk): Linear(in_features=256, out_features=32, bias=False)
          (wv): Linear(in_features=256, out_features=32, bias=False)
          (wo): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=256, out_features=720, bias=False)
          (w2): Linear(in_features=720, out_features=256, bias=False)
          (w3): Linear(in_features=256, out_features=720, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
    )
    (norm): RMSNorm()
    (output): Linear(in_features=256, out_features=32000, bias=False)
  )
)

[2025-11-23 23:06:31,577304][I][examples/fsdp_tp:226:train] Creating optimizer=AdamW with lr=0.003
[2025-11-23 23:06:31,579679][I][examples/fsdp_tp:272:train] Starting 2D training...
[2025-11-23 23:06:32,354499][I][examples/fsdp_tp:308:train] epoch=0 iter=0 loss=10.864079 dt=0.773609 dtf=0.518082 dtb=0.255527
[2025-11-23 23:06:32,355256][I][examples/fsdp_tp:321:train] inp.shape=torch.Size([24, 2048])
[2025-11-23 23:06:32,580864][I][examples/fsdp_tp:308:train] epoch=0 iter=1 loss=10.842239 dt=0.123541 dtf=0.051019 dtb=0.072522
[2025-11-23 23:06:32,795915][I][examples/fsdp_tp:308:train] epoch=0 iter=2 loss=10.843788 dt=0.123272 dtf=0.049386 dtb=0.073886
[2025-11-23 23:06:33,015076][I][examples/fsdp_tp:308:train] epoch=0 iter=3 loss=10.840660 dt=0.123283 dtf=0.049482 dtb=0.073802
[2025-11-23 23:06:33,234540][I][examples/fsdp_tp:308:train] epoch=0 iter=4 loss=10.830682 dt=0.122955 dtf=0.049715 dtb=0.073240
[2025-11-23 23:06:33,441816][I][examples/fsdp_tp:308:train] epoch=0 iter=5 loss=10.831728 dt=0.184005 dtf=0.074104 dtb=0.109902
[2025-11-23 23:06:33,661973][I][examples/fsdp_tp:308:train] epoch=1 iter=0 loss=8.628358 dt=0.122711 dtf=0.049702 dtb=0.073009
[2025-11-23 23:06:33,877569][I][examples/fsdp_tp:308:train] epoch=1 iter=1 loss=9.278450 dt=0.122177 dtf=0.049320 dtb=0.072857
[2025-11-23 23:06:34,097265][I][examples/fsdp_tp:308:train] epoch=1 iter=2 loss=9.598244 dt=0.122649 dtf=0.049381 dtb=0.073268
[2025-11-23 23:06:34,316498][I][examples/fsdp_tp:308:train] epoch=1 iter=3 loss=9.785831 dt=0.122532 dtf=0.049474 dtb=0.073058
[2025-11-23 23:06:34,536028][I][examples/fsdp_tp:308:train] epoch=1 iter=4 loss=9.913525 dt=0.122543 dtf=0.049378 dtb=0.073165
[2025-11-23 23:06:34,683408][I][examples/fsdp_tp:308:train] epoch=1 iter=5 loss=8.692209 dt=0.122729 dtf=0.049533 dtb=0.073196
[2025-11-23 23:06:34,902001][I][examples/fsdp_tp:308:train] epoch=2 iter=0 loss=6.864110 dt=0.122442 dtf=0.049295 dtb=0.073147
[2025-11-23 23:06:35,115914][I][examples/fsdp_tp:308:train] epoch=2 iter=1 loss=7.648619 dt=0.122355 dtf=0.049268 dtb=0.073087
[2025-11-23 23:06:35,337405][I][examples/fsdp_tp:308:train] epoch=2 iter=2 loss=8.083589 dt=0.122695 dtf=0.049447 dtb=0.073248
[2025-11-23 23:06:35,559749][I][examples/fsdp_tp:308:train] epoch=2 iter=3 loss=8.398480 dt=0.122569 dtf=0.049542 dtb=0.073027
[2025-11-23 23:06:35,774418][I][examples/fsdp_tp:308:train] epoch=2 iter=4 loss=8.659504 dt=0.122647 dtf=0.049218 dtb=0.073429
[2025-11-23 23:06:35,921967][I][examples/fsdp_tp:308:train] epoch=2 iter=5 loss=5.661632 dt=0.123083 dtf=0.049369 dtb=0.073714
[2025-11-23 23:06:36,141378][I][examples/fsdp_tp:308:train] epoch=3 iter=0 loss=6.035414 dt=0.122164 dtf=0.049300 dtb=0.072864
[2025-11-23 23:06:36,355957][I][examples/fsdp_tp:308:train] epoch=3 iter=1 loss=6.917465 dt=0.122518 dtf=0.049492 dtb=0.073026
[2025-11-23 23:06:36,580037][I][examples/fsdp_tp:308:train] epoch=3 iter=2 loss=7.340277 dt=0.122908 dtf=0.049391 dtb=0.073518
[2025-11-23 23:06:36,794955][I][examples/fsdp_tp:308:train] epoch=3 iter=3 loss=7.725520 dt=0.122226 dtf=0.049190 dtb=0.073036
[2025-11-23 23:06:37,018111][I][examples/fsdp_tp:308:train] epoch=3 iter=4 loss=8.137290 dt=0.122482 dtf=0.049438 dtb=0.073044
[2025-11-23 23:06:37,158567][I][examples/fsdp_tp:308:train] epoch=3 iter=5 loss=4.029378 dt=0.122663 dtf=0.049405 dtb=0.073258
[2025-11-23 23:06:37,374238][I][examples/fsdp_tp:308:train] epoch=4 iter=0 loss=6.170053 dt=0.122458 dtf=0.049354 dtb=0.073104
[2025-11-23 23:06:37,599063][I][examples/fsdp_tp:308:train] epoch=4 iter=1 loss=7.303947 dt=0.122874 dtf=0.049370 dtb=0.073505
[2025-11-23 23:06:37,813373][I][examples/fsdp_tp:308:train] epoch=4 iter=2 loss=7.889198 dt=0.122297 dtf=0.049209 dtb=0.073088
[2025-11-23 23:06:38,035679][I][examples/fsdp_tp:308:train] epoch=4 iter=3 loss=7.772894 dt=0.122524 dtf=0.049279 dtb=0.073245
[2025-11-23 23:06:38,253598][I][examples/fsdp_tp:308:train] epoch=4 iter=4 loss=8.603051 dt=0.122333 dtf=0.049251 dtb=0.073082
[2025-11-23 23:06:38,401691][I][examples/fsdp_tp:308:train] epoch=4 iter=5 loss=4.518731 dt=0.122574 dtf=0.049322 dtb=0.073252
[2025-11-23 23:06:38,615064][I][examples/fsdp_tp:308:train] epoch=5 iter=0 loss=6.845456 dt=0.122019 dtf=0.049128 dtb=0.072891
[2025-11-23 23:06:38,837438][I][examples/fsdp_tp:308:train] epoch=5 iter=1 loss=7.994131 dt=0.122355 dtf=0.049286 dtb=0.073068
[2025-11-23 23:06:39,052594][I][examples/fsdp_tp:308:train] epoch=5 iter=2 loss=8.705001 dt=0.122190 dtf=0.049238 dtb=0.072952
[2025-11-23 23:06:39,278843][I][examples/fsdp_tp:308:train] epoch=5 iter=3 loss=9.000339 dt=0.122278 dtf=0.049378 dtb=0.072900
[2025-11-23 23:06:39,491043][I][examples/fsdp_tp:308:train] epoch=5 iter=4 loss=9.600255 dt=0.122339 dtf=0.049192 dtb=0.073147
[2025-11-23 23:06:39,638652][I][examples/fsdp_tp:308:train] epoch=5 iter=5 loss=7.614982 dt=0.122852 dtf=0.049400 dtb=0.073452
[2025-11-23 23:06:39,852372][I][examples/fsdp_tp:308:train] epoch=6 iter=0 loss=9.183270 dt=0.121874 dtf=0.049138 dtb=0.072736
[2025-11-23 23:06:40,073895][I][examples/fsdp_tp:308:train] epoch=6 iter=1 loss=9.970013 dt=0.122264 dtf=0.049500 dtb=0.072764
[2025-11-23 23:06:40,292269][I][examples/fsdp_tp:308:train] epoch=6 iter=2 loss=10.098237 dt=0.122703 dtf=0.049352 dtb=0.073351
[2025-11-23 23:06:40,514978][I][examples/fsdp_tp:308:train] epoch=6 iter=3 loss=10.682487 dt=0.123221 dtf=0.049427 dtb=0.073795
[2025-11-23 23:06:40,729248][I][examples/fsdp_tp:308:train] epoch=6 iter=4 loss=11.157271 dt=0.122292 dtf=0.049224 dtb=0.073068
[2025-11-23 23:06:40,875396][I][examples/fsdp_tp:308:train] epoch=6 iter=5 loss=9.858110 dt=0.122675 dtf=0.049533 dtb=0.073142
[2025-11-23 23:06:41,092979][I][examples/fsdp_tp:308:train] epoch=7 iter=0 loss=10.758710 dt=0.122887 dtf=0.049290 dtb=0.073597
[2025-11-23 23:06:41,305520][I][examples/fsdp_tp:308:train] epoch=7 iter=1 loss=10.923629 dt=0.122154 dtf=0.049315 dtb=0.072839
[2025-11-23 23:06:41,523135][I][examples/fsdp_tp:308:train] epoch=7 iter=2 loss=11.212677 dt=0.122524 dtf=0.049346 dtb=0.073178
[2025-11-23 23:06:41,742924][I][examples/fsdp_tp:308:train] epoch=7 iter=3 loss=11.477951 dt=0.122290 dtf=0.049301 dtb=0.072989
[2025-11-23 23:06:41,963317][I][examples/fsdp_tp:308:train] epoch=7 iter=4 loss=11.724617 dt=0.122285 dtf=0.049332 dtb=0.072953
[2025-11-23 23:06:42,110043][I][examples/fsdp_tp:308:train] epoch=7 iter=5 loss=11.078735 dt=0.122525 dtf=0.049464 dtb=0.073062
[2025-11-23 23:06:42,323939][I][examples/fsdp_tp:308:train] epoch=8 iter=0 loss=11.414935 dt=0.122075 dtf=0.049200 dtb=0.072875
[2025-11-23 23:06:42,547754][I][examples/fsdp_tp:308:train] epoch=8 iter=1 loss=11.971210 dt=0.122255 dtf=0.049474 dtb=0.072781
[2025-11-23 23:06:42,762655][I][examples/fsdp_tp:308:train] epoch=8 iter=2 loss=11.603068 dt=0.121994 dtf=0.049191 dtb=0.072804
[2025-11-23 23:06:42,983247][I][examples/fsdp_tp:308:train] epoch=8 iter=3 loss=11.721980 dt=0.122583 dtf=0.049555 dtb=0.073028
[2025-11-23 23:06:43,204163][I][examples/fsdp_tp:308:train] epoch=8 iter=4 loss=11.795288 dt=0.122941 dtf=0.049341 dtb=0.073599
[2025-11-23 23:06:43,348875][I][examples/fsdp_tp:308:train] epoch=8 iter=5 loss=11.219433 dt=0.122844 dtf=0.049419 dtb=0.073426
[2025-11-23 23:06:43,562664][I][examples/fsdp_tp:308:train] epoch=9 iter=0 loss=11.529037 dt=0.122318 dtf=0.049063 dtb=0.073255
[2025-11-23 23:06:43,785308][I][examples/fsdp_tp:308:train] epoch=9 iter=1 loss=11.736125 dt=0.122236 dtf=0.049502 dtb=0.072734
[2025-11-23 23:06:44,000466][I][examples/fsdp_tp:308:train] epoch=9 iter=2 loss=11.398210 dt=0.121968 dtf=0.049215 dtb=0.072752
[2025-11-23 23:06:44,223842][I][examples/fsdp_tp:308:train] epoch=9 iter=3 loss=11.495293 dt=0.122114 dtf=0.049331 dtb=0.072783
[2025-11-23 23:06:44,438789][I][examples/fsdp_tp:308:train] epoch=9 iter=4 loss=11.675751 dt=0.122096 dtf=0.049208 dtb=0.072889
[2025-11-23 23:06:44,587031][I][examples/fsdp_tp:308:train] epoch=9 iter=5 loss=11.527394 dt=0.122552 dtf=0.049457 dtb=0.073095
[2025-11-23 23:06:44,806537][I][examples/fsdp_tp:308:train] epoch=10 iter=0 loss=12.032481 dt=0.123061 dtf=0.049194 dtb=0.073867
[2025-11-23 23:06:45,019855][I][examples/fsdp_tp:308:train] epoch=10 iter=1 loss=12.192897 dt=0.122131 dtf=0.049254 dtb=0.072878
[2025-11-23 23:06:45,239984][I][examples/fsdp_tp:308:train] epoch=10 iter=2 loss=12.415751 dt=0.122286 dtf=0.049377 dtb=0.072909
[2025-11-23 23:06:45,464267][I][examples/fsdp_tp:308:train] epoch=10 iter=3 loss=12.393296 dt=0.122091 dtf=0.049383 dtb=0.072708
[2025-11-23 23:06:45,679638][I][examples/fsdp_tp:308:train] epoch=10 iter=4 loss=12.246201 dt=0.122784 dtf=0.049629 dtb=0.073155
[2025-11-23 23:06:45,827951][I][examples/fsdp_tp:308:train] epoch=10 iter=5 loss=11.883405 dt=0.122394 dtf=0.049512 dtb=0.072883
[2025-11-23 23:06:46,041688][I][examples/fsdp_tp:308:train] epoch=11 iter=0 loss=12.856655 dt=0.122550 dtf=0.049232 dtb=0.073318
[2025-11-23 23:06:46,264821][I][examples/fsdp_tp:308:train] epoch=11 iter=1 loss=12.811150 dt=0.122968 dtf=0.049347 dtb=0.073621
[2025-11-23 23:06:46,480055][I][examples/fsdp_tp:308:train] epoch=11 iter=2 loss=13.198070 dt=0.122347 dtf=0.049242 dtb=0.073105
[2025-11-23 23:06:46,700635][I][examples/fsdp_tp:308:train] epoch=11 iter=3 loss=13.334132 dt=0.122341 dtf=0.049529 dtb=0.072811
[2025-11-23 23:06:46,925191][I][examples/fsdp_tp:308:train] epoch=11 iter=4 loss=13.228088 dt=0.122247 dtf=0.049298 dtb=0.072949
[2025-11-23 23:06:47,065093][I][examples/fsdp_tp:308:train] epoch=11 iter=5 loss=12.851110 dt=0.122495 dtf=0.049281 dtb=0.073214
[2025-11-23 23:06:47,279670][I][examples/fsdp_tp:308:train] epoch=12 iter=0 loss=14.056909 dt=0.121935 dtf=0.049128 dtb=0.072806
[2025-11-23 23:06:47,639209][I][examples/fsdp_tp:308:train] epoch=12 iter=1 loss=14.098704 dt=0.122178 dtf=0.049382 dtb=0.072796
[2025-11-23 23:06:47,859713][I][examples/fsdp_tp:308:train] epoch=12 iter=2 loss=14.764065 dt=0.122522 dtf=0.049439 dtb=0.073083
[2025-11-23 23:06:48,074555][I][examples/fsdp_tp:308:train] epoch=12 iter=3 loss=14.825414 dt=0.122171 dtf=0.049213 dtb=0.072958
[2025-11-23 23:06:48,294681][I][examples/fsdp_tp:308:train] epoch=12 iter=4 loss=14.635264 dt=0.122566 dtf=0.049523 dtb=0.073043
[2025-11-23 23:06:48,440413][I][examples/fsdp_tp:308:train] epoch=12 iter=5 loss=13.876326 dt=0.122501 dtf=0.049481 dtb=0.073020
[2025-11-23 23:06:48,653376][I][examples/fsdp_tp:308:train] epoch=13 iter=0 loss=14.916657 dt=0.122461 dtf=0.049292 dtb=0.073169
[2025-11-23 23:06:48,877657][I][examples/fsdp_tp:308:train] epoch=13 iter=1 loss=14.696300 dt=0.122281 dtf=0.049425 dtb=0.072855
[2025-11-23 23:06:49,092180][I][examples/fsdp_tp:308:train] epoch=13 iter=2 loss=15.874860 dt=0.122447 dtf=0.049470 dtb=0.072977
[2025-11-23 23:06:49,315625][I][examples/fsdp_tp:308:train] epoch=13 iter=3 loss=15.957263 dt=0.122345 dtf=0.049407 dtb=0.072938
[2025-11-23 23:06:49,530883][I][examples/fsdp_tp:308:train] epoch=13 iter=4 loss=16.065737 dt=0.122022 dtf=0.049268 dtb=0.072754
[2025-11-23 23:06:49,676898][I][examples/fsdp_tp:308:train] epoch=13 iter=5 loss=15.163090 dt=0.122442 dtf=0.049452 dtb=0.072990
[2025-11-23 23:06:49,890808][I][examples/fsdp_tp:308:train] epoch=14 iter=0 loss=16.230541 dt=0.122406 dtf=0.049243 dtb=0.073163
[2025-11-23 23:06:50,111644][I][examples/fsdp_tp:308:train] epoch=14 iter=1 loss=15.773082 dt=0.122045 dtf=0.049291 dtb=0.072754
[2025-11-23 23:06:50,332611][I][examples/fsdp_tp:308:train] epoch=14 iter=2 loss=16.666008 dt=0.122141 dtf=0.049277 dtb=0.072864
[2025-11-23 23:06:50,552521][I][examples/fsdp_tp:308:train] epoch=14 iter=3 loss=16.454384 dt=0.122641 dtf=0.049392 dtb=0.073250
[2025-11-23 23:06:50,776164][I][examples/fsdp_tp:308:train] epoch=14 iter=4 loss=16.518511 dt=0.122859 dtf=0.049287 dtb=0.073572
[2025-11-23 23:06:50,917009][I][examples/fsdp_tp:308:train] epoch=14 iter=5 loss=15.399554 dt=0.122454 dtf=0.049179 dtb=0.073275
[2025-11-23 23:06:51,132162][I][examples/fsdp_tp:308:train] epoch=15 iter=0 loss=16.235270 dt=0.122402 dtf=0.049231 dtb=0.073171
[2025-11-23 23:06:51,352490][I][examples/fsdp_tp:308:train] epoch=15 iter=1 loss=15.971088 dt=0.122202 dtf=0.049407 dtb=0.072795
[2025-11-23 23:06:51,571696][I][examples/fsdp_tp:308:train] epoch=15 iter=2 loss=16.338003 dt=0.122139 dtf=0.049288 dtb=0.072852
[2025-11-23 23:06:51,790557][I][examples/fsdp_tp:308:train] epoch=15 iter=3 loss=16.204199 dt=0.122074 dtf=0.049375 dtb=0.072699
[2025-11-23 23:06:52,010033][I][examples/fsdp_tp:308:train] epoch=15 iter=4 loss=16.398516 dt=0.122454 dtf=0.049409 dtb=0.073045
[2025-11-23 23:06:52,288043][I][examples/fsdp_tp:308:train] epoch=15 iter=5 loss=15.457146 dt=0.269943 dtf=0.195748 dtb=0.074195
[2025-11-23 23:06:52,505327][I][examples/fsdp_tp:308:train] epoch=16 iter=0 loss=16.111267 dt=0.123112 dtf=0.049421 dtb=0.073691
[2025-11-23 23:06:52,720159][I][examples/fsdp_tp:308:train] epoch=16 iter=1 loss=16.180702 dt=0.121935 dtf=0.049263 dtb=0.072672
[2025-11-23 23:06:52,943282][I][examples/fsdp_tp:308:train] epoch=16 iter=2 loss=16.012962 dt=0.122520 dtf=0.049432 dtb=0.073088
[2025-11-23 23:06:53,158705][I][examples/fsdp_tp:308:train] epoch=16 iter=3 loss=16.060072 dt=0.122268 dtf=0.049502 dtb=0.072766
[2025-11-23 23:06:53,379415][I][examples/fsdp_tp:308:train] epoch=16 iter=4 loss=16.258642 dt=0.122474 dtf=0.049466 dtb=0.073008
[2025-11-23 23:06:53,524475][I][examples/fsdp_tp:308:train] epoch=16 iter=5 loss=15.665180 dt=0.123044 dtf=0.049505 dtb=0.073539
[2025-11-23 23:06:53,738226][I][examples/fsdp_tp:308:train] epoch=17 iter=0 loss=16.085276 dt=0.122252 dtf=0.049279 dtb=0.072974
[2025-11-23 23:06:53,962048][I][examples/fsdp_tp:308:train] epoch=17 iter=1 loss=16.332842 dt=0.122653 dtf=0.049593 dtb=0.073059
[2025-11-23 23:06:54,176919][I][examples/fsdp_tp:308:train] epoch=17 iter=2 loss=15.961667 dt=0.123412 dtf=0.049410 dtb=0.074002
[2025-11-23 23:06:54,397081][I][examples/fsdp_tp:308:train] epoch=17 iter=3 loss=16.217127 dt=0.122643 dtf=0.049588 dtb=0.073056
[2025-11-23 23:06:54,615675][I][examples/fsdp_tp:308:train] epoch=17 iter=4 loss=16.383659 dt=0.122660 dtf=0.049480 dtb=0.073180
[2025-11-23 23:06:54,753495][I][examples/fsdp_tp:308:train] epoch=17 iter=5 loss=16.160299 dt=0.123051 dtf=0.049700 dtb=0.073351
[2025-11-23 23:06:55,107852][I][examples/fsdp_tp:308:train] epoch=18 iter=0 loss=16.487642 dt=0.122452 dtf=0.049279 dtb=0.073173
[2025-11-23 23:06:55,322942][I][examples/fsdp_tp:308:train] epoch=18 iter=1 loss=16.763620 dt=0.122354 dtf=0.049490 dtb=0.072864
[2025-11-23 23:06:55,539203][I][examples/fsdp_tp:308:train] epoch=18 iter=2 loss=16.489244 dt=0.122438 dtf=0.049270 dtb=0.073168
[2025-11-23 23:06:55,753393][I][examples/fsdp_tp:308:train] epoch=18 iter=3 loss=16.843599 dt=0.122065 dtf=0.049502 dtb=0.072563
[2025-11-23 23:06:55,966676][I][examples/fsdp_tp:308:train] epoch=18 iter=4 loss=16.894737 dt=0.122404 dtf=0.049410 dtb=0.072993
[2025-11-23 23:06:56,103073][I][examples/fsdp_tp:308:train] epoch=18 iter=5 loss=16.951342 dt=0.122779 dtf=0.049364 dtb=0.073416
[2025-11-23 23:06:56,318994][I][examples/fsdp_tp:308:train] epoch=19 iter=0 loss=17.173468 dt=0.122359 dtf=0.049373 dtb=0.072986
[2025-11-23 23:06:56,533672][I][examples/fsdp_tp:308:train] epoch=19 iter=1 loss=17.334078 dt=0.122477 dtf=0.049582 dtb=0.072895
[2025-11-23 23:06:56,748668][I][examples/fsdp_tp:308:train] epoch=19 iter=2 loss=17.264269 dt=0.123050 dtf=0.049547 dtb=0.073504
[2025-11-23 23:06:56,961833][I][examples/fsdp_tp:308:train] epoch=19 iter=3 loss=17.610270 dt=0.122646 dtf=0.049410 dtb=0.073237
[2025-11-23 23:06:57,179366][I][examples/fsdp_tp:308:train] epoch=19 iter=4 loss=17.515657 dt=0.123055 dtf=0.049570 dtb=0.073485
[2025-11-23 23:06:57,315246][I][examples/fsdp_tp:308:train] epoch=19 iter=5 loss=17.701851 dt=0.122617 dtf=0.049356 dtb=0.073261
[2025-11-23 23:06:57,530332][I][examples/fsdp_tp:308:train] epoch=20 iter=0 loss=17.728531 dt=0.122915 dtf=0.049634 dtb=0.073281
[2025-11-23 23:06:57,744788][I][examples/fsdp_tp:308:train] epoch=20 iter=1 loss=17.759817 dt=0.123194 dtf=0.049618 dtb=0.073576
[2025-11-23 23:06:57,958303][I][examples/fsdp_tp:308:train] epoch=20 iter=2 loss=17.859909 dt=0.123137 dtf=0.049716 dtb=0.073421
[2025-11-23 23:06:58,172316][I][examples/fsdp_tp:308:train] epoch=20 iter=3 loss=18.144938 dt=0.123008 dtf=0.049762 dtb=0.073246
[2025-11-23 23:06:58,387807][I][examples/fsdp_tp:308:train] epoch=20 iter=4 loss=17.984995 dt=0.122635 dtf=0.049489 dtb=0.073147
[2025-11-23 23:06:58,524394][I][examples/fsdp_tp:308:train] epoch=20 iter=5 loss=18.271450 dt=0.122825 dtf=0.049397 dtb=0.073428
[2025-11-23 23:06:58,737585][I][examples/fsdp_tp:308:train] epoch=21 iter=0 loss=18.050558 dt=0.122424 dtf=0.049310 dtb=0.073114
[2025-11-23 23:06:58,952246][I][examples/fsdp_tp:308:train] epoch=21 iter=1 loss=18.089947 dt=0.122815 dtf=0.049536 dtb=0.073279
[2025-11-23 23:06:59,167893][I][examples/fsdp_tp:308:train] epoch=21 iter=2 loss=18.310678 dt=0.122582 dtf=0.049270 dtb=0.073312
[2025-11-23 23:06:59,383574][I][examples/fsdp_tp:308:train] epoch=21 iter=3 loss=18.545444 dt=0.123272 dtf=0.049463 dtb=0.073809
[2025-11-23 23:06:59,598691][I][examples/fsdp_tp:308:train] epoch=21 iter=4 loss=18.443415 dt=0.123231 dtf=0.049283 dtb=0.073948
[2025-11-23 23:06:59,734457][I][examples/fsdp_tp:308:train] epoch=21 iter=5 loss=18.726521 dt=0.122606 dtf=0.049170 dtb=0.073435
[2025-11-23 23:06:59,948654][I][examples/fsdp_tp:308:train] epoch=22 iter=0 loss=18.364002 dt=0.122389 dtf=0.049303 dtb=0.073086
[2025-11-23 23:07:00,163775][I][examples/fsdp_tp:308:train] epoch=22 iter=1 loss=18.490095 dt=0.122192 dtf=0.049278 dtb=0.072914
[2025-11-23 23:07:00,379210][I][examples/fsdp_tp:308:train] epoch=22 iter=2 loss=18.751986 dt=0.122438 dtf=0.049349 dtb=0.073089
[2025-11-23 23:07:00,595488][I][examples/fsdp_tp:308:train] epoch=22 iter=3 loss=18.875053 dt=0.123177 dtf=0.049565 dtb=0.073612
[2025-11-23 23:07:00,808810][I][examples/fsdp_tp:308:train] epoch=22 iter=4 loss=18.799135 dt=0.122987 dtf=0.049193 dtb=0.073794
[2025-11-23 23:07:00,946620][I][examples/fsdp_tp:308:train] epoch=22 iter=5 loss=18.941025 dt=0.122506 dtf=0.049247 dtb=0.073259
[2025-11-23 23:07:01,161259][I][examples/fsdp_tp:308:train] epoch=23 iter=0 loss=18.439051 dt=0.122470 dtf=0.049458 dtb=0.073012
[2025-11-23 23:07:01,374688][I][examples/fsdp_tp:308:train] epoch=23 iter=1 loss=18.515509 dt=0.122683 dtf=0.049242 dtb=0.073441
[2025-11-23 23:07:01,590834][I][examples/fsdp_tp:308:train] epoch=23 iter=2 loss=18.700586 dt=0.123159 dtf=0.049194 dtb=0.073965
[2025-11-23 23:07:01,805116][I][examples/fsdp_tp:308:train] epoch=23 iter=3 loss=18.667227 dt=0.123180 dtf=0.049397 dtb=0.073783
[2025-11-23 23:07:02,018434][I][examples/fsdp_tp:308:train] epoch=23 iter=4 loss=18.608809 dt=0.122738 dtf=0.049251 dtb=0.073487
[2025-11-23 23:07:02,155234][I][examples/fsdp_tp:308:train] epoch=23 iter=5 loss=18.679363 dt=0.122947 dtf=0.049627 dtb=0.073320
[2025-11-23 23:07:02,370134][I][examples/fsdp_tp:308:train] epoch=24 iter=0 loss=18.089754 dt=0.122987 dtf=0.049253 dtb=0.073734
[2025-11-23 23:07:02,583967][I][examples/fsdp_tp:308:train] epoch=24 iter=1 loss=18.084196 dt=0.123340 dtf=0.049373 dtb=0.073967
[2025-11-23 23:07:02,798130][I][examples/fsdp_tp:308:train] epoch=24 iter=2 loss=18.199572 dt=0.122620 dtf=0.049251 dtb=0.073369
[2025-11-23 23:07:03,013770][I][examples/fsdp_tp:308:train] epoch=24 iter=3 loss=18.076864 dt=0.122212 dtf=0.049288 dtb=0.072924
[2025-11-23 23:07:03,227783][I][examples/fsdp_tp:308:train] epoch=24 iter=4 loss=18.069027 dt=0.123358 dtf=0.049293 dtb=0.074065
[2025-11-23 23:07:03,364658][I][examples/fsdp_tp:308:train] epoch=24 iter=5 loss=17.988300 dt=0.122608 dtf=0.049256 dtb=0.073352
[2025-11-23 23:07:03,578745][I][examples/fsdp_tp:308:train] epoch=25 iter=0 loss=17.466299 dt=0.122610 dtf=0.049445 dtb=0.073166
[2025-11-23 23:07:03,791329][I][examples/fsdp_tp:308:train] epoch=25 iter=1 loss=17.447611 dt=0.122244 dtf=0.049209 dtb=0.073035
[2025-11-23 23:07:04,006170][I][examples/fsdp_tp:308:train] epoch=25 iter=2 loss=17.468277 dt=0.122323 dtf=0.049320 dtb=0.073002
[2025-11-23 23:07:04,222689][I][examples/fsdp_tp:308:train] epoch=25 iter=3 loss=17.268341 dt=0.122341 dtf=0.049407 dtb=0.072935
[2025-11-23 23:07:04,439195][I][examples/fsdp_tp:308:train] epoch=25 iter=4 loss=17.265757 dt=0.122454 dtf=0.049404 dtb=0.073050
[2025-11-23 23:07:04,575738][I][examples/fsdp_tp:308:train] epoch=25 iter=5 loss=16.888145 dt=0.122546 dtf=0.049233 dtb=0.073313
[2025-11-23 23:07:04,789117][I][examples/fsdp_tp:308:train] epoch=26 iter=0 loss=16.638697 dt=0.122383 dtf=0.049219 dtb=0.073164
[2025-11-23 23:07:05,001547][I][examples/fsdp_tp:308:train] epoch=26 iter=1 loss=16.693640 dt=0.122415 dtf=0.049317 dtb=0.073098
[2025-11-23 23:07:05,215980][I][examples/fsdp_tp:308:train] epoch=26 iter=2 loss=16.621099 dt=0.122729 dtf=0.049098 dtb=0.073631
[2025-11-23 23:07:05,433056][I][examples/fsdp_tp:308:train] epoch=26 iter=3 loss=16.468100 dt=0.122989 dtf=0.049382 dtb=0.073607
[2025-11-23 23:07:05,648961][I][examples/fsdp_tp:308:train] epoch=26 iter=4 loss=16.566025 dt=0.122757 dtf=0.049450 dtb=0.073307
[2025-11-23 23:07:05,785036][I][examples/fsdp_tp:308:train] epoch=26 iter=5 loss=16.075815 dt=0.122556 dtf=0.049210 dtb=0.073346
[2025-11-23 23:07:05,999712][I][examples/fsdp_tp:308:train] epoch=27 iter=0 loss=16.189119 dt=0.122300 dtf=0.049106 dtb=0.073194
[2025-11-23 23:07:06,213488][I][examples/fsdp_tp:308:train] epoch=27 iter=1 loss=16.398449 dt=0.122207 dtf=0.049176 dtb=0.073032
[2025-11-23 23:07:06,427231][I][examples/fsdp_tp:308:train] epoch=27 iter=2 loss=16.243269 dt=0.122509 dtf=0.049273 dtb=0.073236
[2025-11-23 23:07:06,643435][I][examples/fsdp_tp:308:train] epoch=27 iter=3 loss=16.173407 dt=0.122619 dtf=0.049489 dtb=0.073130
[2025-11-23 23:07:06,858766][I][examples/fsdp_tp:308:train] epoch=27 iter=4 loss=16.369158 dt=0.122482 dtf=0.049335 dtb=0.073146
[2025-11-23 23:07:06,995653][I][examples/fsdp_tp:308:train] epoch=27 iter=5 loss=15.978488 dt=0.122520 dtf=0.049209 dtb=0.073310
[2025-11-23 23:07:07,210373][I][examples/fsdp_tp:308:train] epoch=28 iter=0 loss=16.132963 dt=0.122191 dtf=0.049256 dtb=0.072935
[2025-11-23 23:07:07,424435][I][examples/fsdp_tp:308:train] epoch=28 iter=1 loss=16.419313 dt=0.122885 dtf=0.049273 dtb=0.073612
[2025-11-23 23:07:07,638575][I][examples/fsdp_tp:308:train] epoch=28 iter=2 loss=16.092634 dt=0.123347 dtf=0.049181 dtb=0.074167
[2025-11-23 23:07:07,853468][I][examples/fsdp_tp:308:train] epoch=28 iter=3 loss=16.027536 dt=0.123417 dtf=0.049727 dtb=0.073690
[2025-11-23 23:07:08,068517][I][examples/fsdp_tp:308:train] epoch=28 iter=4 loss=16.209948 dt=0.122364 dtf=0.049432 dtb=0.072932
[2025-11-23 23:07:08,204836][I][examples/fsdp_tp:308:train] epoch=28 iter=5 loss=15.868900 dt=0.123437 dtf=0.049496 dtb=0.073941
[2025-11-23 23:07:08,418549][I][examples/fsdp_tp:308:train] epoch=29 iter=0 loss=15.914735 dt=0.122371 dtf=0.049086 dtb=0.073285
[2025-11-23 23:07:08,632711][I][examples/fsdp_tp:308:train] epoch=29 iter=1 loss=16.166750 dt=0.122311 dtf=0.049219 dtb=0.073092
[2025-11-23 23:07:08,848295][I][examples/fsdp_tp:308:train] epoch=29 iter=2 loss=15.645642 dt=0.122216 dtf=0.049155 dtb=0.073061
[2025-11-23 23:07:09,062847][I][examples/fsdp_tp:308:train] epoch=29 iter=3 loss=15.561935 dt=0.122414 dtf=0.049449 dtb=0.072966
[2025-11-23 23:07:09,277521][I][examples/fsdp_tp:308:train] epoch=29 iter=4 loss=15.719699 dt=0.123306 dtf=0.049506 dtb=0.073800
[2025-11-23 23:07:09,414112][I][examples/fsdp_tp:308:train] epoch=29 iter=5 loss=15.408589 dt=0.123981 dtf=0.049371 dtb=0.074611
[2025-11-23 23:07:09,628460][I][examples/fsdp_tp:308:train] epoch=30 iter=0 loss=15.491020 dt=0.122711 dtf=0.049125 dtb=0.073586
[2025-11-23 23:07:09,842391][I][examples/fsdp_tp:308:train] epoch=30 iter=1 loss=15.741310 dt=0.122003 dtf=0.049164 dtb=0.072840
[2025-11-23 23:07:10,056274][I][examples/fsdp_tp:308:train] epoch=30 iter=2 loss=15.120818 dt=0.122357 dtf=0.049223 dtb=0.073133
[2025-11-23 23:07:10,272805][I][examples/fsdp_tp:308:train] epoch=30 iter=3 loss=15.023593 dt=0.122783 dtf=0.049825 dtb=0.072958
[2025-11-23 23:07:10,485921][I][examples/fsdp_tp:308:train] epoch=30 iter=4 loss=15.124940 dt=0.122045 dtf=0.049208 dtb=0.072837
[2025-11-23 23:07:10,624073][I][examples/fsdp_tp:308:train] epoch=30 iter=5 loss=14.686823 dt=0.122820 dtf=0.049407 dtb=0.073413
[2025-11-23 23:07:10,837347][I][examples/fsdp_tp:308:train] epoch=31 iter=0 loss=15.006373 dt=0.122420 dtf=0.049393 dtb=0.073027
[2025-11-23 23:07:11,051520][I][examples/fsdp_tp:308:train] epoch=31 iter=1 loss=15.230182 dt=0.122861 dtf=0.049334 dtb=0.073528
[2025-11-23 23:07:11,267732][I][examples/fsdp_tp:308:train] epoch=31 iter=2 loss=14.648965 dt=0.122740 dtf=0.049410 dtb=0.073330
[2025-11-23 23:07:11,482457][I][examples/fsdp_tp:308:train] epoch=31 iter=3 loss=14.579422 dt=0.122868 dtf=0.049838 dtb=0.073030
[2025-11-23 23:07:11,697101][I][examples/fsdp_tp:308:train] epoch=31 iter=4 loss=14.691770 dt=0.122745 dtf=0.049261 dtb=0.073484
[2025-11-23 23:07:11,834407][I][examples/fsdp_tp:308:train] epoch=31 iter=5 loss=14.169790 dt=0.122682 dtf=0.049321 dtb=0.073361
[2025-11-23 23:07:12,048196][I][examples/fsdp_tp:308:train] epoch=32 iter=0 loss=14.977160 dt=0.122813 dtf=0.049180 dtb=0.073633
[2025-11-23 23:07:12,262811][I][examples/fsdp_tp:308:train] epoch=32 iter=1 loss=15.313783 dt=0.122420 dtf=0.049229 dtb=0.073191
[2025-11-23 23:07:12,475235][I][examples/fsdp_tp:308:train] epoch=32 iter=2 loss=14.961360 dt=0.122349 dtf=0.049314 dtb=0.073035
[2025-11-23 23:07:12,690369][I][examples/fsdp_tp:308:train] epoch=32 iter=3 loss=15.031002 dt=0.121973 dtf=0.049280 dtb=0.072693
[2025-11-23 23:07:12,905457][I][examples/fsdp_tp:308:train] epoch=32 iter=4 loss=15.182728 dt=0.122659 dtf=0.049152 dtb=0.073507
[2025-11-23 23:07:13,042226][I][examples/fsdp_tp:308:train] epoch=32 iter=5 loss=14.563988 dt=0.122532 dtf=0.049144 dtb=0.073388
[2025-11-23 23:07:13,256830][I][examples/fsdp_tp:308:train] epoch=33 iter=0 loss=15.726024 dt=0.122276 dtf=0.049256 dtb=0.073020
[2025-11-23 23:07:13,470744][I][examples/fsdp_tp:308:train] epoch=33 iter=1 loss=15.943748 dt=0.121787 dtf=0.049084 dtb=0.072703
[2025-11-23 23:07:13,685273][I][examples/fsdp_tp:308:train] epoch=33 iter=2 loss=15.627631 dt=0.122853 dtf=0.049442 dtb=0.073411
[2025-11-23 23:07:13,900851][I][examples/fsdp_tp:308:train] epoch=33 iter=3 loss=15.604465 dt=0.123142 dtf=0.049264 dtb=0.073879
[2025-11-23 23:07:14,114678][I][examples/fsdp_tp:308:train] epoch=33 iter=4 loss=15.555977 dt=0.122558 dtf=0.049284 dtb=0.073274
[2025-11-23 23:07:14,251029][I][examples/fsdp_tp:308:train] epoch=33 iter=5 loss=14.675238 dt=0.122377 dtf=0.049194 dtb=0.073183
[2025-11-23 23:07:14,465844][I][examples/fsdp_tp:308:train] epoch=34 iter=0 loss=15.923055 dt=0.122315 dtf=0.049218 dtb=0.073097
[2025-11-23 23:07:14,679811][I][examples/fsdp_tp:308:train] epoch=34 iter=1 loss=15.916331 dt=0.123057 dtf=0.049644 dtb=0.073413
[2025-11-23 23:07:14,894385][I][examples/fsdp_tp:308:train] epoch=34 iter=2 loss=15.589166 dt=0.122935 dtf=0.049373 dtb=0.073562
[2025-11-23 23:07:15,108871][I][examples/fsdp_tp:308:train] epoch=34 iter=3 loss=15.460347 dt=0.122969 dtf=0.049519 dtb=0.073450
[2025-11-23 23:07:15,323462][I][examples/fsdp_tp:308:train] epoch=34 iter=4 loss=15.288394 dt=0.123558 dtf=0.049298 dtb=0.074259
[2025-11-23 23:07:15,459986][I][examples/fsdp_tp:308:train] epoch=34 iter=5 loss=14.310595 dt=0.122837 dtf=0.049219 dtb=0.073618
[2025-11-23 23:07:15,673261][I][examples/fsdp_tp:308:train] epoch=35 iter=0 loss=15.581965 dt=0.122373 dtf=0.049310 dtb=0.073063
[2025-11-23 23:07:15,888036][I][examples/fsdp_tp:308:train] epoch=35 iter=1 loss=15.479309 dt=0.122523 dtf=0.049480 dtb=0.073043
[2025-11-23 23:07:16,103101][I][examples/fsdp_tp:308:train] epoch=35 iter=2 loss=15.209507 dt=0.122687 dtf=0.049282 dtb=0.073405
[2025-11-23 23:07:16,315979][I][examples/fsdp_tp:308:train] epoch=35 iter=3 loss=15.092275 dt=0.122294 dtf=0.049470 dtb=0.072825
[2025-11-23 23:07:16,533618][I][examples/fsdp_tp:308:train] epoch=35 iter=4 loss=14.894475 dt=0.122482 dtf=0.049179 dtb=0.073303
[2025-11-23 23:07:16,669476][I][examples/fsdp_tp:308:train] epoch=35 iter=5 loss=13.985127 dt=0.123512 dtf=0.049430 dtb=0.074082
[2025-11-23 23:07:16,882848][I][examples/fsdp_tp:308:train] epoch=36 iter=0 loss=15.094238 dt=0.122408 dtf=0.049220 dtb=0.073188
[2025-11-23 23:07:17,098814][I][examples/fsdp_tp:308:train] epoch=36 iter=1 loss=14.933116 dt=0.123201 dtf=0.049401 dtb=0.073800
[2025-11-23 23:07:17,313691][I][examples/fsdp_tp:308:train] epoch=36 iter=2 loss=14.705409 dt=0.122542 dtf=0.049335 dtb=0.073207
[2025-11-23 23:07:17,529133][I][examples/fsdp_tp:308:train] epoch=36 iter=3 loss=14.595841 dt=0.122905 dtf=0.049576 dtb=0.073330
[2025-11-23 23:07:17,743286][I][examples/fsdp_tp:308:train] epoch=36 iter=4 loss=14.392354 dt=0.122468 dtf=0.049158 dtb=0.073310
[2025-11-23 23:07:17,880704][I][examples/fsdp_tp:308:train] epoch=36 iter=5 loss=13.607084 dt=0.123447 dtf=0.049326 dtb=0.074120
[2025-11-23 23:07:18,095651][I][examples/fsdp_tp:308:train] epoch=37 iter=0 loss=14.454063 dt=0.122522 dtf=0.049324 dtb=0.073198
[2025-11-23 23:07:18,308980][I][examples/fsdp_tp:308:train] epoch=37 iter=1 loss=14.271518 dt=0.122336 dtf=0.049385 dtb=0.072951
[2025-11-23 23:07:18,523546][I][examples/fsdp_tp:308:train] epoch=37 iter=2 loss=14.084026 dt=0.122399 dtf=0.049299 dtb=0.073100
[2025-11-23 23:07:18,738292][I][examples/fsdp_tp:308:train] epoch=37 iter=3 loss=14.005614 dt=0.122290 dtf=0.049340 dtb=0.072950
[2025-11-23 23:07:18,953703][I][examples/fsdp_tp:308:train] epoch=37 iter=4 loss=13.855595 dt=0.122690 dtf=0.049274 dtb=0.073417
[2025-11-23 23:07:19,091919][I][examples/fsdp_tp:308:train] epoch=37 iter=5 loss=13.252406 dt=0.123758 dtf=0.049506 dtb=0.074252
[2025-11-23 23:07:19,306594][I][examples/fsdp_tp:308:train] epoch=38 iter=0 loss=13.863391 dt=0.123036 dtf=0.049512 dtb=0.073524
[2025-11-23 23:07:19,520647][I][examples/fsdp_tp:308:train] epoch=38 iter=1 loss=13.709941 dt=0.122331 dtf=0.049310 dtb=0.073021
[2025-11-23 23:07:19,734393][I][examples/fsdp_tp:308:train] epoch=38 iter=2 loss=13.590042 dt=0.122270 dtf=0.049320 dtb=0.072950
[2025-11-23 23:07:19,950304][I][examples/fsdp_tp:308:train] epoch=38 iter=3 loss=13.552207 dt=0.123414 dtf=0.049571 dtb=0.073843
[2025-11-23 23:07:20,163827][I][examples/fsdp_tp:308:train] epoch=38 iter=4 loss=13.462181 dt=0.122770 dtf=0.049254 dtb=0.073517
[2025-11-23 23:07:20,301654][I][examples/fsdp_tp:308:train] epoch=38 iter=5 loss=13.023455 dt=0.123348 dtf=0.049443 dtb=0.073905
[2025-11-23 23:07:20,515538][I][examples/fsdp_tp:308:train] epoch=39 iter=0 loss=13.407180 dt=0.122924 dtf=0.049374 dtb=0.073550
[2025-11-23 23:07:20,731119][I][examples/fsdp_tp:308:train] epoch=39 iter=1 loss=13.264835 dt=0.122251 dtf=0.049150 dtb=0.073101
[2025-11-23 23:07:20,945324][I][examples/fsdp_tp:308:train] epoch=39 iter=2 loss=13.161559 dt=0.122359 dtf=0.049285 dtb=0.073074
[2025-11-23 23:07:21,159233][I][examples/fsdp_tp:308:train] epoch=39 iter=3 loss=13.096499 dt=0.122368 dtf=0.049386 dtb=0.072983
[2025-11-23 23:07:21,374601][I][examples/fsdp_tp:308:train] epoch=39 iter=4 loss=12.998965 dt=0.123126 dtf=0.049300 dtb=0.073826
[2025-11-23 23:07:21,510642][I][examples/fsdp_tp:308:train] epoch=39 iter=5 loss=12.632070 dt=0.122735 dtf=0.049283 dtb=0.073452
[2025-11-23 23:07:21,725280][I][examples/fsdp_tp:308:train] epoch=40 iter=0 loss=12.784514 dt=0.123404 dtf=0.049565 dtb=0.073839
[2025-11-23 23:07:21,940982][I][examples/fsdp_tp:308:train] epoch=40 iter=1 loss=12.623932 dt=0.122559 dtf=0.049177 dtb=0.073382
[2025-11-23 23:07:22,154780][I][examples/fsdp_tp:308:train] epoch=40 iter=2 loss=12.473991 dt=0.122384 dtf=0.049122 dtb=0.073261
[2025-11-23 23:07:22,369657][I][examples/fsdp_tp:308:train] epoch=40 iter=3 loss=12.344390 dt=0.123309 dtf=0.049408 dtb=0.073901
[2025-11-23 23:07:22,586862][I][examples/fsdp_tp:308:train] epoch=40 iter=4 loss=12.196277 dt=0.122713 dtf=0.049349 dtb=0.073364
[2025-11-23 23:07:22,721663][I][examples/fsdp_tp:308:train] epoch=40 iter=5 loss=11.857025 dt=0.123207 dtf=0.049243 dtb=0.073964
[2025-11-23 23:07:22,936292][I][examples/fsdp_tp:308:train] epoch=41 iter=0 loss=11.859985 dt=0.122416 dtf=0.049278 dtb=0.073138
[2025-11-23 23:07:23,151334][I][examples/fsdp_tp:308:train] epoch=41 iter=1 loss=11.728287 dt=0.122449 dtf=0.049348 dtb=0.073101
[2025-11-23 23:07:23,364817][I][examples/fsdp_tp:308:train] epoch=41 iter=2 loss=11.574527 dt=0.122257 dtf=0.049283 dtb=0.072974
[2025-11-23 23:07:23,579881][I][examples/fsdp_tp:308:train] epoch=41 iter=3 loss=11.451840 dt=0.123147 dtf=0.049466 dtb=0.073681
[2025-11-23 23:07:23,795439][I][examples/fsdp_tp:308:train] epoch=41 iter=4 loss=11.354470 dt=0.122660 dtf=0.049189 dtb=0.073472
[2025-11-23 23:07:23,932336][I][examples/fsdp_tp:308:train] epoch=41 iter=5 loss=11.155550 dt=0.122508 dtf=0.049248 dtb=0.073260
[2025-11-23 23:07:24,145459][I][examples/fsdp_tp:308:train] epoch=42 iter=0 loss=11.268428 dt=0.122166 dtf=0.049088 dtb=0.073078
[2025-11-23 23:07:24,359004][I][examples/fsdp_tp:308:train] epoch=42 iter=1 loss=11.406644 dt=0.122976 dtf=0.049181 dtb=0.073795
[2025-11-23 23:07:24,573777][I][examples/fsdp_tp:308:train] epoch=42 iter=2 loss=11.469749 dt=0.122227 dtf=0.049216 dtb=0.073012
[2025-11-23 23:07:24,789840][I][examples/fsdp_tp:308:train] epoch=42 iter=3 loss=11.587611 dt=0.122412 dtf=0.049337 dtb=0.073074
[2025-11-23 23:07:25,004885][I][examples/fsdp_tp:308:train] epoch=42 iter=4 loss=11.755021 dt=0.121860 dtf=0.049121 dtb=0.072739
[2025-11-23 23:07:25,142800][I][examples/fsdp_tp:308:train] epoch=42 iter=5 loss=11.861668 dt=0.123083 dtf=0.049780 dtb=0.073303
[2025-11-23 23:07:25,356179][I][examples/fsdp_tp:308:train] epoch=43 iter=0 loss=12.265729 dt=0.122615 dtf=0.049300 dtb=0.073314
[2025-11-23 23:07:25,571464][I][examples/fsdp_tp:308:train] epoch=43 iter=1 loss=12.753016 dt=0.122835 dtf=0.049521 dtb=0.073315
[2025-11-23 23:07:25,785469][I][examples/fsdp_tp:308:train] epoch=43 iter=2 loss=13.034406 dt=0.122454 dtf=0.049255 dtb=0.073199
[2025-11-23 23:07:26,001128][I][examples/fsdp_tp:308:train] epoch=43 iter=3 loss=13.328734 dt=0.122224 dtf=0.049348 dtb=0.072875
[2025-11-23 23:07:26,217041][I][examples/fsdp_tp:308:train] epoch=43 iter=4 loss=13.637181 dt=0.122853 dtf=0.049391 dtb=0.073462
[2025-11-23 23:07:26,354558][I][examples/fsdp_tp:308:train] epoch=43 iter=5 loss=13.906071 dt=0.123875 dtf=0.049783 dtb=0.074092
[2025-11-23 23:07:26,569108][I][examples/fsdp_tp:308:train] epoch=44 iter=0 loss=14.425197 dt=0.122604 dtf=0.049260 dtb=0.073344
[2025-11-23 23:07:26,784059][I][examples/fsdp_tp:308:train] epoch=44 iter=1 loss=15.069877 dt=0.122719 dtf=0.049335 dtb=0.073384
[2025-11-23 23:07:26,997312][I][examples/fsdp_tp:308:train] epoch=44 iter=2 loss=15.386724 dt=0.122979 dtf=0.049261 dtb=0.073718
[2025-11-23 23:07:27,210571][I][examples/fsdp_tp:308:train] epoch=44 iter=3 loss=15.686360 dt=0.122715 dtf=0.049470 dtb=0.073245
[2025-11-23 23:07:27,426909][I][examples/fsdp_tp:308:train] epoch=44 iter=4 loss=15.963119 dt=0.123169 dtf=0.049808 dtb=0.073361
[2025-11-23 23:07:27,564435][I][examples/fsdp_tp:308:train] epoch=44 iter=5 loss=16.254913 dt=0.123010 dtf=0.049493 dtb=0.073517
[2025-11-23 23:07:27,777400][I][examples/fsdp_tp:308:train] epoch=45 iter=0 loss=16.736452 dt=0.122530 dtf=0.049244 dtb=0.073286
[2025-11-23 23:07:27,992558][I][examples/fsdp_tp:308:train] epoch=45 iter=1 loss=17.383436 dt=0.122652 dtf=0.049400 dtb=0.073252
[2025-11-23 23:07:28,207675][I][examples/fsdp_tp:308:train] epoch=45 iter=2 loss=17.602053 dt=0.122514 dtf=0.049430 dtb=0.073084
[2025-11-23 23:07:28,420375][I][examples/fsdp_tp:308:train] epoch=45 iter=3 loss=17.785009 dt=0.122582 dtf=0.049487 dtb=0.073095
[2025-11-23 23:07:28,637437][I][examples/fsdp_tp:308:train] epoch=45 iter=4 loss=17.915934 dt=0.122613 dtf=0.049469 dtb=0.073144
[2025-11-23 23:07:28,773336][I][examples/fsdp_tp:308:train] epoch=45 iter=5 loss=18.109262 dt=0.122922 dtf=0.049498 dtb=0.073424
[2025-11-23 23:07:28,986841][I][examples/fsdp_tp:308:train] epoch=46 iter=0 loss=18.445480 dt=0.122306 dtf=0.049182 dtb=0.073123
[2025-11-23 23:07:29,203090][I][examples/fsdp_tp:308:train] epoch=46 iter=1 loss=18.951139 dt=0.122595 dtf=0.049190 dtb=0.073405
[2025-11-23 23:07:29,416852][I][examples/fsdp_tp:308:train] epoch=46 iter=2 loss=18.969025 dt=0.122387 dtf=0.049147 dtb=0.073239
[2025-11-23 23:07:29,632074][I][examples/fsdp_tp:308:train] epoch=46 iter=3 loss=18.935678 dt=0.123333 dtf=0.049944 dtb=0.073389
[2025-11-23 23:07:29,848122][I][examples/fsdp_tp:308:train] epoch=46 iter=4 loss=18.846550 dt=0.122517 dtf=0.049372 dtb=0.073145
[2025-11-23 23:07:29,985198][I][examples/fsdp_tp:308:train] epoch=46 iter=5 loss=18.855362 dt=0.122986 dtf=0.049361 dtb=0.073625
[2025-11-23 23:07:30,198637][I][examples/fsdp_tp:308:train] epoch=47 iter=0 loss=18.931412 dt=0.122467 dtf=0.049336 dtb=0.073132
[2025-11-23 23:07:30,413187][I][examples/fsdp_tp:308:train] epoch=47 iter=1 loss=19.201500 dt=0.122561 dtf=0.049297 dtb=0.073264
[2025-11-23 23:07:30,628988][I][examples/fsdp_tp:308:train] epoch=47 iter=2 loss=18.958166 dt=0.122385 dtf=0.049142 dtb=0.073243
[2025-11-23 23:07:30,843143][I][examples/fsdp_tp:308:train] epoch=47 iter=3 loss=18.688080 dt=0.123212 dtf=0.049527 dtb=0.073684
[2025-11-23 23:07:31,058359][I][examples/fsdp_tp:308:train] epoch=47 iter=4 loss=18.354195 dt=0.123288 dtf=0.049653 dtb=0.073636
[2025-11-23 23:07:31,195246][I][examples/fsdp_tp:308:train] epoch=47 iter=5 loss=18.197393 dt=0.122845 dtf=0.049321 dtb=0.073524
[2025-11-23 23:07:31,409091][I][examples/fsdp_tp:308:train] epoch=48 iter=0 loss=17.974590 dt=0.122425 dtf=0.049267 dtb=0.073158
[2025-11-23 23:07:31,622917][I][examples/fsdp_tp:308:train] epoch=48 iter=1 loss=17.981524 dt=0.123202 dtf=0.049266 dtb=0.073936
[2025-11-23 23:07:31,838469][I][examples/fsdp_tp:308:train] epoch=48 iter=2 loss=17.532938 dt=0.122501 dtf=0.049277 dtb=0.073224
[2025-11-23 23:07:32,052027][I][examples/fsdp_tp:308:train] epoch=48 iter=3 loss=17.097700 dt=0.122542 dtf=0.049465 dtb=0.073077
[2025-11-23 23:07:32,268936][I][examples/fsdp_tp:308:train] epoch=48 iter=4 loss=16.575041 dt=0.122619 dtf=0.049291 dtb=0.073328
[2025-11-23 23:07:32,405056][I][examples/fsdp_tp:308:train] epoch=48 iter=5 loss=16.417542 dt=0.123154 dtf=0.049612 dtb=0.073542
[2025-11-23 23:07:32,618148][I][examples/fsdp_tp:308:train] epoch=49 iter=0 loss=15.919083 dt=0.122423 dtf=0.049192 dtb=0.073231
[2025-11-23 23:07:32,834362][I][examples/fsdp_tp:308:train] epoch=49 iter=1 loss=15.717862 dt=0.122603 dtf=0.049314 dtb=0.073289
[2025-11-23 23:07:33,050900][I][examples/fsdp_tp:308:train] epoch=49 iter=2 loss=15.197731 dt=0.122466 dtf=0.049328 dtb=0.073138
[2025-11-23 23:07:33,264905][I][examples/fsdp_tp:308:train] epoch=49 iter=3 loss=14.756850 dt=0.122378 dtf=0.049349 dtb=0.073029
[2025-11-23 23:07:33,479731][I][examples/fsdp_tp:308:train] epoch=49 iter=4 loss=14.158829 dt=0.122634 dtf=0.049205 dtb=0.073429
[2025-11-23 23:07:33,616836][I][examples/fsdp_tp:308:train] epoch=49 iter=5 loss=14.174994 dt=0.122690 dtf=0.049148 dtb=0.073542
[2025-11-23 23:07:33,617501][I][examples/fsdp_tp:322:train] Finished 2D training
[rank1]:[W1123 23:07:33.909582214 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank6]:[W1123 23:07:34.195988636 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank2]:[W1123 23:07:34.439077446 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank4]:[W1123 23:07:34.478394255 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank5]:[W1123 23:07:34.484271831 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:[W1123 23:07:34.454715740 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank7]:[W1123 23:07:34.970587080 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-11-23 23:07:35,531933][I][ezpz/history:810:plot_all] Saving train_epoch plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:07:35,713617][I][ezpz/history:810:plot_all] Saving train_iter plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:07:35,893974][I][ezpz/history:810:plot_all] Saving train_loss plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:07:36,062519][I][ezpz/history:810:plot_all] Saving train_dt plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:07:36,240849][I][ezpz/history:810:plot_all] Saving train_dtf plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:07:36,416070][I][ezpz/history:810:plot_all] Saving train_dtb plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:07:36,591822][I][ezpz/history:714:tplot_all] Saving tplots to /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot
                 train_epoch [2025-11-23-230736]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
49.0‚î§                                                  ‚ñÑ‚ñÑ‚ñü‚ñÄ‚îÇ
    ‚îÇ                                              ‚ñó‚ñÑ‚ñÑ‚ñÄ‚ñò   ‚îÇ
41.7‚î§                                           ‚ñÑ‚ñÑ‚ñû‚ñÄ       ‚îÇ
    ‚îÇ                                       ‚ñó‚ñÑ‚ñÑ‚ñÄ‚ñò          ‚îÇ
    ‚îÇ                                    ‚ñÑ‚ñÑ‚ñõ‚ñò              ‚îÇ
34.3‚î§                                ‚ñÑ‚ñÑ‚ñü‚ñÄ                  ‚îÇ
    ‚îÇ                            ‚ñó‚ñÑ‚ñÑ‚ñõ‚ñò                     ‚îÇ
27.0‚î§                         ‚ñÑ‚ñû‚ñÄ‚ñÄ                         ‚îÇ
    ‚îÇ                     ‚ñó‚ñü‚ñÄ‚ñÄ‚ñò                            ‚îÇ
19.7‚î§                  ‚ñÑ‚ñõ‚ñÄ‚ñÄ                                ‚îÇ
    ‚îÇ              ‚ñó‚ñü‚ñÄ‚ñÄ                                    ‚îÇ
    ‚îÇ          ‚ñó‚ñÑ‚ñÄ‚ñÄ‚ñò                                       ‚îÇ
12.3‚î§       ‚ñÑ‚ñû‚ñÄ‚ñÄ                                           ‚îÇ
    ‚îÇ   ‚ñó‚ñÑ‚ñÄ‚ñÄ‚ñò                                              ‚îÇ
 5.0‚î§‚ñÑ‚ñõ‚ñÄ‚ñÄ                                                  ‚îÇ
    ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
     2 15  35 51 66  87 103   135 151   182  207    243 268
train_epoch                   iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_epoch.txt
                 train_iter [2025-11-23-230736]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
5.00‚î§ ‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚îÇ
    ‚îÇ ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚îÇ
4.17‚î§ ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚îÇ
    ‚îÇ‚ñó‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñû‚îÇ
    ‚îÇ‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñå‚îÇ
3.33‚î§‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñå‚îÇ
    ‚îÇ‚ñê‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñå‚îÇ
2.50‚î§‚ñê‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñå‚îÇ
    ‚îÇ‚ñê‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñå‚îÇ
1.67‚î§‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
0.83‚î§‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê ‚îÇ
0.00‚î§‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê ‚îÇ
    ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
     2 15  35 51 66  87 103   135 151   182  207    243 268
train_iter                    iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_iter.txt
                 train_loss [2025-11-23-230736]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
19.2‚î§                    ‚ñÑ‚ñÑ‚ñÑ                          ‚ñÑ‚ñü   ‚îÇ
    ‚îÇ                  ‚ñü‚ñà‚ñÄ‚ñù‚ñê‚ñô                        ‚ñó‚ñò ‚ñö  ‚îÇ
17.1‚î§                ‚ñó‚ñõ      ‚ñú‚ññ                     ‚ñó‚ñò  ‚ñù‚ññ ‚îÇ
    ‚îÇ          ‚ñó‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñò        ‚ñÄ‚ñô‚ñÑ‚ññ‚ññ                 ‚ñê    ‚ñö ‚îÇ
    ‚îÇ         ‚ñó‚ñú‚ñú‚ñÄ‚ñå‚ñÄ            ‚ñò‚ñù‚ñà‚ñå‚ññ‚ñó‚ñû‚ñà‚ñô‚ñå          ‚ñõ    ‚ñù‚ññ‚îÇ
15.1‚î§        ‚ñó‚ñà                    ‚ñÄ‚ñô‚ñõ‚ñå‚ñú‚ñê‚ñê‚ñô‚ññ       ‚ñê      ‚ñå‚îÇ
    ‚îÇ        ‚ñû‚ñù                      ‚ñò    ‚ñò‚ñõ‚ñô‚ññ     ‚ñû      ‚ñù‚îÇ
13.0‚î§       ‚ñü‚ñå                              ‚ñò‚ñú‚ñö‚ññ  ‚ñê‚ñò       ‚îÇ
    ‚îÇ    ‚ñÑ ‚ñõ‚ñå                                  ‚ñÄ‚ññ ‚ñû        ‚îÇ
11.0‚î§  ‚ñÑ‚ñà‚ñú‚ñÄ‚ñò                                    ‚ñÄ‚ñõ         ‚îÇ
    ‚îÇ ‚ñó‚ñõ                                                   ‚îÇ
    ‚îÇ ‚ñû‚ñò                                                   ‚îÇ
 8.9‚î§‚ñê‚ñå                                                    ‚îÇ
    ‚îÇ‚ñå‚ñå                                                    ‚îÇ
 6.8‚î§‚ñå                                                     ‚îÇ
    ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
     2 15  35 51 66  87 103   135 151   182  207    243 268
train_loss                    iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_loss.txt
                  train_dt [2025-11-23-230736]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.270‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.245‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.221‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.196‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.171‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.146‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.122‚î§‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
      2 15  35 51 66  87 103  135 151   182  207    243 268
train_dt                      iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_dt.txt
                  train_dt [2025-11-23-230736]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
269.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
224.2‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
179.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
134.5‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 89.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 44.8‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
  0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
    0.115        0.156        0.196        0.236      0.277
freq                        train_dt
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_dt-hist.txt
                  train_dtf [2025-11-23-230736]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.196‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.171‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.147‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.122‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.098‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.074‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.049‚î§‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
      2 15  35 51 66  87 103  135 151   182  207    243 268
train_dtf                     iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_dtf.txt
                  train_dtf [2025-11-23-230736]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
269.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
224.2‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
179.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
134.5‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 89.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 44.8‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
  0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
    0.043        0.082        0.122        0.162      0.202
freq                        train_dtf
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_dtf-hist.txt
                   train_dtb [2025-11-23-230736]
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.07461‚î§                            ‚ñå                      ‚îÇ
       ‚îÇ                            ‚ñå                      ‚îÇ
0.07427‚î§                            ‚ñå    ‚ñó   ‚ññ             ‚îÇ
       ‚îÇ            ‚ñå             ‚ñü ‚ñå    ‚ñà‚ñó ‚ññ‚ñå     ‚ñó       ‚îÇ
       ‚îÇ            ‚ñå ‚ññ    ‚ññ‚ñó‚ñó‚ñå   ‚ñà‚ññ‚ñå    ‚ñà‚ñê‚ñê‚ñå‚ñå  ‚ñó  ‚ñê       ‚îÇ
0.07393‚î§     ‚ñó      ‚ñå‚ñê‚ñå   ‚ñê‚ñå‚ñê‚ñê‚ñå   ‚ñà‚ñå‚ñå   ‚ñå‚ñà‚ñê‚ñü‚ñå‚ñô‚ñå‚ñÑ‚ñà  ‚ñê    ‚ñê  ‚îÇ
       ‚îÇ ‚ñê   ‚ñê      ‚ñô‚ñê‚ñå   ‚ñê‚ñô‚ñà‚ñà‚ñå   ‚ñà‚ñà‚ñå   ‚ñå‚ñà‚ñê‚ñà‚ñå‚ñà‚ñå‚ñà‚ñà‚ñÑ‚ñå‚ñê‚ñó   ‚ñü  ‚îÇ
0.07359‚î§ ‚ñê‚ñü ‚ñå‚ñê ‚ñå   ‚ññ‚ñà‚ñê‚ñå  ‚ññ‚ñê‚ñà‚ñà‚ñà‚ñå ‚ñå ‚ñà‚ñà‚ñå‚ñó‚ñü ‚ñå‚ñà‚ñê‚ñà‚ñå‚ñà‚ñô‚ñà‚ñà‚ñà‚ñå‚ñê‚ñà‚ññ ‚ñà‚ñà‚ñó‚ñó‚îÇ
       ‚îÇ ‚ñà‚ñà ‚ñô‚ñê ‚ñå  ‚ñê‚ñå‚ñà‚ñà‚ñå‚ñó‚ñà‚ñô‚ñü‚ñà‚ñà‚ñà‚ñå ‚ñå ‚ñà‚ñà‚ñå‚ñü‚ñà‚ñô‚ñå‚ñà‚ñü‚ñà‚ñå‚ñà‚ñê‚ñà‚ñà‚ñà‚ñå‚ñê‚ñà‚ñå‚ñÑ‚ñà‚ñà‚ñà‚ñê‚îÇ
0.07325‚î§ ‚ñà‚ñà ‚ñà‚ñê‚ñó‚ñå  ‚ñê‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñõ‚ñà‚ñà‚ñò‚ñà‚ñê‚ñà‚ñü‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñú‚ñê‚ñà‚ñà‚ñà‚ñà‚ñê‚ñõ‚ñà‚ñà‚ñô‚ñà‚ñú‚ñå‚ñà‚ñà‚ñà‚ñà‚ñå‚îÇ
       ‚îÇ ‚ñà‚ñà ‚ñà‚ñê‚ñê‚ñà ‚ñå‚ñü‚ñê‚ñà‚ñà‚ñà‚ñà‚ñå‚ñê‚ñå‚ñà‚ñà ‚ñà‚ñê‚ñå‚ñà‚ñà‚ñà‚ñô‚ñà‚ñà‚ñà‚ñê‚ñê‚ñà‚ñÄ‚ñà‚ñà‚ñê‚ñå‚ñê‚ñà‚ñà‚ñà ‚ñô‚ñõ‚ñà‚ñú‚ñõ‚ñå‚îÇ
       ‚îÇ‚ñà‚ñà‚ñú‚ñå‚ñà‚ñê‚ñà‚ñà‚ñü‚ñô‚ñà‚ñê‚ñà‚ñà‚ñú‚ñà‚ñå  ‚ñà‚ñú ‚ñõ‚ñû ‚ñú‚ñà‚ñú‚ñà‚ñõ‚ñò‚ñà  ‚ñà ‚ñà‚ñú‚ñù‚ñå‚ñù‚ñõ‚ñà‚ñà ‚ñù   ‚ñò‚ñò‚îÇ
0.07290‚î§‚ñÄ‚ñà‚ñê‚ñö‚ñà‚ñû‚ñõ‚ñú‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñù‚ñå‚ñò  ‚ñù  ‚ñò‚ñò  ‚ñÄ ‚ñú‚ñå ‚ñà  ‚ñú ‚ñÄ‚ñù    ‚ñà‚ñú       ‚îÇ
       ‚îÇ ‚ñõ ‚ñù‚ñú‚ñò‚ñå ‚ñò ‚ñÄ‚ñù‚ñà‚ñò ‚ñå               ‚ñà          ‚ñú        ‚îÇ
0.07256‚î§               ‚ñå                                   ‚îÇ
       ‚îî‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
        2 15 35 48 66  87 103  135 151   182 207    243 268
train_dtb                      iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_dtb.txt
                  train_dtb [2025-11-23-230736]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
73.0‚î§           ‚ñà‚ñà‚ñà‚ñà‚ñà                                      ‚îÇ
    ‚îÇ           ‚ñà‚ñà‚ñà‚ñà‚ñà                                      ‚îÇ
60.8‚î§           ‚ñà‚ñà‚ñà‚ñà‚ñà                                      ‚îÇ
    ‚îÇ           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                ‚îÇ
    ‚îÇ           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                ‚îÇ
48.7‚î§           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                ‚îÇ
    ‚îÇ           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           ‚îÇ
36.5‚î§     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           ‚îÇ
    ‚îÇ     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           ‚îÇ
24.3‚î§     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           ‚îÇ
    ‚îÇ     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                ‚îÇ
    ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                ‚îÇ
12.2‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                ‚îÇ
    ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           ‚îÇ
 0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
    ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
  0.07247      0.07303       0.07359      0.07414   0.07470
freq                        train_dtb
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/plots/tplot/train_dtb-hist.txt
[2025-11-23 23:07:36,728688][I][utils/__init__:416:dataset_to_h5pyfile] Saving dataset to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230734/ezpz-fsdp-tp/train_dataset.h5
[2025-11-23 23:07:36,738484][I][examples/fsdp_tp:329:train] dataset=<xarray.Dataset> Size: 15kB
Dimensions:      (draw: 270)
Coordinates:
  * draw         (draw) int64 2kB 0 1 2 3 4 5 6 ... 263 264 265 266 267 268 269
Data variables:
    train_epoch  (draw) int64 2kB 5 5 5 5 5 5 6 6 6 ... 48 48 49 49 49 49 49 49
    train_iter   (draw) int64 2kB 0 1 2 3 4 5 0 1 2 3 4 ... 2 3 4 5 0 1 2 3 4 5
    train_loss   (draw) float64 2kB 6.845 7.994 8.705 9.0 ... 14.76 14.16 14.17
    train_dt     (draw) float64 2kB 0.122 0.1224 0.1222 ... 0.1224 0.1226 0.1227
    train_dtf    (draw) float64 2kB 0.04913 0.04929 0.04924 ... 0.04921 0.04915
    train_dtb    (draw) float64 2kB 0.07289 0.07307 0.07295 ... 0.07343 0.07354
[rank0]:[W1123 23:07:37.162488231 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Application 8f12cb28 resources: utime=599s stime=215s maxrss=2517384KB inblock=0 oublock=3608 minflt=2721188 majflt=1192 nvcsw=366002 nivcsw=2836
[2025-11-23 23:07:41,838831][I][ezpz/launch:402:launch] Execution finished with 0.
[2025-11-23 23:07:41,839349][I][ezpz/launch:403:launch] Executing finished in 87.43 seconds.
[2025-11-23 23:07:41,839725][I][ezpz/launch:404:launch] Took 87.43 seconds to run. Exiting.
Finished TP=2 at 2025-11-23 23:07:43
--------------------------------------------------------
========================================================
Running Experiment: Layers=8, TP=4
Start Time: 2025-11-23 23:07:48
========================================================


[2025-11-23 23:07:59,731725][I][ezpz/launch:369:launch] ----[üçã ezpz.launch][started][2025-11-23-230759]----
[2025-11-23 23:08:00,959364][I][ezpz/launch:374:launch] Job ID: 6650384
[2025-11-23 23:08:00,960394][I][ezpz/launch:375:launch] nodelist: ['x3206c0s37b1n0', 'x3206c0s7b0n0']
[2025-11-23 23:08:00,960797][I][ezpz/launch:376:launch] hostfile: /var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov
[2025-11-23 23:08:00,961756][I][ezpz/pbs:179:get_pbs_launch_cmd] ‚úÖ Using [8/8] GPUs [2 hosts] x [4 GPU/host]
[2025-11-23 23:08:00,964070][I][ezpz/launch:345:build_executable] Building command to execute by piecing together:
[2025-11-23 23:08:00,964459][I][ezpz/launch:346:build_executable] (1.) launch_cmd: mpiexec --verbose --envall --np=8 --ppn=4 --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind=depth --depth=8
[2025-11-23 23:08:00,965009][I][ezpz/launch:347:build_executable] (2.) cmd_to_launch: python3 -m ezpz.examples.fsdp_tp --dataset random --n-layers 8 --tp 4
[2025-11-23 23:08:00,965614][I][ezpz/launch:389:launch] Took: 1.23 seconds to build command.
[2025-11-23 23:08:00,965962][I][ezpz/launch:390:launch] Executing:
mpiexec
  --verbose
  --envall
  --np=8
  --ppn=4
  --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov
  --cpu-bind=depth
  --depth=8
  python3
  -m
  ezpz.examples.fsdp_tp
  --dataset
  random
  --n-layers
  8
  --tp
  4
[2025-11-23 23:08:00,967756][I][ezpz/launch:397:launch] Execution started @ 2025-11-23-230800...
[2025-11-23 23:08:00,968189][I][ezpz/launch:398:launch] ----[üçã ezpz.launch][stop][2025-11-23-230800]----
[2025-11-23 23:08:00,968659][I][ezpz/launch:127:run_command] Running command:
 mpiexec --verbose --envall --np=8 --ppn=4 --hostfile=/var/spool/pbs/aux/6650384.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind=depth --depth=8 python3 -m ezpz.examples.fsdp_tp --dataset random --n-layers 8 --tp 4
Disabling local launch: multi-node application
Connected to tcp://x3206c0s37b1n0.hsn.cm.polaris.alcf.anl.gov:7919
Found executable /soft/applications/conda/2025-09-25/mconda3/bin/python3
Launching application fb343854-82ef-454c-92fc-f4d9f6282ddb
Using PMI ports 53881,53882
[2025-11-23 23:08:13,299721][I][examples/fsdp_tp:334:<module>] args:
Namespace(dim=256, n_layers=8, n_heads=32, n_kv_heads=4, multiple_of=360, ffn_dim_multiplier=None, norm_eps=1e-05, vocab_size=32000, seq_length=2048, lr=0.003, epochs=50, batch_size=24, seed=None, tp=4, dataset='random', max_seq_len=32768, depth_init=True)
[2025-11-23 23:08:13,474123][I][ezpz/dist:1242:setup_torch_distributed] Using fw='ddp' with torch_{device,backend}= {cuda, nccl}
[2025-11-23 23:08:13,476361][I][ezpz/dist:1113:setup_torch_DDP] Caught MASTER_PORT=54967 from environment!
[2025-11-23 23:08:13,476952][I][ezpz/dist:1129:setup_torch_DDP] Using torch.distributed.init_process_group with
- master_addr='x3206c0s37b1n0.hsn.cm.polaris.alcf.anl.gov'
- master_port='54967'
- world_size=8
- rank=0
- local_rank=0
- timeout=datetime.timedelta(seconds=3600)
- backend='nccl'
[2025-11-23 23:08:13,477803][I][ezpz/dist:822:init_process_group] Calling torch.distributed.init_process_group_with: rank=0 world_size=8 backend=nccl
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank2]:[W1123 23:08:13.947471818 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank3]:[W1123 23:08:13.947497086 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank1]:[W1123 23:08:13.948319531 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:08:16,248271][I][tp/__init__:141:initialize_tensor_parallel] TP: 4, PP: 1, CP: 1, DP: 2
[2025-11-23 23:08:16,252908][I][ezpz/pbs:179:get_pbs_launch_cmd] ‚úÖ Using [8/8] GPUs [2 hosts] x [4 GPU/host]
[2025-11-23 23:08:16,255305][I][ezpz/dist:510:print_dist_setup] [device='cuda'][rank=0/7][local_rank=0/3][node=0/1]
[2025-11-23 23:08:16,255809][W][ezpz/dist:514:print_dist_setup] Using [8 / 8] available "cuda" devices !!
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank0]:[W1123 23:08:16.212190837 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank4]:[W1123 23:08:16.295733783 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank7]:[W1123 23:08:16.746384369 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
/soft/applications/conda/2025-09-25/mconda3/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user.
  warnings.warn(  # warn only once
[rank6]:[W1123 23:08:16.746846055 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank5]:[W1123 23:08:16.746876732 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank4]:[W1123 23:08:17.104769091 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 6 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank6]:[W1123 23:08:17.104768189 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 6 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank1]:[W1123 23:08:17.071332796 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 5 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank7]:[W1123 23:08:17.104780272 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 6 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank5]:[W1123 23:08:17.104786884 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 6 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank2]:[W1123 23:08:17.071314271 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 5 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank3]:[W1123 23:08:17.071326163 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 5 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:08:17,116629][I][ezpz/dist:1462:setup_torch] Using device='cuda' with backend='nccl' + 'nccl' for distributed training.
[rank0]:[W1123 23:08:17.072027281 ProcessGroupNCCL.cpp:5023] [PG ID 2 PG GUID 5 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank4]:[W1123 23:08:17.432784546 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 1 Rank 1]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank5]:[W1123 23:08:17.432755722 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 2 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank6]:[W1123 23:08:17.432721367 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 3 Rank 1]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank7]:[W1123 23:08:17.432730895 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 4 Rank 1]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank0]:[W1123 23:08:17.400291067 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 1 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank3]:[W1123 23:08:17.400303320 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 4 Rank 0]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank1]:[W1123 23:08:17.400323558 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 2 Rank 0]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[rank2]:[W1123 23:08:17.400362862 ProcessGroupNCCL.cpp:5023] [PG ID 1 PG GUID 3 Rank 0]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
[2025-11-23 23:08:17,509530][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][3/7] [tp:3/3][dp:0/1]
[2025-11-23 23:08:17,509574][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][7/7] [tp:3/3][dp:1/1]
[2025-11-23 23:08:17,510661][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][1/7] [tp:1/3][dp:0/1]
[2025-11-23 23:08:17,510696][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][5/7] [tp:1/3][dp:1/1]
[2025-11-23 23:08:17,535065][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][6/7] [tp:2/3][dp:1/1]
[2025-11-23 23:08:17,535028][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][2/7] [tp:2/3][dp:0/1]
[2025-11-23 23:08:17,564685][I][ezpz/dist:1509:setup_torch] ['x3206c0s37b1n0'][0/7] [tp:0/3][dp:0/1]
[2025-11-23 23:08:17,564730][I][ezpz/dist:1509:setup_torch] ['x3206c0s7b0n0'][4/7] [tp:0/3][dp:1/1]
[2025-11-23 23:08:17,568281][I][examples/fsdp_tp:185:train] Device mesh created:
device_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('dp', 'tp'))
[2025-11-23 23:08:17,569028][I][examples/fsdp_tp:196:train] config:
ModelArgs(dim=256, n_layers=8, n_heads=32, n_kv_heads=4, vocab_size=32000, multiple_of=360, ffn_dim_multiplier=None, norm_eps=1e-05, batch_size=24, max_seq_len=32768, depth_init=True)
[2025-11-23 23:08:17,781568][I][examples/fsdp_tp:223:train] 
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Transformer                              --
‚îú‚îÄEmbedding: 1-1                         8,192,000
‚îú‚îÄModuleList: 1-2                        --
‚îÇ    ‚îî‚îÄTransformerBlock: 2-1             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-2             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-3             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-4             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-5             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-6             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-7             700,928
‚îÇ    ‚îî‚îÄTransformerBlock: 2-8             700,928
‚îú‚îÄRMSNorm: 1-3                           256
‚îú‚îÄLinear: 1-4                            8,192,000
=================================================================
Total params: 21,991,680
Trainable params: 21,991,680
Non-trainable params: 0
=================================================================
[2025-11-23 23:08:18,044284][I][examples/fsdp_tp:171:parallelize] Model after parallelization:
sharded_model=FullyShardedDataParallel(
  (_fsdp_wrapped_module): Transformer(
    (tok_embeddings): Embedding(32000, 256)
    (layers): ModuleList(
      (0-7): 8 x TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=256, out_features=256, bias=False)
          (wk): Linear(in_features=256, out_features=32, bias=False)
          (wv): Linear(in_features=256, out_features=32, bias=False)
          (wo): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=256, out_features=720, bias=False)
          (w2): Linear(in_features=720, out_features=256, bias=False)
          (w3): Linear(in_features=256, out_features=720, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
    )
    (norm): RMSNorm()
    (output): Linear(in_features=256, out_features=32000, bias=False)
  )
)

[2025-11-23 23:08:18,047100][I][examples/fsdp_tp:226:train] Creating optimizer=AdamW with lr=0.003
[2025-11-23 23:08:18,048783][I][examples/fsdp_tp:272:train] Starting 2D training...
[2025-11-23 23:08:18,958188][I][examples/fsdp_tp:308:train] epoch=0 iter=0 loss=10.863223 dt=0.908168 dtf=0.655721 dtb=0.252446
[2025-11-23 23:08:18,958967][I][examples/fsdp_tp:321:train] inp.shape=torch.Size([24, 2048])
[2025-11-23 23:08:19,130488][I][examples/fsdp_tp:308:train] epoch=0 iter=1 loss=10.843083 dt=0.125269 dtf=0.051311 dtb=0.073958
[2025-11-23 23:08:19,301942][I][examples/fsdp_tp:308:train] epoch=0 iter=2 loss=10.835233 dt=0.126769 dtf=0.050528 dtb=0.076241
[2025-11-23 23:08:19,473460][I][examples/fsdp_tp:308:train] epoch=0 iter=3 loss=10.843257 dt=0.126574 dtf=0.050242 dtb=0.076331
[2025-11-23 23:08:19,644730][I][examples/fsdp_tp:308:train] epoch=0 iter=4 loss=10.830672 dt=0.125890 dtf=0.050026 dtb=0.075864
[2025-11-23 23:08:19,840978][I][examples/fsdp_tp:308:train] epoch=0 iter=5 loss=10.840614 dt=0.186683 dtf=0.075229 dtb=0.111454
[2025-11-23 23:08:20,013687][I][examples/fsdp_tp:308:train] epoch=1 iter=0 loss=8.624726 dt=0.122257 dtf=0.049369 dtb=0.072888
[2025-11-23 23:08:20,184159][I][examples/fsdp_tp:308:train] epoch=1 iter=1 loss=9.280680 dt=0.122937 dtf=0.048996 dtb=0.073941
[2025-11-23 23:08:20,353939][I][examples/fsdp_tp:308:train] epoch=1 iter=2 loss=9.592227 dt=0.123020 dtf=0.049029 dtb=0.073991
[2025-11-23 23:08:20,525148][I][examples/fsdp_tp:308:train] epoch=1 iter=3 loss=9.785464 dt=0.123194 dtf=0.049248 dtb=0.073946
[2025-11-23 23:08:20,695072][I][examples/fsdp_tp:308:train] epoch=1 iter=4 loss=9.912068 dt=0.122946 dtf=0.048918 dtb=0.074028
[2025-11-23 23:08:20,827394][I][examples/fsdp_tp:308:train] epoch=1 iter=5 loss=8.702271 dt=0.123300 dtf=0.048831 dtb=0.074469
[2025-11-23 23:08:20,997111][I][examples/fsdp_tp:308:train] epoch=2 iter=0 loss=6.849132 dt=0.122209 dtf=0.048644 dtb=0.073566
[2025-11-23 23:08:21,166805][I][examples/fsdp_tp:308:train] epoch=2 iter=1 loss=7.649786 dt=0.122923 dtf=0.048895 dtb=0.074028
[2025-11-23 23:08:21,336449][I][examples/fsdp_tp:308:train] epoch=2 iter=2 loss=8.079460 dt=0.122997 dtf=0.048828 dtb=0.074169
[2025-11-23 23:08:21,506063][I][examples/fsdp_tp:308:train] epoch=2 iter=3 loss=8.392091 dt=0.122770 dtf=0.048875 dtb=0.073895
[2025-11-23 23:08:21,675768][I][examples/fsdp_tp:308:train] epoch=2 iter=4 loss=8.653596 dt=0.122594 dtf=0.048738 dtb=0.073856
[2025-11-23 23:08:21,807724][I][examples/fsdp_tp:308:train] epoch=2 iter=5 loss=5.653138 dt=0.122887 dtf=0.048732 dtb=0.074156
[2025-11-23 23:08:21,978157][I][examples/fsdp_tp:308:train] epoch=3 iter=0 loss=6.019928 dt=0.121953 dtf=0.048816 dtb=0.073137
[2025-11-23 23:08:22,147815][I][examples/fsdp_tp:308:train] epoch=3 iter=1 loss=6.857655 dt=0.122791 dtf=0.048881 dtb=0.073910
[2025-11-23 23:08:22,317321][I][examples/fsdp_tp:308:train] epoch=3 iter=2 loss=7.316393 dt=0.122889 dtf=0.049015 dtb=0.073874
[2025-11-23 23:08:22,486888][I][examples/fsdp_tp:308:train] epoch=3 iter=3 loss=7.629375 dt=0.122783 dtf=0.048862 dtb=0.073921
[2025-11-23 23:08:22,656710][I][examples/fsdp_tp:308:train] epoch=3 iter=4 loss=7.889513 dt=0.122604 dtf=0.048861 dtb=0.073743
[2025-11-23 23:08:22,789592][I][examples/fsdp_tp:308:train] epoch=3 iter=5 loss=3.680923 dt=0.123598 dtf=0.048943 dtb=0.074655
[2025-11-23 23:08:22,959264][I][examples/fsdp_tp:308:train] epoch=4 iter=0 loss=5.876450 dt=0.122117 dtf=0.048717 dtb=0.073400
[2025-11-23 23:08:23,129066][I][examples/fsdp_tp:308:train] epoch=4 iter=1 loss=6.470168 dt=0.122545 dtf=0.048889 dtb=0.073656
[2025-11-23 23:08:23,299245][I][examples/fsdp_tp:308:train] epoch=4 iter=2 loss=6.808157 dt=0.122522 dtf=0.048803 dtb=0.073720
[2025-11-23 23:08:23,468813][I][examples/fsdp_tp:308:train] epoch=4 iter=3 loss=7.807147 dt=0.122754 dtf=0.048848 dtb=0.073906
[2025-11-23 23:08:23,638469][I][examples/fsdp_tp:308:train] epoch=4 iter=4 loss=7.742523 dt=0.122504 dtf=0.048726 dtb=0.073778
[2025-11-23 23:08:23,770534][I][examples/fsdp_tp:308:train] epoch=4 iter=5 loss=5.589977 dt=0.122958 dtf=0.048839 dtb=0.074119
[2025-11-23 23:08:23,940724][I][examples/fsdp_tp:308:train] epoch=5 iter=0 loss=6.632948 dt=0.121928 dtf=0.048830 dtb=0.073099
[2025-11-23 23:08:24,111743][I][examples/fsdp_tp:308:train] epoch=5 iter=1 loss=7.201540 dt=0.122502 dtf=0.048963 dtb=0.073539
[2025-11-23 23:08:24,281481][I][examples/fsdp_tp:308:train] epoch=5 iter=2 loss=7.889290 dt=0.122753 dtf=0.048906 dtb=0.073847
[2025-11-23 23:08:24,451392][I][examples/fsdp_tp:308:train] epoch=5 iter=3 loss=8.628128 dt=0.122636 dtf=0.048848 dtb=0.073788
[2025-11-23 23:08:24,621148][I][examples/fsdp_tp:308:train] epoch=5 iter=4 loss=9.289962 dt=0.122511 dtf=0.048789 dtb=0.073722
[2025-11-23 23:08:24,753340][I][examples/fsdp_tp:308:train] epoch=5 iter=5 loss=6.799704 dt=0.123084 dtf=0.048967 dtb=0.074117
[2025-11-23 23:08:24,923855][I][examples/fsdp_tp:308:train] epoch=6 iter=0 loss=10.072088 dt=0.121615 dtf=0.048754 dtb=0.072861
[2025-11-23 23:08:25,093742][I][examples/fsdp_tp:308:train] epoch=6 iter=1 loss=11.008172 dt=0.122866 dtf=0.048886 dtb=0.073981
[2025-11-23 23:08:25,263317][I][examples/fsdp_tp:308:train] epoch=6 iter=2 loss=11.116940 dt=0.122607 dtf=0.048829 dtb=0.073778
[2025-11-23 23:08:25,433908][I][examples/fsdp_tp:308:train] epoch=6 iter=3 loss=11.038066 dt=0.122858 dtf=0.048964 dtb=0.073893
[2025-11-23 23:08:25,605159][I][examples/fsdp_tp:308:train] epoch=6 iter=4 loss=11.070168 dt=0.122601 dtf=0.048804 dtb=0.073797
[2025-11-23 23:08:25,739355][I][examples/fsdp_tp:308:train] epoch=6 iter=5 loss=9.629787 dt=0.122951 dtf=0.048863 dtb=0.074088
[2025-11-23 23:08:25,909104][I][examples/fsdp_tp:308:train] epoch=7 iter=0 loss=10.601497 dt=0.122042 dtf=0.048830 dtb=0.073212
[2025-11-23 23:08:26,078717][I][examples/fsdp_tp:308:train] epoch=7 iter=1 loss=11.329384 dt=0.122879 dtf=0.048930 dtb=0.073949
[2025-11-23 23:08:26,248746][I][examples/fsdp_tp:308:train] epoch=7 iter=2 loss=11.586917 dt=0.122766 dtf=0.048869 dtb=0.073897
[2025-11-23 23:08:26,418411][I][examples/fsdp_tp:308:train] epoch=7 iter=3 loss=11.872928 dt=0.123304 dtf=0.048869 dtb=0.074435
[2025-11-23 23:08:26,588346][I][examples/fsdp_tp:308:train] epoch=7 iter=4 loss=11.944491 dt=0.122395 dtf=0.048830 dtb=0.073565
[2025-11-23 23:08:26,721650][I][examples/fsdp_tp:308:train] epoch=7 iter=5 loss=11.852090 dt=0.123132 dtf=0.048778 dtb=0.074354
[2025-11-23 23:08:26,891266][I][examples/fsdp_tp:308:train] epoch=8 iter=0 loss=11.989406 dt=0.121865 dtf=0.048722 dtb=0.073143
[2025-11-23 23:08:27,060598][I][examples/fsdp_tp:308:train] epoch=8 iter=1 loss=12.023766 dt=0.122638 dtf=0.048725 dtb=0.073913
[2025-11-23 23:08:27,230383][I][examples/fsdp_tp:308:train] epoch=8 iter=2 loss=12.021199 dt=0.122470 dtf=0.048790 dtb=0.073680
[2025-11-23 23:08:27,400213][I][examples/fsdp_tp:308:train] epoch=8 iter=3 loss=12.113697 dt=0.122704 dtf=0.048773 dtb=0.073931
[2025-11-23 23:08:27,569824][I][examples/fsdp_tp:308:train] epoch=8 iter=4 loss=11.818004 dt=0.122464 dtf=0.048805 dtb=0.073659
[2025-11-23 23:08:27,702581][I][examples/fsdp_tp:308:train] epoch=8 iter=5 loss=11.564445 dt=0.122974 dtf=0.048765 dtb=0.074209
[2025-11-23 23:08:27,871731][I][examples/fsdp_tp:308:train] epoch=9 iter=0 loss=11.819649 dt=0.121733 dtf=0.048619 dtb=0.073115
[2025-11-23 23:08:28,041406][I][examples/fsdp_tp:308:train] epoch=9 iter=1 loss=11.977645 dt=0.122787 dtf=0.048973 dtb=0.073814
[2025-11-23 23:08:28,211073][I][examples/fsdp_tp:308:train] epoch=9 iter=2 loss=11.903542 dt=0.122453 dtf=0.048772 dtb=0.073681
[2025-11-23 23:08:28,380567][I][examples/fsdp_tp:308:train] epoch=9 iter=3 loss=12.170920 dt=0.122542 dtf=0.048770 dtb=0.073773
[2025-11-23 23:08:28,550252][I][examples/fsdp_tp:308:train] epoch=9 iter=4 loss=11.894635 dt=0.122606 dtf=0.048842 dtb=0.073765
[2025-11-23 23:08:28,682861][I][examples/fsdp_tp:308:train] epoch=9 iter=5 loss=11.704676 dt=0.123038 dtf=0.048607 dtb=0.074431
[2025-11-23 23:08:28,851931][I][examples/fsdp_tp:308:train] epoch=10 iter=0 loss=12.242753 dt=0.121443 dtf=0.048588 dtb=0.072855
[2025-11-23 23:08:29,021705][I][examples/fsdp_tp:308:train] epoch=10 iter=1 loss=12.427315 dt=0.122626 dtf=0.048725 dtb=0.073901
[2025-11-23 23:08:29,191395][I][examples/fsdp_tp:308:train] epoch=10 iter=2 loss=12.607551 dt=0.122783 dtf=0.048847 dtb=0.073936
[2025-11-23 23:08:29,360826][I][examples/fsdp_tp:308:train] epoch=10 iter=3 loss=12.835446 dt=0.122607 dtf=0.048786 dtb=0.073821
[2025-11-23 23:08:29,530309][I][examples/fsdp_tp:308:train] epoch=10 iter=4 loss=12.817996 dt=0.122619 dtf=0.048657 dtb=0.073962
[2025-11-23 23:08:29,663110][I][examples/fsdp_tp:308:train] epoch=10 iter=5 loss=11.523745 dt=0.123058 dtf=0.048724 dtb=0.074334
[2025-11-23 23:08:29,832756][I][examples/fsdp_tp:308:train] epoch=11 iter=0 loss=13.227551 dt=0.121708 dtf=0.048632 dtb=0.073076
[2025-11-23 23:08:30,002453][I][examples/fsdp_tp:308:train] epoch=11 iter=1 loss=13.406123 dt=0.122693 dtf=0.048829 dtb=0.073864
[2025-11-23 23:08:30,174679][I][examples/fsdp_tp:308:train] epoch=11 iter=2 loss=13.657737 dt=0.123586 dtf=0.049506 dtb=0.074080
[2025-11-23 23:08:30,344219][I][examples/fsdp_tp:308:train] epoch=11 iter=3 loss=13.567729 dt=0.122651 dtf=0.048870 dtb=0.073780
[2025-11-23 23:08:30,514966][I][examples/fsdp_tp:308:train] epoch=11 iter=4 loss=14.008395 dt=0.122566 dtf=0.048908 dtb=0.073658
[2025-11-23 23:08:30,648184][I][examples/fsdp_tp:308:train] epoch=11 iter=5 loss=12.843573 dt=0.122933 dtf=0.048892 dtb=0.074041
[2025-11-23 23:08:30,817968][I][examples/fsdp_tp:308:train] epoch=12 iter=0 loss=14.364089 dt=0.121870 dtf=0.048885 dtb=0.072985
[2025-11-23 23:08:31,128004][I][examples/fsdp_tp:308:train] epoch=12 iter=1 loss=14.599799 dt=0.170734 dtf=0.048894 dtb=0.121839
[2025-11-23 23:08:31,297552][I][examples/fsdp_tp:308:train] epoch=12 iter=2 loss=15.096391 dt=0.122720 dtf=0.048932 dtb=0.073788
[2025-11-23 23:08:31,467283][I][examples/fsdp_tp:308:train] epoch=12 iter=3 loss=14.893517 dt=0.122456 dtf=0.048792 dtb=0.073664
[2025-11-23 23:08:31,638014][I][examples/fsdp_tp:308:train] epoch=12 iter=4 loss=15.723811 dt=0.122680 dtf=0.048972 dtb=0.073708
[2025-11-23 23:08:31,769947][I][examples/fsdp_tp:308:train] epoch=12 iter=5 loss=15.170245 dt=0.122843 dtf=0.048880 dtb=0.073963
[2025-11-23 23:08:31,939642][I][examples/fsdp_tp:308:train] epoch=13 iter=0 loss=15.586535 dt=0.121965 dtf=0.048711 dtb=0.073254
[2025-11-23 23:08:32,109403][I][examples/fsdp_tp:308:train] epoch=13 iter=1 loss=15.442630 dt=0.122880 dtf=0.048925 dtb=0.073955
[2025-11-23 23:08:32,279470][I][examples/fsdp_tp:308:train] epoch=13 iter=2 loss=15.892550 dt=0.122652 dtf=0.048871 dtb=0.073782
[2025-11-23 23:08:32,449143][I][examples/fsdp_tp:308:train] epoch=13 iter=3 loss=15.756931 dt=0.122577 dtf=0.048833 dtb=0.073744
[2025-11-23 23:08:32,618902][I][examples/fsdp_tp:308:train] epoch=13 iter=4 loss=17.296404 dt=0.122509 dtf=0.048888 dtb=0.073621
[2025-11-23 23:08:32,752455][I][examples/fsdp_tp:308:train] epoch=13 iter=5 loss=17.235130 dt=0.123035 dtf=0.048964 dtb=0.074071
[2025-11-23 23:08:32,922048][I][examples/fsdp_tp:308:train] epoch=14 iter=0 loss=16.976974 dt=0.121729 dtf=0.048869 dtb=0.072860
[2025-11-23 23:08:33,091651][I][examples/fsdp_tp:308:train] epoch=14 iter=1 loss=16.517521 dt=0.122802 dtf=0.048939 dtb=0.073862
[2025-11-23 23:08:33,262136][I][examples/fsdp_tp:308:train] epoch=14 iter=2 loss=16.772984 dt=0.122780 dtf=0.048970 dtb=0.073810
[2025-11-23 23:08:33,432173][I][examples/fsdp_tp:308:train] epoch=14 iter=3 loss=16.423153 dt=0.122562 dtf=0.048891 dtb=0.073671
[2025-11-23 23:08:33,602036][I][examples/fsdp_tp:308:train] epoch=14 iter=4 loss=17.915884 dt=0.122713 dtf=0.048950 dtb=0.073763
[2025-11-23 23:08:33,735691][I][examples/fsdp_tp:308:train] epoch=14 iter=5 loss=17.853304 dt=0.122677 dtf=0.048894 dtb=0.073783
[2025-11-23 23:08:33,905515][I][examples/fsdp_tp:308:train] epoch=15 iter=0 loss=17.160656 dt=0.122277 dtf=0.048777 dtb=0.073500
[2025-11-23 23:08:34,076358][I][examples/fsdp_tp:308:train] epoch=15 iter=1 loss=16.760912 dt=0.122576 dtf=0.048968 dtb=0.073609
[2025-11-23 23:08:34,245354][I][examples/fsdp_tp:308:train] epoch=15 iter=2 loss=16.922850 dt=0.122461 dtf=0.048863 dtb=0.073598
[2025-11-23 23:08:34,415591][I][examples/fsdp_tp:308:train] epoch=15 iter=3 loss=16.659492 dt=0.122796 dtf=0.048943 dtb=0.073852
[2025-11-23 23:08:34,584992][I][examples/fsdp_tp:308:train] epoch=15 iter=4 loss=17.743551 dt=0.122270 dtf=0.048835 dtb=0.073435
[2025-11-23 23:08:34,857881][I][examples/fsdp_tp:308:train] epoch=15 iter=5 loss=17.941982 dt=0.264132 dtf=0.189554 dtb=0.074577
[2025-11-23 23:08:35,027530][I][examples/fsdp_tp:308:train] epoch=16 iter=0 loss=17.154730 dt=0.122825 dtf=0.049182 dtb=0.073644
[2025-11-23 23:08:35,198500][I][examples/fsdp_tp:308:train] epoch=16 iter=1 loss=17.095003 dt=0.123190 dtf=0.049265 dtb=0.073925
[2025-11-23 23:08:35,368556][I][examples/fsdp_tp:308:train] epoch=16 iter=2 loss=17.103035 dt=0.122837 dtf=0.049050 dtb=0.073787
[2025-11-23 23:08:35,539251][I][examples/fsdp_tp:308:train] epoch=16 iter=3 loss=16.881111 dt=0.122996 dtf=0.049189 dtb=0.073807
[2025-11-23 23:08:35,708843][I][examples/fsdp_tp:308:train] epoch=16 iter=4 loss=17.200949 dt=0.122864 dtf=0.049125 dtb=0.073739
[2025-11-23 23:08:35,842915][I][examples/fsdp_tp:308:train] epoch=16 iter=5 loss=17.394833 dt=0.123311 dtf=0.049083 dtb=0.074227
[2025-11-23 23:08:36,014471][I][examples/fsdp_tp:308:train] epoch=17 iter=0 loss=16.829088 dt=0.122582 dtf=0.049013 dtb=0.073569
[2025-11-23 23:08:36,184289][I][examples/fsdp_tp:308:train] epoch=17 iter=1 loss=16.975748 dt=0.122913 dtf=0.049003 dtb=0.073910
[2025-11-23 23:08:36,354821][I][examples/fsdp_tp:308:train] epoch=17 iter=2 loss=16.840475 dt=0.122904 dtf=0.049110 dtb=0.073794
[2025-11-23 23:08:36,525261][I][examples/fsdp_tp:308:train] epoch=17 iter=3 loss=16.833809 dt=0.123140 dtf=0.049204 dtb=0.073936
[2025-11-23 23:08:36,696071][I][examples/fsdp_tp:308:train] epoch=17 iter=4 loss=16.568624 dt=0.123076 dtf=0.049159 dtb=0.073917
[2025-11-23 23:08:36,830328][I][examples/fsdp_tp:308:train] epoch=17 iter=5 loss=16.771805 dt=0.123210 dtf=0.048950 dtb=0.074259
[2025-11-23 23:08:37,145629][I][examples/fsdp_tp:308:train] epoch=18 iter=0 loss=16.828516 dt=0.122412 dtf=0.049125 dtb=0.073286
[2025-11-23 23:08:37,315978][I][examples/fsdp_tp:308:train] epoch=18 iter=1 loss=17.085032 dt=0.122987 dtf=0.049132 dtb=0.073855
[2025-11-23 23:08:37,486877][I][examples/fsdp_tp:308:train] epoch=18 iter=2 loss=16.988962 dt=0.123007 dtf=0.049261 dtb=0.073746
[2025-11-23 23:08:37,657645][I][examples/fsdp_tp:308:train] epoch=18 iter=3 loss=17.049160 dt=0.123196 dtf=0.049317 dtb=0.073880
[2025-11-23 23:08:37,828791][I][examples/fsdp_tp:308:train] epoch=18 iter=4 loss=16.544317 dt=0.122986 dtf=0.049085 dtb=0.073901
[2025-11-23 23:08:37,964038][I][examples/fsdp_tp:308:train] epoch=18 iter=5 loss=16.152296 dt=0.123295 dtf=0.049037 dtb=0.074258
[2025-11-23 23:08:38,134447][I][examples/fsdp_tp:308:train] epoch=19 iter=0 loss=16.914503 dt=0.122539 dtf=0.049154 dtb=0.073384
[2025-11-23 23:08:38,305543][I][examples/fsdp_tp:308:train] epoch=19 iter=1 loss=17.129416 dt=0.122892 dtf=0.049140 dtb=0.073752
[2025-11-23 23:08:38,476138][I][examples/fsdp_tp:308:train] epoch=19 iter=2 loss=17.003704 dt=0.122712 dtf=0.049113 dtb=0.073598
[2025-11-23 23:08:38,646663][I][examples/fsdp_tp:308:train] epoch=19 iter=3 loss=16.881920 dt=0.123289 dtf=0.049190 dtb=0.074099
[2025-11-23 23:08:38,817317][I][examples/fsdp_tp:308:train] epoch=19 iter=4 loss=16.484304 dt=0.123013 dtf=0.049096 dtb=0.073916
[2025-11-23 23:08:38,952356][I][examples/fsdp_tp:308:train] epoch=19 iter=5 loss=15.423754 dt=0.123347 dtf=0.049344 dtb=0.074003
[2025-11-23 23:08:39,123386][I][examples/fsdp_tp:308:train] epoch=20 iter=0 loss=16.793833 dt=0.122459 dtf=0.049143 dtb=0.073316
[2025-11-23 23:08:39,293286][I][examples/fsdp_tp:308:train] epoch=20 iter=1 loss=16.905590 dt=0.123333 dtf=0.049161 dtb=0.074172
[2025-11-23 23:08:39,464263][I][examples/fsdp_tp:308:train] epoch=20 iter=2 loss=16.763237 dt=0.122935 dtf=0.049151 dtb=0.073784
[2025-11-23 23:08:39,634670][I][examples/fsdp_tp:308:train] epoch=20 iter=3 loss=16.531546 dt=0.123046 dtf=0.049290 dtb=0.073756
[2025-11-23 23:08:39,805819][I][examples/fsdp_tp:308:train] epoch=20 iter=4 loss=16.382462 dt=0.123083 dtf=0.049084 dtb=0.073999
[2025-11-23 23:08:39,940227][I][examples/fsdp_tp:308:train] epoch=20 iter=5 loss=14.945084 dt=0.123253 dtf=0.049041 dtb=0.074211
[2025-11-23 23:08:40,110536][I][examples/fsdp_tp:308:train] epoch=21 iter=0 loss=16.688358 dt=0.122804 dtf=0.049078 dtb=0.073726
[2025-11-23 23:08:40,282297][I][examples/fsdp_tp:308:train] epoch=21 iter=1 loss=16.765635 dt=0.124594 dtf=0.050677 dtb=0.073918
[2025-11-23 23:08:40,452237][I][examples/fsdp_tp:308:train] epoch=21 iter=2 loss=16.645109 dt=0.122865 dtf=0.049041 dtb=0.073823
[2025-11-23 23:08:40,623574][I][examples/fsdp_tp:308:train] epoch=21 iter=3 loss=16.478670 dt=0.122952 dtf=0.049158 dtb=0.073793
[2025-11-23 23:08:40,793997][I][examples/fsdp_tp:308:train] epoch=21 iter=4 loss=16.539787 dt=0.123102 dtf=0.049282 dtb=0.073820
[2025-11-23 23:08:40,927772][I][examples/fsdp_tp:308:train] epoch=21 iter=5 loss=15.140070 dt=0.123512 dtf=0.048963 dtb=0.074549
[2025-11-23 23:08:41,098928][I][examples/fsdp_tp:308:train] epoch=22 iter=0 loss=16.957451 dt=0.122643 dtf=0.049134 dtb=0.073509
[2025-11-23 23:08:41,269752][I][examples/fsdp_tp:308:train] epoch=22 iter=1 loss=17.073729 dt=0.123326 dtf=0.049009 dtb=0.074317
[2025-11-23 23:08:41,440267][I][examples/fsdp_tp:308:train] epoch=22 iter=2 loss=16.998274 dt=0.122982 dtf=0.048940 dtb=0.074042
[2025-11-23 23:08:41,612204][I][examples/fsdp_tp:308:train] epoch=22 iter=3 loss=16.976274 dt=0.123597 dtf=0.049345 dtb=0.074252
[2025-11-23 23:08:41,781939][I][examples/fsdp_tp:308:train] epoch=22 iter=4 loss=17.099007 dt=0.123133 dtf=0.049178 dtb=0.073955
[2025-11-23 23:08:41,917588][I][examples/fsdp_tp:308:train] epoch=22 iter=5 loss=15.903502 dt=0.123123 dtf=0.048876 dtb=0.074247
[2025-11-23 23:08:42,088171][I][examples/fsdp_tp:308:train] epoch=23 iter=0 loss=17.390980 dt=0.122594 dtf=0.049061 dtb=0.073533
[2025-11-23 23:08:42,259068][I][examples/fsdp_tp:308:train] epoch=23 iter=1 loss=17.409441 dt=0.123330 dtf=0.049080 dtb=0.074250
[2025-11-23 23:08:42,429573][I][examples/fsdp_tp:308:train] epoch=23 iter=2 loss=17.262512 dt=0.122922 dtf=0.049060 dtb=0.073862
[2025-11-23 23:08:42,601318][I][examples/fsdp_tp:308:train] epoch=23 iter=3 loss=17.288033 dt=0.123638 dtf=0.049249 dtb=0.074389
[2025-11-23 23:08:42,770833][I][examples/fsdp_tp:308:train] epoch=23 iter=4 loss=17.404343 dt=0.123258 dtf=0.049071 dtb=0.074187
[2025-11-23 23:08:42,905465][I][examples/fsdp_tp:308:train] epoch=23 iter=5 loss=16.467020 dt=0.123186 dtf=0.048850 dtb=0.074336
[2025-11-23 23:08:43,077147][I][examples/fsdp_tp:308:train] epoch=24 iter=0 loss=17.592482 dt=0.122942 dtf=0.049173 dtb=0.073769
[2025-11-23 23:08:43,247505][I][examples/fsdp_tp:308:train] epoch=24 iter=1 loss=17.575224 dt=0.123418 dtf=0.049144 dtb=0.074274
[2025-11-23 23:08:43,417143][I][examples/fsdp_tp:308:train] epoch=24 iter=2 loss=17.513958 dt=0.123267 dtf=0.049196 dtb=0.074071
[2025-11-23 23:08:43,588119][I][examples/fsdp_tp:308:train] epoch=24 iter=3 loss=17.726309 dt=0.123131 dtf=0.049155 dtb=0.073976
[2025-11-23 23:08:43,759897][I][examples/fsdp_tp:308:train] epoch=24 iter=4 loss=18.023655 dt=0.122946 dtf=0.048881 dtb=0.074065
[2025-11-23 23:08:43,893829][I][examples/fsdp_tp:308:train] epoch=24 iter=5 loss=17.256653 dt=0.123198 dtf=0.048955 dtb=0.074243
[2025-11-23 23:08:44,065230][I][examples/fsdp_tp:308:train] epoch=25 iter=0 loss=18.107859 dt=0.122504 dtf=0.048968 dtb=0.073536
[2025-11-23 23:08:44,235722][I][examples/fsdp_tp:308:train] epoch=25 iter=1 loss=17.971186 dt=0.123124 dtf=0.049002 dtb=0.074122
[2025-11-23 23:08:44,406601][I][examples/fsdp_tp:308:train] epoch=25 iter=2 loss=17.860672 dt=0.123209 dtf=0.049273 dtb=0.073936
[2025-11-23 23:08:44,576955][I][examples/fsdp_tp:308:train] epoch=25 iter=3 loss=18.087746 dt=0.123541 dtf=0.049073 dtb=0.074467
[2025-11-23 23:08:44,747023][I][examples/fsdp_tp:308:train] epoch=25 iter=4 loss=18.392792 dt=0.123114 dtf=0.049131 dtb=0.073982
[2025-11-23 23:08:44,881464][I][examples/fsdp_tp:308:train] epoch=25 iter=5 loss=17.622414 dt=0.123196 dtf=0.048928 dtb=0.074268
[2025-11-23 23:08:45,052798][I][examples/fsdp_tp:308:train] epoch=26 iter=0 loss=18.249250 dt=0.122662 dtf=0.048907 dtb=0.073754
[2025-11-23 23:08:45,223799][I][examples/fsdp_tp:308:train] epoch=26 iter=1 loss=18.022497 dt=0.123262 dtf=0.049086 dtb=0.074176
[2025-11-23 23:08:45,394115][I][examples/fsdp_tp:308:train] epoch=26 iter=2 loss=17.830305 dt=0.123103 dtf=0.049119 dtb=0.073984
[2025-11-23 23:08:45,565344][I][examples/fsdp_tp:308:train] epoch=26 iter=3 loss=18.119612 dt=0.123070 dtf=0.049109 dtb=0.073961
[2025-11-23 23:08:45,736615][I][examples/fsdp_tp:308:train] epoch=26 iter=4 loss=18.330467 dt=0.122950 dtf=0.049024 dtb=0.073926
[2025-11-23 23:08:45,870125][I][examples/fsdp_tp:308:train] epoch=26 iter=5 loss=17.619274 dt=0.123295 dtf=0.048917 dtb=0.074378
[2025-11-23 23:08:46,041539][I][examples/fsdp_tp:308:train] epoch=27 iter=0 loss=18.162222 dt=0.122430 dtf=0.049038 dtb=0.073392
[2025-11-23 23:08:46,212071][I][examples/fsdp_tp:308:train] epoch=27 iter=1 loss=17.983040 dt=0.123266 dtf=0.049085 dtb=0.074180
[2025-11-23 23:08:46,383307][I][examples/fsdp_tp:308:train] epoch=27 iter=2 loss=17.765091 dt=0.123247 dtf=0.049046 dtb=0.074200
[2025-11-23 23:08:46,553229][I][examples/fsdp_tp:308:train] epoch=27 iter=3 loss=18.173307 dt=0.123407 dtf=0.049173 dtb=0.074234
[2025-11-23 23:08:46,724872][I][examples/fsdp_tp:308:train] epoch=27 iter=4 loss=18.245537 dt=0.123093 dtf=0.049094 dtb=0.073999
[2025-11-23 23:08:46,858845][I][examples/fsdp_tp:308:train] epoch=27 iter=5 loss=17.655659 dt=0.123282 dtf=0.048941 dtb=0.074342
[2025-11-23 23:08:47,030138][I][examples/fsdp_tp:308:train] epoch=28 iter=0 loss=18.166986 dt=0.122607 dtf=0.049135 dtb=0.073472
[2025-11-23 23:08:47,200996][I][examples/fsdp_tp:308:train] epoch=28 iter=1 loss=18.028324 dt=0.123196 dtf=0.049101 dtb=0.074094
[2025-11-23 23:08:47,371038][I][examples/fsdp_tp:308:train] epoch=28 iter=2 loss=17.782415 dt=0.123231 dtf=0.049056 dtb=0.074175
[2025-11-23 23:08:47,541817][I][examples/fsdp_tp:308:train] epoch=28 iter=3 loss=18.221668 dt=0.123317 dtf=0.049108 dtb=0.074209
[2025-11-23 23:08:47,712328][I][examples/fsdp_tp:308:train] epoch=28 iter=4 loss=18.055534 dt=0.123091 dtf=0.049068 dtb=0.074024
[2025-11-23 23:08:47,846752][I][examples/fsdp_tp:308:train] epoch=28 iter=5 loss=17.535311 dt=0.123110 dtf=0.048965 dtb=0.074145
[2025-11-23 23:08:48,017572][I][examples/fsdp_tp:308:train] epoch=29 iter=0 loss=17.949869 dt=0.122543 dtf=0.049009 dtb=0.073534
[2025-11-23 23:08:48,188697][I][examples/fsdp_tp:308:train] epoch=29 iter=1 loss=17.816053 dt=0.123344 dtf=0.049042 dtb=0.074302
[2025-11-23 23:08:48,358970][I][examples/fsdp_tp:308:train] epoch=29 iter=2 loss=17.508337 dt=0.122775 dtf=0.048917 dtb=0.073858
[2025-11-23 23:08:48,531209][I][examples/fsdp_tp:308:train] epoch=29 iter=3 loss=17.903624 dt=0.123551 dtf=0.049260 dtb=0.074291
[2025-11-23 23:08:48,700166][I][examples/fsdp_tp:308:train] epoch=29 iter=4 loss=17.520927 dt=0.123329 dtf=0.049165 dtb=0.074165
[2025-11-23 23:08:48,835350][I][examples/fsdp_tp:308:train] epoch=29 iter=5 loss=17.068123 dt=0.123384 dtf=0.048904 dtb=0.074480
[2025-11-23 23:08:49,006882][I][examples/fsdp_tp:308:train] epoch=30 iter=0 loss=17.403053 dt=0.122483 dtf=0.048947 dtb=0.073536
[2025-11-23 23:08:49,177747][I][examples/fsdp_tp:308:train] epoch=30 iter=1 loss=17.278004 dt=0.123130 dtf=0.049022 dtb=0.074108
[2025-11-23 23:08:49,348383][I][examples/fsdp_tp:308:train] epoch=30 iter=2 loss=16.993158 dt=0.123127 dtf=0.048851 dtb=0.074276
[2025-11-23 23:08:49,518861][I][examples/fsdp_tp:308:train] epoch=30 iter=3 loss=17.386602 dt=0.123282 dtf=0.049061 dtb=0.074221
[2025-11-23 23:08:49,689906][I][examples/fsdp_tp:308:train] epoch=30 iter=4 loss=16.985554 dt=0.123027 dtf=0.048997 dtb=0.074031
[2025-11-23 23:08:49,823904][I][examples/fsdp_tp:308:train] epoch=30 iter=5 loss=16.574009 dt=0.123305 dtf=0.048878 dtb=0.074427
[2025-11-23 23:08:49,993948][I][examples/fsdp_tp:308:train] epoch=31 iter=0 loss=17.041647 dt=0.122783 dtf=0.049028 dtb=0.073756
[2025-11-23 23:08:50,165321][I][examples/fsdp_tp:308:train] epoch=31 iter=1 loss=17.004320 dt=0.123038 dtf=0.048978 dtb=0.074060
[2025-11-23 23:08:50,336342][I][examples/fsdp_tp:308:train] epoch=31 iter=2 loss=16.813034 dt=0.123019 dtf=0.049010 dtb=0.074009
[2025-11-23 23:08:50,508272][I][examples/fsdp_tp:308:train] epoch=31 iter=3 loss=17.167316 dt=0.125816 dtf=0.051551 dtb=0.074265
[2025-11-23 23:08:50,679065][I][examples/fsdp_tp:308:train] epoch=31 iter=4 loss=16.760450 dt=0.123084 dtf=0.048945 dtb=0.074140
[2025-11-23 23:08:50,813479][I][examples/fsdp_tp:308:train] epoch=31 iter=5 loss=16.184158 dt=0.123341 dtf=0.048926 dtb=0.074415
[2025-11-23 23:08:50,983835][I][examples/fsdp_tp:308:train] epoch=32 iter=0 loss=16.705338 dt=0.122261 dtf=0.048885 dtb=0.073376
[2025-11-23 23:08:51,154788][I][examples/fsdp_tp:308:train] epoch=32 iter=1 loss=16.581564 dt=0.123443 dtf=0.049109 dtb=0.074333
[2025-11-23 23:08:51,325852][I][examples/fsdp_tp:308:train] epoch=32 iter=2 loss=16.300953 dt=0.122993 dtf=0.048982 dtb=0.074011
[2025-11-23 23:08:51,496320][I][examples/fsdp_tp:308:train] epoch=32 iter=3 loss=16.422113 dt=0.123245 dtf=0.049189 dtb=0.074056
[2025-11-23 23:08:51,668020][I][examples/fsdp_tp:308:train] epoch=32 iter=4 loss=15.912511 dt=0.123165 dtf=0.048983 dtb=0.074183
[2025-11-23 23:08:51,801646][I][examples/fsdp_tp:308:train] epoch=32 iter=5 loss=15.214972 dt=0.123376 dtf=0.048940 dtb=0.074436
[2025-11-23 23:08:51,972820][I][examples/fsdp_tp:308:train] epoch=33 iter=0 loss=15.580718 dt=0.122582 dtf=0.049014 dtb=0.073568
[2025-11-23 23:08:52,143564][I][examples/fsdp_tp:308:train] epoch=33 iter=1 loss=15.407047 dt=0.123043 dtf=0.048979 dtb=0.074064
[2025-11-23 23:08:52,314138][I][examples/fsdp_tp:308:train] epoch=33 iter=2 loss=15.112477 dt=0.123126 dtf=0.049082 dtb=0.074044
[2025-11-23 23:08:52,485044][I][examples/fsdp_tp:308:train] epoch=33 iter=3 loss=15.127002 dt=0.123143 dtf=0.049133 dtb=0.074010
[2025-11-23 23:08:52,655640][I][examples/fsdp_tp:308:train] epoch=33 iter=4 loss=14.638748 dt=0.123194 dtf=0.049028 dtb=0.074166
[2025-11-23 23:08:52,788471][I][examples/fsdp_tp:308:train] epoch=33 iter=5 loss=14.013168 dt=0.123108 dtf=0.048858 dtb=0.074251
[2025-11-23 23:08:52,960680][I][examples/fsdp_tp:308:train] epoch=34 iter=0 loss=14.477768 dt=0.122581 dtf=0.048833 dtb=0.073748
[2025-11-23 23:08:53,130866][I][examples/fsdp_tp:308:train] epoch=34 iter=1 loss=14.441779 dt=0.123281 dtf=0.049088 dtb=0.074194
[2025-11-23 23:08:53,302080][I][examples/fsdp_tp:308:train] epoch=34 iter=2 loss=14.247241 dt=0.122880 dtf=0.049042 dtb=0.073838
[2025-11-23 23:08:53,472385][I][examples/fsdp_tp:308:train] epoch=34 iter=3 loss=14.338325 dt=0.123115 dtf=0.049121 dtb=0.073994
[2025-11-23 23:08:53,643697][I][examples/fsdp_tp:308:train] epoch=34 iter=4 loss=14.007848 dt=0.122961 dtf=0.049202 dtb=0.073759
[2025-11-23 23:08:53,777830][I][examples/fsdp_tp:308:train] epoch=34 iter=5 loss=13.396467 dt=0.123546 dtf=0.048942 dtb=0.074604
[2025-11-23 23:08:53,948307][I][examples/fsdp_tp:308:train] epoch=35 iter=0 loss=14.184364 dt=0.122563 dtf=0.049024 dtb=0.073539
[2025-11-23 23:08:54,119251][I][examples/fsdp_tp:308:train] epoch=35 iter=1 loss=14.252904 dt=0.123218 dtf=0.049191 dtb=0.074027
[2025-11-23 23:08:54,289953][I][examples/fsdp_tp:308:train] epoch=35 iter=2 loss=14.105580 dt=0.123247 dtf=0.049012 dtb=0.074236
[2025-11-23 23:08:54,461009][I][examples/fsdp_tp:308:train] epoch=35 iter=3 loss=14.170692 dt=0.123324 dtf=0.048985 dtb=0.074338
[2025-11-23 23:08:54,631535][I][examples/fsdp_tp:308:train] epoch=35 iter=4 loss=13.919093 dt=0.123320 dtf=0.049121 dtb=0.074198
[2025-11-23 23:08:54,766582][I][examples/fsdp_tp:308:train] epoch=35 iter=5 loss=13.103555 dt=0.123468 dtf=0.048908 dtb=0.074560
[2025-11-23 23:08:54,938023][I][examples/fsdp_tp:308:train] epoch=36 iter=0 loss=14.093236 dt=0.122740 dtf=0.048868 dtb=0.073872
[2025-11-23 23:08:55,108281][I][examples/fsdp_tp:308:train] epoch=36 iter=1 loss=14.137322 dt=0.123323 dtf=0.049034 dtb=0.074289
[2025-11-23 23:08:55,279509][I][examples/fsdp_tp:308:train] epoch=36 iter=2 loss=13.937359 dt=0.122794 dtf=0.048887 dtb=0.073907
[2025-11-23 23:08:55,449807][I][examples/fsdp_tp:308:train] epoch=36 iter=3 loss=13.896751 dt=0.123486 dtf=0.049367 dtb=0.074119
[2025-11-23 23:08:55,621128][I][examples/fsdp_tp:308:train] epoch=36 iter=4 loss=13.642166 dt=0.122957 dtf=0.049259 dtb=0.073698
[2025-11-23 23:08:55,756834][I][examples/fsdp_tp:308:train] epoch=36 iter=5 loss=12.679162 dt=0.123331 dtf=0.048995 dtb=0.074336
[2025-11-23 23:08:55,928282][I][examples/fsdp_tp:308:train] epoch=37 iter=0 loss=13.700002 dt=0.122935 dtf=0.049165 dtb=0.073769
[2025-11-23 23:08:56,099324][I][examples/fsdp_tp:308:train] epoch=37 iter=1 loss=13.680710 dt=0.123274 dtf=0.049089 dtb=0.074186
[2025-11-23 23:08:56,270214][I][examples/fsdp_tp:308:train] epoch=37 iter=2 loss=13.454812 dt=0.123011 dtf=0.049046 dtb=0.073965
[2025-11-23 23:08:56,441400][I][examples/fsdp_tp:308:train] epoch=37 iter=3 loss=13.337430 dt=0.123527 dtf=0.049225 dtb=0.074302
[2025-11-23 23:08:56,612294][I][examples/fsdp_tp:308:train] epoch=37 iter=4 loss=13.115956 dt=0.123113 dtf=0.048932 dtb=0.074181
[2025-11-23 23:08:56,747366][I][examples/fsdp_tp:308:train] epoch=37 iter=5 loss=12.163480 dt=0.123143 dtf=0.048945 dtb=0.074198
[2025-11-23 23:08:56,917527][I][examples/fsdp_tp:308:train] epoch=38 iter=0 loss=13.144317 dt=0.122675 dtf=0.049266 dtb=0.073409
[2025-11-23 23:08:57,088813][I][examples/fsdp_tp:308:train] epoch=38 iter=1 loss=13.091651 dt=0.123219 dtf=0.048924 dtb=0.074295
[2025-11-23 23:08:57,259368][I][examples/fsdp_tp:308:train] epoch=38 iter=2 loss=12.911670 dt=0.123151 dtf=0.049007 dtb=0.074145
[2025-11-23 23:08:57,430540][I][examples/fsdp_tp:308:train] epoch=38 iter=3 loss=12.808441 dt=0.123197 dtf=0.049152 dtb=0.074045
[2025-11-23 23:08:57,601362][I][examples/fsdp_tp:308:train] epoch=38 iter=4 loss=12.663268 dt=0.122964 dtf=0.048977 dtb=0.073987
[2025-11-23 23:08:57,736498][I][examples/fsdp_tp:308:train] epoch=38 iter=5 loss=11.903168 dt=0.123097 dtf=0.048865 dtb=0.074232
[2025-11-23 23:08:57,906675][I][examples/fsdp_tp:308:train] epoch=39 iter=0 loss=12.735383 dt=0.122264 dtf=0.048984 dtb=0.073280
[2025-11-23 23:08:58,078251][I][examples/fsdp_tp:308:train] epoch=39 iter=1 loss=12.673843 dt=0.123128 dtf=0.048970 dtb=0.074159
[2025-11-23 23:08:58,249135][I][examples/fsdp_tp:308:train] epoch=39 iter=2 loss=12.592435 dt=0.123152 dtf=0.049122 dtb=0.074030
[2025-11-23 23:08:58,419093][I][examples/fsdp_tp:308:train] epoch=39 iter=3 loss=12.555692 dt=0.123255 dtf=0.049152 dtb=0.074103
[2025-11-23 23:08:58,589576][I][examples/fsdp_tp:308:train] epoch=39 iter=4 loss=12.492253 dt=0.123138 dtf=0.049009 dtb=0.074129
[2025-11-23 23:08:58,724159][I][examples/fsdp_tp:308:train] epoch=39 iter=5 loss=12.108511 dt=0.123749 dtf=0.049020 dtb=0.074729
[2025-11-23 23:08:58,893714][I][examples/fsdp_tp:308:train] epoch=40 iter=0 loss=12.666725 dt=0.122310 dtf=0.048986 dtb=0.073324
[2025-11-23 23:08:59,064167][I][examples/fsdp_tp:308:train] epoch=40 iter=1 loss=12.664660 dt=0.123265 dtf=0.048991 dtb=0.074274
[2025-11-23 23:08:59,235060][I][examples/fsdp_tp:308:train] epoch=40 iter=2 loss=12.751859 dt=0.123083 dtf=0.049068 dtb=0.074015
[2025-11-23 23:08:59,406219][I][examples/fsdp_tp:308:train] epoch=40 iter=3 loss=12.839721 dt=0.123489 dtf=0.049267 dtb=0.074222
[2025-11-23 23:08:59,577749][I][examples/fsdp_tp:308:train] epoch=40 iter=4 loss=12.886269 dt=0.123712 dtf=0.049065 dtb=0.074648
[2025-11-23 23:08:59,711511][I][examples/fsdp_tp:308:train] epoch=40 iter=5 loss=12.947758 dt=0.123421 dtf=0.049076 dtb=0.074344
[2025-11-23 23:08:59,882613][I][examples/fsdp_tp:308:train] epoch=41 iter=0 loss=13.204814 dt=0.123176 dtf=0.049052 dtb=0.074124
[2025-11-23 23:09:00,053049][I][examples/fsdp_tp:308:train] epoch=41 iter=1 loss=13.284882 dt=0.123691 dtf=0.049148 dtb=0.074543
[2025-11-23 23:09:00,224279][I][examples/fsdp_tp:308:train] epoch=41 iter=2 loss=13.502170 dt=0.123320 dtf=0.049058 dtb=0.074262
[2025-11-23 23:09:00,395092][I][examples/fsdp_tp:308:train] epoch=41 iter=3 loss=13.667264 dt=0.124918 dtf=0.050176 dtb=0.074742
[2025-11-23 23:09:00,566668][I][examples/fsdp_tp:308:train] epoch=41 iter=4 loss=13.733002 dt=0.124130 dtf=0.049776 dtb=0.074354
[2025-11-23 23:09:00,701298][I][examples/fsdp_tp:308:train] epoch=41 iter=5 loss=14.011627 dt=0.124680 dtf=0.049775 dtb=0.074906
[2025-11-23 23:09:00,872247][I][examples/fsdp_tp:308:train] epoch=42 iter=0 loss=13.985995 dt=0.123476 dtf=0.049330 dtb=0.074145
[2025-11-23 23:09:01,043607][I][examples/fsdp_tp:308:train] epoch=42 iter=1 loss=14.000053 dt=0.128116 dtf=0.051946 dtb=0.076171
[2025-11-23 23:09:01,215104][I][examples/fsdp_tp:308:train] epoch=42 iter=2 loss=14.174724 dt=0.127004 dtf=0.050488 dtb=0.076516
[2025-11-23 23:09:01,386599][I][examples/fsdp_tp:308:train] epoch=42 iter=3 loss=14.273250 dt=0.126381 dtf=0.050725 dtb=0.075656
[2025-11-23 23:09:01,557234][I][examples/fsdp_tp:308:train] epoch=42 iter=4 loss=14.233051 dt=0.126402 dtf=0.050259 dtb=0.076143
[2025-11-23 23:09:01,692631][I][examples/fsdp_tp:308:train] epoch=42 iter=5 loss=14.492163 dt=0.126845 dtf=0.050234 dtb=0.076611
[2025-11-23 23:09:01,863515][I][examples/fsdp_tp:308:train] epoch=43 iter=0 loss=14.230023 dt=0.126402 dtf=0.050391 dtb=0.076011
[2025-11-23 23:09:02,034898][I][examples/fsdp_tp:308:train] epoch=43 iter=1 loss=14.112536 dt=0.127188 dtf=0.050534 dtb=0.076655
[2025-11-23 23:09:02,206155][I][examples/fsdp_tp:308:train] epoch=43 iter=2 loss=14.159011 dt=0.126221 dtf=0.050383 dtb=0.075838
[2025-11-23 23:09:02,376895][I][examples/fsdp_tp:308:train] epoch=43 iter=3 loss=14.139648 dt=0.127208 dtf=0.050431 dtb=0.076776
[2025-11-23 23:09:02,548595][I][examples/fsdp_tp:308:train] epoch=43 iter=4 loss=13.970997 dt=0.126173 dtf=0.050338 dtb=0.075835
[2025-11-23 23:09:02,683143][I][examples/fsdp_tp:308:train] epoch=43 iter=5 loss=14.098992 dt=0.126969 dtf=0.050194 dtb=0.076775
[2025-11-23 23:09:02,854926][I][examples/fsdp_tp:308:train] epoch=44 iter=0 loss=13.706028 dt=0.125613 dtf=0.050184 dtb=0.075429
[2025-11-23 23:09:03,025784][I][examples/fsdp_tp:308:train] epoch=44 iter=1 loss=13.481602 dt=0.126845 dtf=0.050268 dtb=0.076578
[2025-11-23 23:09:03,197037][I][examples/fsdp_tp:308:train] epoch=44 iter=2 loss=13.399712 dt=0.126256 dtf=0.050324 dtb=0.075932
[2025-11-23 23:09:03,367898][I][examples/fsdp_tp:308:train] epoch=44 iter=3 loss=13.286232 dt=0.127329 dtf=0.050477 dtb=0.076852
[2025-11-23 23:09:03,539930][I][examples/fsdp_tp:308:train] epoch=44 iter=4 loss=13.047324 dt=0.126745 dtf=0.050600 dtb=0.076145
[2025-11-23 23:09:03,673885][I][examples/fsdp_tp:308:train] epoch=44 iter=5 loss=13.024494 dt=0.126425 dtf=0.049970 dtb=0.076454
[2025-11-23 23:09:03,845738][I][examples/fsdp_tp:308:train] epoch=45 iter=0 loss=12.649323 dt=0.125786 dtf=0.050137 dtb=0.075649
[2025-11-23 23:09:04,016350][I][examples/fsdp_tp:308:train] epoch=45 iter=1 loss=12.393669 dt=0.126773 dtf=0.050152 dtb=0.076621
[2025-11-23 23:09:04,187891][I][examples/fsdp_tp:308:train] epoch=45 iter=2 loss=12.233971 dt=0.126149 dtf=0.050290 dtb=0.075859
[2025-11-23 23:09:04,359167][I][examples/fsdp_tp:308:train] epoch=45 iter=3 loss=12.103147 dt=0.126256 dtf=0.050402 dtb=0.075854
[2025-11-23 23:09:04,530592][I][examples/fsdp_tp:308:train] epoch=45 iter=4 loss=11.903816 dt=0.126336 dtf=0.050402 dtb=0.075934
[2025-11-23 23:09:04,665807][I][examples/fsdp_tp:308:train] epoch=45 iter=5 loss=11.781050 dt=0.126834 dtf=0.050305 dtb=0.076529
[2025-11-23 23:09:04,837040][I][examples/fsdp_tp:308:train] epoch=46 iter=0 loss=11.630653 dt=0.125462 dtf=0.049977 dtb=0.075485
[2025-11-23 23:09:05,008048][I][examples/fsdp_tp:308:train] epoch=46 iter=1 loss=11.501900 dt=0.126548 dtf=0.050271 dtb=0.076276
[2025-11-23 23:09:05,179748][I][examples/fsdp_tp:308:train] epoch=46 iter=2 loss=11.423011 dt=0.126633 dtf=0.050642 dtb=0.075991
[2025-11-23 23:09:05,351329][I][examples/fsdp_tp:308:train] epoch=46 iter=3 loss=11.463852 dt=0.127064 dtf=0.050696 dtb=0.076368
[2025-11-23 23:09:05,522490][I][examples/fsdp_tp:308:train] epoch=46 iter=4 loss=11.524013 dt=0.126077 dtf=0.050370 dtb=0.075707
[2025-11-23 23:09:05,657581][I][examples/fsdp_tp:308:train] epoch=46 iter=5 loss=11.495369 dt=0.126557 dtf=0.050068 dtb=0.076488
[2025-11-23 23:09:05,829003][I][examples/fsdp_tp:308:train] epoch=47 iter=0 loss=11.835677 dt=0.126182 dtf=0.050207 dtb=0.075974
[2025-11-23 23:09:06,000313][I][examples/fsdp_tp:308:train] epoch=47 iter=1 loss=12.036197 dt=0.126201 dtf=0.050255 dtb=0.075946
[2025-11-23 23:09:06,170691][I][examples/fsdp_tp:308:train] epoch=47 iter=2 loss=12.185329 dt=0.126704 dtf=0.050415 dtb=0.076289
[2025-11-23 23:09:06,342349][I][examples/fsdp_tp:308:train] epoch=47 iter=3 loss=12.512362 dt=0.126849 dtf=0.050608 dtb=0.076241
[2025-11-23 23:09:06,513351][I][examples/fsdp_tp:308:train] epoch=47 iter=4 loss=12.877116 dt=0.126438 dtf=0.050233 dtb=0.076205
[2025-11-23 23:09:06,648597][I][examples/fsdp_tp:308:train] epoch=47 iter=5 loss=12.881267 dt=0.126670 dtf=0.050330 dtb=0.076340
[2025-11-23 23:09:06,820483][I][examples/fsdp_tp:308:train] epoch=48 iter=0 loss=13.665424 dt=0.125603 dtf=0.050094 dtb=0.075509
[2025-11-23 23:09:06,991088][I][examples/fsdp_tp:308:train] epoch=48 iter=1 loss=14.047904 dt=0.126293 dtf=0.050331 dtb=0.075962
[2025-11-23 23:09:07,162618][I][examples/fsdp_tp:308:train] epoch=48 iter=2 loss=14.232732 dt=0.126902 dtf=0.050474 dtb=0.076428
[2025-11-23 23:09:07,334131][I][examples/fsdp_tp:308:train] epoch=48 iter=3 loss=14.616562 dt=0.126639 dtf=0.050501 dtb=0.076138
[2025-11-23 23:09:07,504910][I][examples/fsdp_tp:308:train] epoch=48 iter=4 loss=15.052699 dt=0.126335 dtf=0.050315 dtb=0.076020
[2025-11-23 23:09:07,640322][I][examples/fsdp_tp:308:train] epoch=48 iter=5 loss=14.852614 dt=0.127176 dtf=0.050560 dtb=0.076616
[2025-11-23 23:09:07,811142][I][examples/fsdp_tp:308:train] epoch=49 iter=0 loss=15.856215 dt=0.125689 dtf=0.050157 dtb=0.075531
[2025-11-23 23:09:07,982478][I][examples/fsdp_tp:308:train] epoch=49 iter=1 loss=16.221581 dt=0.126853 dtf=0.050601 dtb=0.076252
[2025-11-23 23:09:08,154341][I][examples/fsdp_tp:308:train] epoch=49 iter=2 loss=16.280622 dt=0.126561 dtf=0.050286 dtb=0.076275
[2025-11-23 23:09:08,325515][I][examples/fsdp_tp:308:train] epoch=49 iter=3 loss=16.567163 dt=0.126459 dtf=0.050336 dtb=0.076122
[2025-11-23 23:09:08,496385][I][examples/fsdp_tp:308:train] epoch=49 iter=4 loss=16.927382 dt=0.125990 dtf=0.050063 dtb=0.075927
[2025-11-23 23:09:08,631992][I][examples/fsdp_tp:308:train] epoch=49 iter=5 loss=16.470680 dt=0.127468 dtf=0.050638 dtb=0.076829
[2025-11-23 23:09:08,632953][I][examples/fsdp_tp:322:train] Finished 2D training
[rank3]:[W1123 23:09:08.922299072 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank2]:[W1123 23:09:08.922664279 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank1]:[W1123 23:09:08.925519024 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank4]:[W1123 23:09:09.488677147 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank5]:[W1123 23:09:09.508730515 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank7]:[W1123 23:09:09.513309294 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank6]:[W1123 23:09:09.517241060 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-11-23 23:09:10,584943][I][ezpz/history:810:plot_all] Saving train_epoch plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:09:10,762741][I][ezpz/history:810:plot_all] Saving train_iter plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:09:10,938608][I][ezpz/history:810:plot_all] Saving train_loss plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:09:11,112739][I][ezpz/history:810:plot_all] Saving train_dt plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:09:11,289172][I][ezpz/history:810:plot_all] Saving train_dtf plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:09:11,459550][I][ezpz/history:810:plot_all] Saving train_dtb plot to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/mplot
[2025-11-23 23:09:11,618333][I][ezpz/history:714:tplot_all] Saving tplots to /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot
                 train_epoch [2025-11-23-230911]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
49.0‚î§                                                  ‚ñÑ‚ñÑ‚ñü‚ñÄ‚îÇ
    ‚îÇ                                              ‚ñó‚ñÑ‚ñÑ‚ñÄ‚ñò   ‚îÇ
41.7‚î§                                           ‚ñÑ‚ñÑ‚ñû‚ñÄ       ‚îÇ
    ‚îÇ                                       ‚ñó‚ñÑ‚ñÑ‚ñÄ‚ñò          ‚îÇ
    ‚îÇ                                    ‚ñÑ‚ñÑ‚ñõ‚ñò              ‚îÇ
34.3‚î§                                ‚ñÑ‚ñÑ‚ñü‚ñÄ                  ‚îÇ
    ‚îÇ                            ‚ñó‚ñÑ‚ñÑ‚ñõ‚ñò                     ‚îÇ
27.0‚î§                         ‚ñÑ‚ñû‚ñÄ‚ñÄ                         ‚îÇ
    ‚îÇ                     ‚ñó‚ñü‚ñÄ‚ñÄ‚ñò                            ‚îÇ
19.7‚î§                  ‚ñÑ‚ñõ‚ñÄ‚ñÄ                                ‚îÇ
    ‚îÇ              ‚ñó‚ñü‚ñÄ‚ñÄ                                    ‚îÇ
    ‚îÇ          ‚ñó‚ñÑ‚ñÄ‚ñÄ‚ñò                                       ‚îÇ
12.3‚î§       ‚ñÑ‚ñû‚ñÄ‚ñÄ                                           ‚îÇ
    ‚îÇ   ‚ñó‚ñÑ‚ñÄ‚ñÄ‚ñò                                              ‚îÇ
 5.0‚î§‚ñÑ‚ñõ‚ñÄ‚ñÄ                                                  ‚îÇ
    ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
      11 28 44  63 77   104 127 143 162   194 215 234  266
train_epoch                   iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_epoch.txt
                 train_iter [2025-11-23-230911]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
5.00‚î§ ‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñó‚ñå‚ñå‚ñå‚ñü‚ñê‚ñê‚ñó‚ñå‚ñå‚ñü‚ñê‚îÇ
    ‚îÇ ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚îÇ
4.17‚î§ ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚îÇ
    ‚îÇ‚ñó‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñå‚ñå‚ñà‚ñü‚ñê‚ñô‚ñô‚ñå‚ñà‚ñü‚ñê‚ñê‚ñô‚ñå‚ñà‚ñû‚îÇ
    ‚îÇ‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñå‚îÇ
3.33‚î§‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñå‚îÇ
    ‚îÇ‚ñê‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñô‚ñå‚ñà‚ñà‚ñû‚ñà‚ñà‚ñô‚ñú‚ñà‚ñü‚ñê‚ñà‚ñô‚ñú‚ñå‚îÇ
2.50‚î§‚ñê‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñå‚îÇ
    ‚îÇ‚ñê‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñà‚ñà‚ñê‚ñå‚îÇ
1.67‚î§‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñà‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñà‚ñå‚ñà‚ñà‚ñê ‚îÇ
0.83‚î§‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê ‚îÇ
    ‚îÇ‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñå‚ñå‚ñå‚ñà‚ñê‚ñê‚ñê‚ñå‚ñå‚ñà‚ñê ‚îÇ
0.00‚î§‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñù‚ñå‚ñå‚ñå‚ñú‚ñê‚ñê‚ñù‚ñå‚ñå‚ñú‚ñê ‚îÇ
    ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
      11 28 44  63 77   104 127 143 162   194 215 234  266
train_iter                    iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_iter.txt
                 train_loss [2025-11-23-230911]
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
18.4‚î§           ‚ñó ‚ññ         ‚ñó‚ñü‚ñô‚ñô‚ñô‚ñô‚ññ                        ‚îÇ
    ‚îÇ          ‚ñó‚ñê‚ñü‚ñô‚ñô‚ñó‚ññ‚ññ  ‚ñó‚ñü‚ñü‚ñú ‚ñò‚ñÄ‚ñò‚ñÄ‚ñú‚ñà‚ñÑ                      ‚îÇ
16.4‚î§          ‚ñõ‚ñà‚ñÄ‚ñù‚ñù‚ñÄ‚ñú‚ñê‚ñú‚ñà‚ñû‚ñà‚ñê        ‚ñÄ‚ñà‚ññ                  ‚ñó‚ñü‚îÇ
    ‚îÇ         ‚ñÑ‚ñå     ‚ñù‚ñê‚ñê‚ñå‚ñå‚ñù           ‚ñô                  ‚ñê ‚îÇ
    ‚îÇ        ‚ñó‚ñõ        ‚ñù‚ñå‚ñò            ‚ñò‚ñå                 ‚ñà ‚îÇ
14.5‚î§        ‚ñû                         ‚ñú‚ñö‚ñà‚ñô      ‚ñü‚ñú‚ñô    ‚ñê  ‚îÇ
    ‚îÇ       ‚ñû‚ñå                          ‚ñù‚ñù‚ñå‚ñõ‚ñô   ‚ñû  ‚ñù‚ñô   ‚ñû  ‚îÇ
12.5‚î§    ‚ññ‚ñó‚ñû‚ñå‚ñò                             ‚ñò‚ñå‚ñà‚ñö‚ñÄ    ‚ñù‚ññ ‚ñó‚ñò  ‚îÇ
    ‚îÇ  ‚ñó‚ñõ‚ñú‚ñÄ‚ñò‚ñå                                ‚ñù       ‚ñù‚ñÑ‚ñõ   ‚îÇ
10.6‚î§ ‚ñû‚ñà                                                   ‚îÇ
    ‚îÇ ‚ñå‚ñå                                                   ‚îÇ
    ‚îÇ‚ñó‚ñå‚ñò                                                   ‚îÇ
 8.6‚î§‚ñê‚ñå                                                    ‚îÇ
    ‚îÇ‚ñû‚ñå                                                    ‚îÇ
 6.6‚î§‚ñå‚ñå                                                    ‚îÇ
    ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
      11 28 44  63 77   104 127 143 162   194 215 234  266
train_loss                    iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_loss.txt
                  train_dt [2025-11-23-230911]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.264‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.240‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.217‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.193‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.169‚î§        ‚ñó   ‚ñê                                        ‚îÇ
     ‚îÇ        ‚ñà   ‚ñê                                        ‚îÇ
     ‚îÇ        ‚ñà   ‚ñê                                        ‚îÇ
0.145‚î§        ‚ñà   ‚ñê                                        ‚îÇ
     ‚îÇ        ‚ñà   ‚ñê                                        ‚îÇ
0.121‚î§‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñô‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñô‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñú‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚ñÄ‚îÇ
     ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
       11 28 44  63 77   104    143 162   194 215 234  266
train_dt                      iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_dt.txt
                  train_dt [2025-11-23-230911]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
268.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
223.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
178.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
134.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 89.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 44.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
  0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà           ‚ñà‚ñà‚ñà‚ñà‚ñà                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
    0.115        0.154        0.193        0.232      0.270
freq                        train_dt
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_dt-hist.txt
                  train_dtf [2025-11-23-230911]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.190‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.166‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.143‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.119‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.096‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.072‚î§            ‚ñê                                        ‚îÇ
     ‚îÇ            ‚ñê                                        ‚îÇ
0.049‚î§‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñô‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñü‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚îÇ
     ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
       11 28 44  63 77   104    143 162   194 215 234  266
train_dtf                     iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_dtf.txt
                  train_dtf [2025-11-23-230911]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
269.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
224.2‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
179.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
134.5‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 89.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 44.8‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
  0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
    0.042        0.081        0.119        0.157      0.196
freq                        train_dtf
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_dtf-hist.txt
                   train_dtb [2025-11-23-230911]
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
0.1218‚î§        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                           ‚îÇ
0.1137‚î§        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                           ‚îÇ
0.1055‚î§        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                           ‚îÇ
0.0973‚î§        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                           ‚îÇ
0.0892‚î§        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                           ‚îÇ
0.0810‚î§        ‚ñå                                           ‚îÇ
      ‚îÇ        ‚ñå                                 ‚ñó‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚îÇ
0.0729‚î§‚ñû‚ñõ‚ñú‚ñà‚ñà‚ñà‚ñÄ‚ñà‚ñà‚ñõ‚ñà‚ñà‚ñà‚ñÄ‚ñõ‚ñõ‚ñà‚ñõ‚ñÄ‚ñú‚ñú‚ñÄ‚ñÄ‚ñõ‚ñÄ‚ñú‚ñú‚ñú‚ñú‚ñÄ‚ñÄ‚ñõ‚ñõ‚ñÄ‚ñú‚ñÄ‚ñú‚ñÄ‚ñõ‚ñõ‚ñõ‚ñÄ‚ñÄ         ‚îÇ
      ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
        11 28 44  63   89 104    143 162   194    234  266
train_dtb                      iter
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_dtb.txt
                  train_dtb [2025-11-23-230911]
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
269.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
224.2‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
179.3‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
134.5‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 89.7‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
 44.8‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà                                                ‚îÇ
  0.0‚î§‚ñà‚ñà‚ñà‚ñà‚ñà                                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ
     ‚îî‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îò
    0.071        0.084        0.097        0.111      0.124
freq                        train_dtb
text saved in /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/plots/tplot/train_dtb-hist.txt
[2025-11-23 23:09:11,747310][I][utils/__init__:416:dataset_to_h5pyfile] Saving dataset to: /home/tnguyent/ai-science-training-series/02-AI-at-Scale/outputs/ezpz-fsdp-tp/2025-11-23-230909/ezpz-fsdp-tp/train_dataset.h5
[2025-11-23 23:09:11,756382][I][examples/fsdp_tp:329:train] dataset=<xarray.Dataset> Size: 15kB
Dimensions:      (draw: 270)
Coordinates:
  * draw         (draw) int64 2kB 0 1 2 3 4 5 6 ... 263 264 265 266 267 268 269
Data variables:
    train_epoch  (draw) int64 2kB 5 5 5 5 5 5 6 6 6 ... 48 48 49 49 49 49 49 49
    train_iter   (draw) int64 2kB 0 1 2 3 4 5 0 1 2 3 4 ... 2 3 4 5 0 1 2 3 4 5
    train_loss   (draw) float64 2kB 6.633 7.202 7.889 ... 16.57 16.93 16.47
    train_dt     (draw) float64 2kB 0.1219 0.1225 0.1228 ... 0.1265 0.126 0.1275
    train_dtf    (draw) float64 2kB 0.04883 0.04896 0.04891 ... 0.05006 0.05064
    train_dtb    (draw) float64 2kB 0.0731 0.07354 0.07385 ... 0.07593 0.07683
[rank0]:[W1123 23:09:12.174315381 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Application fb343854 resources: utime=481s stime=148s maxrss=2593256KB inblock=1024 oublock=3504 minflt=2723954 majflt=1314 nvcsw=368726 nivcsw=2678
[2025-11-23 23:09:16,848800][I][ezpz/launch:402:launch] Execution finished with 0.
[2025-11-23 23:09:16,849296][I][ezpz/launch:403:launch] Executing finished in 75.88 seconds.
[2025-11-23 23:09:16,849705][I][ezpz/launch:404:launch] Took 75.88 seconds to run. Exiting.
Finished TP=4 at 2025-11-23 23:09:18
--------------------------------------------------------
tnguyent@x3206c0s37b1n0:~/ai-science-training-series/02-AI-at-Scale> 